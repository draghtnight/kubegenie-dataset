[
  {
    "apiVersion": "policy/v1beta1",
    "kind": "PodDisruptionBudget",
    "metadata": {
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      },
      "name": "activator"
    },
    "spec": {
      "selector": {
        "matchLabels": {
          "app": "activator"
        }
      },
      "minAvailable": 1
    }
  },
  {
    "apiVersion": "policy/v1beta1",
    "kind": "PodDisruptionBudget",
    "metadata": {
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      },
      "name": "autoscaler"
    },
    "spec": {
      "selector": {
        "matchLabels": {
          "app": "autoscaler"
        }
      },
      "minAvailable": 1
    }
  },
  {
    "apiVersion": "policy/v1beta1",
    "kind": "PodDisruptionBudget",
    "metadata": {
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      },
      "name": "controller"
    },
    "spec": {
      "selector": {
        "matchLabels": {
          "app": "controller"
        }
      },
      "minAvailable": 1
    }
  },
  {
    "apiVersion": "policy/v1beta1",
    "kind": "PodDisruptionBudget",
    "metadata": {
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      },
      "name": "webhook"
    },
    "spec": {
      "selector": {
        "matchLabels": {
          "app": "webhook"
        }
      },
      "minAvailable": 1
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ServiceAccount",
    "metadata": {
      "name": "controller",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    }
  },
  {
    "apiVersion": "v1",
    "kind": "Secret",
    "metadata": {
      "name": "webhook-certs",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-autoscaler",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# The Revision ContainerConcurrency field specifies the maximum number\n# of requests the Container can handle at once. Container concurrency\n# target percentage is how much of that maximum to use in a stable\n# state. E.g. if a Revision specifies ContainerConcurrency of 10, then\n# the Autoscaler will try to maintain 7 concurrent connections per pod\n# on average.\n# Note: this limit will be applied to container concurrency set at every\n# level (ConfigMap, Revision Spec or Annotation).\n# For legacy and backwards compatibility reasons, this value also accepts\n# fractional values in (0, 1] interval (i.e. 0.7 â‡’ 70%).\n# Thus minimal percentage value must be greater than 1.0, or it will be\n# treated as a fraction.\n# NOTE: that this value does not affect actual number of concurrent requests\n#       the user container may receive, but only the average number of requests\n#       that the revision pods will receive.\ncontainer-concurrency-target-percentage: \"70\"\n\n# The container concurrency target default is what the Autoscaler will\n# try to maintain when concurrency is used as the scaling metric for the\n# Revision and the Revision specifies unlimited concurrency.\n# When revision explicitly specifies container concurrency, that value\n# will be used as a scaling target for autoscaler.\n# When specifying unlimited concurrency, the autoscaler will\n# horizontally scale the application based on this target concurrency.\n# This is what we call \"soft limit\" in the documentation, i.e. it only\n# affects number of pods and does not affect the number of requests\n# individual pod processes.\n# The value must be a positive number such that the value multiplied\n# by container-concurrency-target-percentage is greater than 0.01.\n# NOTE: that this value will be adjusted by application of\n#       container-concurrency-target-percentage, i.e. by default\n#       the system will target on average 70 concurrent requests\n#       per revision pod.\n# NOTE: Only one metric can be used for autoscaling a Revision.\ncontainer-concurrency-target-default: \"100\"\n\n# The requests per second (RPS) target default is what the Autoscaler will\n# try to maintain when RPS is used as the scaling metric for a Revision and\n# the Revision specifies unlimited RPS. Even when specifying unlimited RPS,\n# the autoscaler will horizontally scale the application based on this\n# target RPS.\n# Must be greater than 1.0.\n# NOTE: Only one metric can be used for autoscaling a Revision.\nrequests-per-second-target-default: \"200\"\n\n# The target burst capacity specifies the size of burst in concurrent\n# requests that the system operator expects the system will receive.\n# Autoscaler will try to protect the system from queueing by introducing\n# Activator in the request path if the current spare capacity of the\n# service is less than this setting.\n# If this setting is 0, then Activator will be in the request path only\n# when the revision is scaled to 0.\n# If this setting is > 0 and container-concurrency-target-percentage is\n# 100% or 1.0, then activator will always be in the request path.\n# -1 denotes unlimited target-burst-capacity and activator will always\n# be in the request path.\n# Other negative values are invalid.\ntarget-burst-capacity: \"200\"\n\n# When operating in a stable mode, the autoscaler operates on the\n# average concurrency over the stable window.\n# Stable window must be in whole seconds.\nstable-window: \"60s\"\n\n# When observed average concurrency during the panic window reaches\n# panic-threshold-percentage the target concurrency, the autoscaler\n# enters panic mode. When operating in panic mode, the autoscaler\n# scales on the average concurrency over the panic window which is\n# panic-window-percentage of the stable-window.\n# When computing the panic window it will be rounded to the closest\n# whole second.\npanic-window-percentage: \"10.0\"\n\n# The percentage of the container concurrency target at which to\n# enter panic mode when reached within the panic window.\npanic-threshold-percentage: \"200.0\"\n\n# Max scale up rate limits the rate at which the autoscaler will\n# increase pod count. It is the maximum ratio of desired pods versus\n# observed pods.\n# Cannot be less or equal to 1.\n# I.e with value of 2.0 the number of pods can at most go N to 2N\n# over single Autoscaler period (see tick-interval), but at least N to\n# N+1, if Autoscaler needs to scale up.\nmax-scale-up-rate: \"1000.0\"\n\n# Max scale down rate limits the rate at which the autoscaler will\n# decrease pod count. It is the maximum ratio of observed pods versus\n# desired pods.\n# Cannot be less or equal to 1.\n# I.e. with value of 2.0 the number of pods can at most go N to N/2\n# over single Autoscaler evaluation period (see tick-interval), but at\n# least N to N-1, if Autoscaler needs to scale down.\nmax-scale-down-rate: \"2.0\"\n\n# Scale to zero feature flag\nenable-scale-to-zero: \"true\"\n\n# Scale to zero pod retention period defines the minimum amount\n# of time the last pod will remain after Autoscaler has decided to\n# scale to zero.\n# This flag is for the situations where the pod starup is very expensive\n# and the traffic is bursty (requiring smaller windows for fast action),\n# but patchy.\n# The larger of this flag and `scale-to-zero-grace-period` will effectively\n# detemine how the last pod will hang around.\nscale-to-zero-pod-retention-period: \"0s\"\n\n# Scale to zero grace period is the time an inactive revision is left\n# running before it is scaled to zero (min: 6s).\nscale-to-zero-grace-period: \"30s\"\n\n# pod-autoscaler-class specifies the default pod autoscaler class\n# that should be used if none is specified. If omitted, the Knative\n# Horizontal Pod Autoscaler (KPA) is used by default.\npod-autoscaler-class: \"kpa.autoscaling.knative.dev\"\n\n# The capacity of a single activator task.\n# The `unit` is one concurrent request proxied by the activator.\n# activator-capacity must be at least 1.\n# This value is used for computation of the Activator subset size.\n# See the algorithm here: http://bit.ly/38XiCZ3.\n# TODO(vagababov): tune after actual benchmarking.\nactivator-capacity: \"100.0\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-defaults",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# revision-timeout-seconds contains the default number of\n# seconds to use for the revision's per-request timeout, if\n# none is specified.\nrevision-timeout-seconds: \"300\"  # 5 minutes\n\n# max-revision-timeout-seconds contains the maximum number of\n# seconds that can be used for revision-timeout-seconds.\n# This value must be greater than or equal to revision-timeout-seconds.\n# If omitted, the system default is used (600 seconds).\nmax-revision-timeout-seconds: \"600\"  # 10 minutes\n\n# revision-cpu-request contains the cpu allocation to assign\n# to revisions by default.  If omitted, no value is specified\n# and the system default is used.\nrevision-cpu-request: \"400m\"  # 0.4 of a CPU (aka 400 milli-CPU)\n\n# to revisions by default.  If omitted, no value is specified\n# and the system default is used.\nrevision-memory-request: \"100M\"  # 100 megabytes of memory\n\n# revision-ephemeral-storage-request contains the ephemeral storage\n# allocation to assign to revisions by default.  If omitted, no value is\n# specified and the system default is used.\nrevision-ephemeral-storage-request: \"500M\"  # 500 megabytes of storage\n\n# revision-cpu-limit contains the cpu allocation to limit\n# revisions to by default.  If omitted, no value is specified\n# and the system default is used.\nrevision-cpu-limit: \"1000m\"  # 1 CPU (aka 1000 milli-CPU)\n\n# revision-memory-limit contains the memory allocation to limit\n# revisions to by default.  If omitted, no value is specified\n# and the system default is used.\nrevision-memory-limit: \"200M\"  # 200 megabytes of memory\n\n# revision-ephemeral-storage-limit contains the ephemeral storage\n# allocation to limit revisions to by default.  If omitted, no value is\n# specified and the system default is used.\nrevision-ephemeral-storage-limit: \"750M\"  # 750 megabytes of storage\n\n# container-name-template contains a template for the default\n# container name, if none is specified.  This field supports\n# Go templating and is supplied with the ObjectMeta of the\n# enclosing Service or Configuration, so values such as\n#  are also valid.\ncontainer-name-template: \"user-container\"\n\n# container-concurrency specifies the maximum number\n# of requests the Container can handle at once, and requests\n# above this threshold are queued.  Setting a value of zero\n# disables this throttling and lets through as many requests as\n# the pod receives.\ncontainer-concurrency: \"0\"\n\n# The container concurrency max limit is an operator setting ensuring that\n# the individual revisions cannot have arbitrary large concurrency\n# values, or autoscaling targets. `container-concurrency` default setting\n# must be at or below this value.\n\n\n# The container concurrency max limit is an operator setting ensuring that\n# the individual revisions cannot have arbitrary large concurrency\n# values, or autoscaling targets. `container-concurrency` default setting\n# must be at or below this value.\n# Must be greater than 1.\ncontainer-concurrency-max-limit: \"1000\"\n\n\nallow-container-concurrency-zero: \"true\"\n\n# feature flag indicates whether to enable multi container support or not\nenable-multi-container: \"false\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-deployment",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      },
      "annotations": {
        "knative.dev/example-checksum": "0608517d"
      }
    },
    "data": {
      "queueSidecarImage": "gcr.io/knative-releases/knative.dev/serving/cmd/queue@sha256:ab38418f2e13dfc21d48c64af0589f4eae5c40fc34a5e02f48b24b7156391d22",
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# List of repositories for which tag to digest resolving should be skipped\nregistriesSkippingTagResolving: \"ko.local,dev.local\"\n\n# ProgressDeadline is the duration we wait for the deployment to\n# be ready before considering it failed.\nprogressDeadline: \"120s\"\n\n# queueSidecarCPURequest is the requests.cpu to set for the queue proxy sidecar container.\n# If omitted, a default value (currently \"25m\"), is used.\nqueueSidecarCPURequest: \"25m\"\n\n# queueSidecarCPULimit is the limits.cpu to set for the queue proxy sidecar container.\n# If omitted, no value is specified and the system default is used.\nqueueSidecarCPULimit: \"1000m\"\n\n# queueSidecarMemoryRequest is the requests.memory to set for the queue proxy container.\n# If omitted, no value is specified and the system default is used.\nqueueSidecarMemoryRequest: \"400m\"\n\n# queueSidecarMemoryLimit is the limits.memory to set for the queue proxy container.\n# If omitted, no value is specified and the system default is used.\nqueueSidecarMemoryLimit: \"800m\"\n\n# queueSidecarEphemeralStorageRequest is the requests.ephemeral-storage to\n# set for the queue proxy sidecar container.\n# If omitted, no value is specified and the system default is used.\nqueueSidecarEphemeralStorageRequest: \"512m\"\n\n# queueSidecarEphemeralStorageLimit is the limits.ephemeral-storage to set\n# for the queue proxy sidecar container.\n# If omitted, no value is specified and the system default is used.\nqueueSidecarEphemeralStorageLimit: \"1024m\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-domain",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "data": {
      "example.com": "# Routes having domain suffix of 'svc.cluster.local' will not be exposed\n# through Ingress. You can define your own label selector to assign that\n# domain suffix to your Route here, or you can set the label\n#    \"serving.knative.dev/visibility=cluster-local\"\n# to achieve the same effect.  This shows how to make routes having\n# the label app=secret only exposed to the local cluster.\nsvc.cluster.local: |\n  selector:\n    app: secret\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-features",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      },
      "annotations": {
        "knative.dev/example-checksum": "e0eb3d80"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# Indicates whether multi container support is enabled\nmulti-container: \"disabled\"\n\n\n# Indicates whether Kubernetes FieldRef support is enabled\nkubernetes.podspec-fieldref: \"disabled\"\n\n\n# This feature validates PodSpecs from the validating webhook\n# against the K8s API Server.\n#\n# When \"allowed\", the client may enable the behavior with the\n# 'features.knative.dev/podspec-dryrun':'enabled' annotation.\n# When \"enabled\"  the server will always run the extra validation.\nkubernetes.podspec-dryrun: \"allowed\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-gc",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      },
      "annotations": {
        "knative.dev/example-checksum": "83219cc3"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# Delay after revision creation before considering it for GC\nstale-revision-create-delay: \"48h\"\n\n# Duration since a route has pointed at the revision before it\n# should be GC'd.\n# This minus lastpinned-debounce must be longer than the controller\n# resync period (10 hours).\nstale-revision-timeout: \"15h\"\n\n# Minimum number of generations of revisions to keep before considering\n# them for GC\nstale-revision-minimum-generations: \"20\"\n\n# To avoid constant updates, we allow an existing annotation to be stale by this\n# amount before we update the timestamp.\nstale-revision-lastpinned-debounce: \"5h\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-leader-election",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      },
      "annotations": {
        "knative.dev/example-checksum": "b705abde"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# leaseDuration is how long non-leaders will wait to try to acquire the\n# lock; 15 seconds is the value used by core kubernetes controllers.\nleaseDuration: \"15s\"\n\n# renewDeadline is how long a leader will try to renew the lease before\n# giving up; 10 seconds is the value used by core kubernetes controllers.\nrenewDeadline: \"10s\"\n\n# retryPeriod is how long the leader election client waits between tries of\n# actions; 2 seconds is the value used by core kubernetes controllers.\nretryPeriod: \"2s\"\n\n# enabledComponents is a comma-delimited list of component names for which\n# leader election is enabled. Valid values are:\nenabledComponents: \"controller,contour-ingress-controller,hpaautoscaler,certcontroller,istiocontroller,net-http01,nscontroller,webhook\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-logging",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# Common configuration for all Knative codebase\nzap-logger-config: |\n  {\n    \"level\": \"info\",\n    \"development\": false,\n    \"outputPaths\": [\"stdout\"],\n    \"errorOutputPaths\": [\"stderr\"],\n    \"encoding\": \"json\",\n    \"encoderConfig\": {\n      \"timeKey\": \"ts\",\n      \"levelKey\": \"level\",\n      \"nameKey\": \"logger\",\n      \"callerKey\": \"caller\",\n      \"messageKey\": \"msg\",\n      \"stacktraceKey\": \"stacktrace\",\n      \"lineEnding\": \"\",\n      \"levelEncoder\": \"\",\n      \"timeEncoder\": \"iso8601\",\n      \"durationEncoder\": \"\",\n      \"callerEncoder\": \"\"\n    }\n  }\n\n# Log level overrides\n# For all components except the autoscaler and queue proxy,\n# changes are be picked up immediately.\n# For autoscaler and queue proxy, changes require recreation of the pods.\nloglevel.controller: \"info\"\nloglevel.autoscaler: \"info\"\nloglevel.queueproxy: \"info\"\nloglevel.webhook: \"info\"\nloglevel.activator: \"info\"\nloglevel.hpaautoscaler: \"info\"\nloglevel.certcontroller: \"info\"\nloglevel.istiocontroller: \"info\"\nloglevel.nscontroller: \"info\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-network",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      },
      "annotations": {
        "knative.dev/example-checksum": "c7f290c9"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# DEPRECATED:\n# istio.sidecar.includeOutboundIPRanges is obsolete.\n# The current versions have outbound network access enabled by default.\n# If you need this option for some reason, please use global.proxy.includeIPRanges in Istio.\n#\n# istio.sidecar.includeOutboundIPRanges: \"*\"\n\n# ingress.class specifies the default ingress class\n# to use when not dictated by Route annotation.\n#\n# If not specified, will use the Istio ingress.\n#\n# Note that changing the Ingress class of an existing Route\n# will result in undefined behavior.  Therefore it is best to only\n# update this value during the setup of Knative, to avoid getting\n# undefined behavior.\ningress.class: \"istio.ingress.networking.knative.dev\"\n\n# certificate.class specifies the default Certificate class\n# to use when not dictated by Route annotation.\n#\n# If not specified, will use the Cert-Manager Certificate.\n#\n# Note that changing the Certificate class of an existing Route\n# will result in undefined behavior.  Therefore it is best to only\n# update this value during the setup of Knative, to avoid getting\n# undefined behavior.\ncertificate.class: \"cert-manager.certificate.networking.knative.dev\"\n\n# domainTemplate specifies the golang text template string to use\n# when constructing the Knative service's DNS name. The default\n# value is \"..\". And those three\n# values (Name, Namespace, Domain) are the only variables defined.\n#\ndomainTemplate: \"..\"\n\n# tagTemplate specifies the golang text template string to use\n# when constructing the DNS name for \"tags\" within the traffic blocks\n# of Routes and Configuration.  This is used in conjunction with the\n# domainTemplate above to determine the full URL for the tag.\ntagTemplate: \"-\"\n\n# Controls whether TLS certificates are automatically provisioned and\n# installed in the Knative ingress to terminate external TLS connection.\n# 1. Enabled: enabling auto-TLS feature.\n# 2. Disabled: disabling auto-TLS feature.\nautoTLS: \"Disabled\"\n\n# Controls the behavior of the HTTP endpoint for the Knative ingress.\n# It requires autoTLS to be enabled.\n# 1. Enabled: The Knative ingress will be able to serve HTTP connection.\n# 2. Disabled: The Knative ingress will reject HTTP traffic.\n# 3. Redirected: The Knative ingress will send a 302 redirect for all\n# http connections, asking the clients to use HTTPS\nhttpProtocol: \"Enabled\"\n\n# Controls whether tag header based routing feature are enabled or not.\n# 1. Enabled: enabling tag header based routing\n# 2. Disabled: disabling tag header based routing\ntagHeaderBasedRouting: \"Disabled\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-observability",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      },
      "annotations": {
        "knative.dev/example-checksum": "8acf3b67"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n\n# logging.enable-var-log-collection defaults to false.\n# The fluentd daemon set will be set up to collect /var/log if\n# this flag is true.\nlogging.enable-var-log-collection: \"false\"\n\n# logging.revision-url-template provides a template to use for producing the\n# logging URL that is injected into the status of each Revision.\n# This value is what you might use the the Knative monitoring bundle, and provides\n# access to Kibana after setting up kubectl proxy.\nlogging.revision-url-template: |\n  http://localhost:8001/api/v1/namespaces/knative-monitoring/services/kibana-logging/proxy/app/kibana#/discover?_a=(query:(match:(kubernetes.labels.serving-knative-dev%2FrevisionUID:(query:'${REVISION_UID}',type:phrase))))\n\n# If non-empty, this enables queue proxy writing user request logs to stdout, excluding probe\n# requests.\n# The value determines the shape of the request logs and it must be a valid go text/template.\n# It is important to keep this as a single line. Multiple lines are parsed as separate entities\n# by most collection agents and will split the request logs into multiple records.\n#\n# The following fields and functions are available to the template:\n#\n# Request: An http.Request (see https://golang.org/pkg/net/http/#Request)\n# representing an HTTP request received by the server.\n#\n# Response:\n# struct {\n#   Code    int       // HTTP status code (see https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)\n#   Size    int       // An int representing the size of the response.\n#   Latency float64   // A float64 representing the latency of the response in seconds.\n# }\n#\n# Revision:\n# struct {\n#   Name          string  // Knative revision name\n#   Namespace     string  // Knative revision namespace\n#   Service       string  // Knative service name\n#   Configuration string  // Knative configuration name\n#   PodName       string  // Name of the pod hosting the revision\n#   PodIP         string  // IP of the pod hosting the revision\n# }\n#\n\n# If true, this enables queue proxy writing request logs for probe requests to stdout.\n# It uses the same template for user requests, i.e. logging.request-log-template.\nlogging.enable-probe-request-log: \"false\"\n\n# metrics.backend-destination field specifies the system metrics destination.\n# It supports either prometheus (the default) or stackdriver.\n# Note: Using stackdriver will incur additional charges\nmetrics.backend-destination: prometheus\n\n# metrics.request-metrics-backend-destination specifies the request metrics\n# destination. It enables queue proxy to send request metrics.\n# Currently supported values: prometheus (the default), stackdriver.\nmetrics.request-metrics-backend-destination: prometheus\n\n# metrics.stackdriver-project-id field specifies the stackdriver project ID. This\n# field is optional. When running on GCE, application default credentials will be\n# used if this field is not provided.\nmetrics.stackdriver-project-id: \"<your stackdriver project id>\"\n\n# metrics.allow-stackdriver-custom-metrics indicates whether it is allowed to send metrics to\n# Stackdriver using \"global\" resource type and custom metric type if the\n# metrics are not supported by \"knative_revision\" resource type. Setting this\n# flag to \"true\" could cause extra Stackdriver charge.\n# If metrics.backend-destination is not Stackdriver, this is ignored.\nmetrics.allow-stackdriver-custom-metrics: \"false\"\n\n# profiling.enable indicates whether it is allowed to retrieve runtime profiling data from\n# the pods via an HTTP server in the format expected by the pprof visualization tool. When\n# enabled, the Knative Serving pods expose the profiling data on an alternate HTTP port 8008.\n# The HTTP context root for profiling is then /debug/pprof/.\nprofiling.enable: \"false\"\n"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "ConfigMap",
    "metadata": {
      "name": "config-tracing",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      },
      "annotations": {
        "knative.dev/example-checksum": "4002b4c2"
      }
    },
    "data": {
      "_example": "################################\n#                              #\n#    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n# This block is not actually functional configuration,\n# but serves to illustrate the available configuration\n# options and document them in a way that is accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample configuration options may be copied out of\n# this example block and unindented to be in the data block\n# to actually change the configuration.\n#\n# This may be \"zipkin\" or \"stackdriver\", the default is \"none\"\nbackend: \"none\"\n\n# URL to zipkin collector where traces are sent.\n# This must be specified when backend is \"zipkin\"\nzipkin-endpoint: \"http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans\"\n\n# The GCP project into which stackdriver metrics will be written\n# when backend is \"stackdriver\".  If unspecified, the project-id\n# is read from GCP metadata when running on GCP.\nstackdriver-project-id: \"my-project\"\n\n# Enable zipkin debug mode. This allows all spans to be sent to the server\n# bypassing sampling.\ndebug: \"false\"\n\n# Percentage (0-1) of requests to trace\nsample-rate: \"0.1\"\n"
    }
  },
  {
    "kind": "ClusterRole",
    "apiVersion": "rbac.authorization.k8s.io/v1",
    "metadata": {
      "name": "knative-serving-addressable-resolver",
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "duck.knative.dev/addressable": "true"
      }
    },
    "rules": [
      {
        "apiGroups": [
          "serving.knative.dev"
        ],
        "resources": [
          "routes",
          "routes/status",
          "services",
          "services/status"
        ],
        "verbs": [
          "get",
          "list",
          "watch"
        ]
      }
    ]
  },
  {
    "kind": "ClusterRole",
    "apiVersion": "rbac.authorization.k8s.io/v1",
    "metadata": {
      "name": "knative-serving-namespaced-edit",
      "labels": {
        "rbac.authorization.k8s.io/aggregate-to-edit": "true",
        "serving.knative.dev/release": "v0.15.0"
      }
    },
    "rules": [
      {
        "apiGroups": [
          "serving.knative.dev"
        ],
        "resources": [
          "*"
        ],
        "verbs": [
          "create",
          "update",
          "patch",
          "delete"
        ]
      },
      {
        "apiGroups": [
          "networking.internal.knative.dev",
          "autoscaling.internal.knative.dev",
          "caching.internal.knative.dev"
        ],
        "resources": [
          "*"
        ],
        "verbs": [
          "get",
          "list",
          "watch"
        ]
      }
    ]
  },
  {
    "kind": "ClusterRole",
    "apiVersion": "rbac.authorization.k8s.io/v1",
    "metadata": {
      "name": "knative-serving-namespaced-admin",
      "labels": {
        "rbac.authorization.k8s.io/aggregate-to-admin": "true",
        "serving.knative.dev/release": "v0.15.0"
      }
    },
    "rules": [
      {
        "apiGroups": [
          "serving.knative.dev"
        ],
        "resources": [
          "*"
        ],
        "verbs": [
          "*"
        ]
      },
      {
        "apiGroups": [
          "networking.internal.knative.dev",
          "autoscaling.internal.knative.dev",
          "caching.internal.knative.dev"
        ],
        "resources": [
          "*"
        ],
        "verbs": [
          "get",
          "list",
          "watch"
        ]
      }
    ]
  },
  {
    "kind": "ClusterRole",
    "apiVersion": "rbac.authorization.k8s.io/v1",
    "metadata": {
      "name": "knative-serving-namespaced-view",
      "labels": {
        "rbac.authorization.k8s.io/aggregate-to-view": "true",
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "rules": [
      {
        "apiGroups": [
          "serving.knative.dev",
          "networking.internal.knative.dev",
          "autoscaling.internal.knative.dev",
          "caching.internal.knative.dev"
        ],
        "resources": [
          "*"
        ],
        "verbs": [
          "get",
          "list",
          "watch"
        ]
      }
    ]
  },
  {
    "kind": "ClusterRole",
    "apiVersion": "rbac.authorization.k8s.io/v1",
    "metadata": {
      "name": "knative-serving-podspecable-binding",
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "duck.knative.dev/podspecable": "true"
      }
    },
    "rules": [
      {
        "apiGroups": [
          "serving.knative.dev"
        ],
        "resources": [
          "configurations",
          "services"
        ],
        "verbs": [
          "list",
          "watch",
          "patch"
        ]
      }
    ]
  },
  {
    "kind": "ClusterRole",
    "apiVersion": "rbac.authorization.k8s.io/v1",
    "metadata": {
      "name": "knative-serving-admin",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "aggregationRule": {
      "clusterRoleSelectors": [
        {
          "matchLabels": {
            "serving.knative.dev/controller": "true"
          }
        }
      ]
    },
    "rules": []
  },
  {
    "kind": "ClusterRole",
    "apiVersion": "rbac.authorization.k8s.io/v1",
    "metadata": {
      "name": "knative-serving-core",
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "serving.knative.dev/controller": "true"
      }
    },
    "rules": [
      {
        "apiGroups": [
          ""
        ],
        "resources": [
          "pods",
          "namespaces",
          "secrets",
          "configmaps",
          "endpoints",
          "services",
          "events",
          "serviceaccounts"
        ],
        "verbs": [
          "get",
          "list",
          "create",
          "update",
          "delete",
          "patch",
          "watch"
        ]
      },
      {
        "apiGroups": [
          ""
        ],
        "resources": [
          "endpoints/restricted"
        ],
        "verbs": [
          "create"
        ]
      },
      {
        "apiGroups": [
          "apps"
        ],
        "resources": [
          "deployments",
          "deployments/finalizers"
        ],
        "verbs": [
          "get",
          "list",
          "create",
          "update",
          "delete",
          "patch",
          "watch"
        ]
      },
      {
        "apiGroups": [
          "admissionregistration.k8s.io"
        ],
        "resources": [
          "mutatingwebhookconfigurations",
          "validatingwebhookconfigurations"
        ],
        "verbs": [
          "get",
          "list",
          "create",
          "update",
          "delete",
          "patch",
          "watch"
        ]
      },
      {
        "apiGroups": [
          "apiextensions.k8s.io"
        ],
        "resources": [
          "customresourcedefinitions",
          "customresourcedefinitions/status"
        ],
        "verbs": [
          "get",
          "list",
          "create",
          "update",
          "delete",
          "patch",
          "watch"
        ]
      },
      {
        "apiGroups": [
          "autoscaling"
        ],
        "resources": [
          "horizontalpodautoscalers"
        ],
        "verbs": [
          "get",
          "list",
          "create",
          "update",
          "delete",
          "patch",
          "watch"
        ]
      },
      {
        "apiGroups": [
          "coordination.k8s.io"
        ],
        "resources": [
          "leases"
        ],
        "verbs": [
          "get",
          "list",
          "create",
          "update",
          "delete",
          "patch",
          "watch"
        ]
      },
      {
        "apiGroups": [
          "serving.knative.dev",
          "autoscaling.internal.knative.dev",
          "networking.internal.knative.dev"
        ],
        "resources": [
          "*",
          "*/status",
          "*/finalizers"
        ],
        "verbs": [
          "get",
          "list",
          "create",
          "update",
          "delete",
          "deletecollection",
          "patch",
          "watch"
        ]
      },
      {
        "apiGroups": [
          "caching.internal.knative.dev"
        ],
        "resources": [
          "images"
        ],
        "verbs": [
          "get",
          "list",
          "create",
          "update",
          "delete",
          "patch",
          "watch"
        ]
      }
    ]
  },
  {
    "apiVersion": "rbac.authorization.k8s.io/v1",
    "kind": "ClusterRoleBinding",
    "metadata": {
      "name": "knative-serving-controller-admin",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "subjects": [
      {
        "kind": "ServiceAccount",
        "name": "controller",
        "namespace": "knative-serving"
      }
    ],
    "roleRef": {
      "kind": "ClusterRole",
      "name": "knative-serving-admin",
      "apiGroup": "rbac.authorization.k8s.io"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "Service",
    "metadata": {
      "name": "net-certmanager-webhook",
      "namespace": "knative-serving",
      "labels": {
        "role": "net-certmanager-webhook",
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "spec": {
      "ports": [
        {
          "name": "http-metrics",
          "port": 9090,
          "targetPort": 9090
        },
        {
          "name": "http-profiling",
          "port": 8008,
          "targetPort": 8008
        },
        {
          "name": "https-webhook",
          "port": 443,
          "targetPort": 8443
        }
      ],
      "selector": {
        "app": "net-certmanager-webhook"
      }
    }
  },
  {
    "apiVersion": "v1",
    "kind": "Service",
    "metadata": {
      "name": "activator-service",
      "namespace": "knative-serving",
      "labels": {
        "app": "activator",
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      }
    },
    "spec": {
      "selector": {
        "app": "activator"
      },
      "ports": [
        {
          "name": "http-metrics",
          "port": 9090,
          "targetPort": 9090
        },
        {
          "name": "http-profiling",
          "port": 8008,
          "targetPort": 8008
        },
        {
          "name": "http",
          "port": 80,
          "targetPort": 8012
        },
        {
          "name": "http2",
          "port": 81,
          "targetPort": 8013
        }
      ],
      "type": "ClusterIP"
    }
  },
  {
    "apiVersion": "v1",
    "kind": "Service",
    "metadata": {
      "labels": {
        "app": "autoscaler",
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      },
      "name": "autoscaler",
      "namespace": "knative-serving"
    },
    "spec": {
      "ports": [
        {
          "name": "http-metrics",
          "port": 9090,
          "targetPort": 9090
        },
        {
          "name": "http-profiling",
          "port": 8008,
          "targetPort": 8008
        },
        {
          "name": "http",
          "port": 8080,
          "targetPort": 8080
        }
      ],
      "selector": {
        "app": "autoscaler"
      }
    }
  },
  {
    "apiVersion": "v1",
    "kind": "Service",
    "metadata": {
      "labels": {
        "app": "controller",
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      },
      "name": "controller",
      "namespace": "knative-serving"
    },
    "spec": {
      "ports": [
        {
          "name": "http-metrics",
          "port": 9090,
          "targetPort": 9090
        },
        {
          "name": "http-profiling",
          "port": 8008,
          "targetPort": 8008
        }
      ],
      "selector": {
        "app": "controller"
      }
    }
  },
  {
    "apiVersion": "v1",
    "kind": "Service",
    "metadata": {
      "labels": {
        "role": "webhook",
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      },
      "name": "webhook",
      "namespace": "knative-serving"
    },
    "spec": {
      "ports": [
        {
          "name": "http-metrics",
          "port": 9090,
          "targetPort": 9090
        },
        {
          "name": "http-profiling",
          "port": 8008,
          "targetPort": 8008
        },
        {
          "name": "https-webhook",
          "port": 443,
          "targetPort": 8443
        }
      ],
      "selector": {
        "role": "webhook"
      }
    }
  },
  {
    "apiVersion": "apps/v1",
    "kind": "Deployment",
    "metadata": {
      "name": "net-certmanager-webhook",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "spec": {
      "selector": {
        "matchLabels": {
          "app": "net-certmanager-webhook",
          "role": "net-certmanager-webhook"
        }
      },
      "template": {
        "metadata": {
          "annotations": {
            "cluster-autoscaler.kubernetes.io/safe-to-evict": "false"
          },
          "labels": {
            "app": "net-certmanager-webhook",
            "role": "net-certmanager-webhook",
            "serving.knative.dev/release": "v0.16.0"
          }
        },
        "spec": {
          "serviceAccountName": "controller",
          "containers": [
            {
              "name": "webhook",
              "image": "gcr.io/knative-releases/knative.dev/net-certmanager/cmd/webhook@sha256:873b968f02b58e2bb3a1596209c37dee3ab75862f5a929b6b9a2ce7fea8bc14d",
              "resources": {
                "requests": {
                  "cpu": "20m",
                  "memory": "20Mi"
                },
                "limits": {
                  "cpu": "200m",
                  "memory": "200Mi"
                }
              },
              "env": [
                {
                  "name": "SYSTEM_NAMESPACE",
                  "valueFrom": {
                    "fieldRef": {
                      "fieldPath": "metadata.namespace"
                    }
                  }
                },
                {
                  "name": "CONFIG_LOGGING_NAME",
                  "value": "config-logging"
                },
                {
                  "name": "CONFIG_OBSERVABILITY_NAME",
                  "value": "config-observability"
                },
                {
                  "name": "METRICS_DOMAIN",
                  "value": "knative.dev/net-certmanager"
                },
                {
                  "name": "WEBHOOK_NAME",
                  "value": "net-certmanager-webhook"
                }
              ],
              "securityContext": {
                "allowPrivilegeEscalation": false,
                "capabilities": {
                  "drop": {
                    "": "NET_RAW"
                  }
                },
                "readOnlyRootFilesystem": true,
                "seccompProfile": {
                  "type": "RuntimeDefault"
                }
              },
              "ports": [
                {
                  "name": "metrics",
                  "containerPort": 9090
                },
                {
                  "name": "profiling",
                  "containerPort": 8008
                },
                {
                  "name": "https-webhook",
                  "containerPort": 8443
                }
              ]
            }
          ]
        }
      }
    }
  },
  {
    "apiVersion": "apps/v1",
    "kind": "Deployment",
    "metadata": {
      "name": "activator",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      }
    },
    "spec": {
      "selector": {
        "matchLabels": {
          "app": "activator",
          "role": "activator"
        }
      },
      "template": {
        "metadata": {
          "annotations": {
            "cluster-autoscaler.kubernetes.io/safe-to-evict": "false"
          },
          "labels": {
            "app": "activator",
            "role": "activator",
            "serving.knative.dev/release": "v0.16.0"
          }
        },
        "spec": {
          "serviceAccountName": "controller",
          "containers": [
            {
              "name": "activator",
              "image": "gcr.io/knative-releases/knative.dev/serving/cmd/activator@sha256:a5de0fb75046f2ad29a9394b9f4f31d258c4abaea3529cf3443d69e2aab1a879",
              "resources": {
                "seccompProfile": {
                  "type": "RuntimeDefault"
                }
              },
              "env": [
                {
                  "name": "GOGC",
                  "value": "500"
                },
                {
                  "name": "POD_NAME",
                  "valueFrom": {
                    "fieldRef": {
                      "fieldPath": "metadata.name"
                    }
                  }
                },
                {
                  "name": "POD_IP",
                  "valueFrom": {
                    "fieldRef": {
                      "fieldPath": "status.podIP"
                    }
                  }
                },
                {
                  "name": "SYSTEM_NAMESPACE",
                  "valueFrom": {
                    "fieldRef": {
                      "fieldPath": "metadata.namespace"
                    }
                  }
                },
                {
                  "name": "CONFIG_LOGGING_NAME",
                  "value": "config-logging"
                },
                {
                  "name": "CONFIG_OBSERVABILITY_NAME",
                  "value": "config-observability"
                },
                {
                  "name": "METRICS_DOMAIN",
                  "value": "knative.dev/internal/serving"
                }
              ],
              "securityContext": {
                "allowPrivilegeEscalation": false,
                "capabilities": {
                  "drop": {
                    "": "NET_RAW"
                  }
                },
                "readOnlyRootFilesystem": true
              },
              "ports": [
                {
                  "name": "metrics",
                  "containerPort": 9090
                },
                {
                  "name": "profiling",
                  "containerPort": 8008
                },
                {
                  "name": "http1",
                  "containerPort": 8012
                },
                {
                  "name": "h2c",
                  "containerPort": 8013
                }
              ],
              "readinessProbe": {
                "httpGet": {
                  "port": 8012,
                  "httpHeaders": [
                    {
                      "name": "k-kubelet-probe",
                      "value": "activator"
                    }
                  ]
                },
                "failureThreshold": 12
              },
              "livenessProbe": {
                "httpGet": {
                  "port": 8012,
                  "httpHeaders": [
                    {
                      "name": "k-kubelet-probe",
                      "value": "activator"
                    }
                  ]
                },
                "failureThreshold": 12
              }
            }
          ],
          "terminationGracePeriodSeconds": 300
        }
      }
    }
  },
  {
    "apiVersion": "apps/v1",
    "kind": "Deployment",
    "metadata": {
      "name": "autoscaler",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      }
    },
    "spec": {
      "replicas": 1,
      "selector": {
        "matchLabels": {
          "app": "autoscaler"
        }
      },
      "template": {
        "metadata": {
          "annotations": {
            "cluster-autoscaler.kubernetes.io/safe-to-evict": "false"
          },
          "labels": {
            "app": "autoscaler",
            "serving.knative.dev/release": "v0.16.0"
          }
        },
        "spec": {
          "serviceAccountName": "controller",
          "containers": [
            {
              "name": "autoscaler",
              "image": "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler@sha256:2ef460356b17481bc467fc7c35da581707dc490b1f32083457d6d4faed9ef300",
              "resources": {
                "seccompProfile": {
                  "type": "RuntimeDefault"
                }
              },
              "env": [
                {
                  "name": "SYSTEM_NAMESPACE",
                  "valueFrom": {
                    "fieldRef": {
                      "fieldPath": "metadata.namespace"
                    }
                  }
                },
                {
                  "name": "CONFIG_LOGGING_NAME",
                  "value": "config-logging"
                },
                {
                  "name": "CONFIG_OBSERVABILITY_NAME",
                  "value": "config-observability"
                },
                {
                  "name": "METRICS_DOMAIN",
                  "value": "knative.dev/serving"
                }
              ],
              "securityContext": {
                "allowPrivilegeEscalation": false,
                "capabilities": {
                  "drop": {
                    "": "NET_RAW"
                  }
                },
                "readOnlyRootFilesystem": true
              },
              "ports": [
                {
                  "name": "metrics",
                  "containerPort": 9090
                },
                {
                  "name": "profiling",
                  "containerPort": 8008
                },
                {
                  "name": "websocket",
                  "containerPort": 8080
                }
              ],
              "readinessProbe": {
                "httpGet": {
                  "port": 8080,
                  "httpHeaders": [
                    {
                      "name": "k-kubelet-probe",
                      "value": "autoscaler"
                    }
                  ]
                }
              },
              "livenessProbe": {
                "httpGet": {
                  "port": 8080,
                  "httpHeaders": [
                    {
                      "name": "k-kubelet-probe",
                      "value": "autoscaler"
                    }
                  ]
                }
              }
            }
          ]
        }
      }
    }
  },
  {
    "apiVersion": "apps/v1",
    "kind": "Deployment",
    "metadata": {
      "name": "controller",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      }
    },
    "spec": {
      "selector": {
        "matchLabels": {
          "app": "controller"
        }
      },
      "template": {
        "metadata": {
          "annotations": {
            "cluster-autoscaler.kubernetes.io/safe-to-evict": "true"
          },
          "labels": {
            "app": "controller",
            "serving.knative.dev/release": "v0.16.0"
          }
        },
        "spec": {
          "serviceAccountName": "controller",
          "containers": [
            {
              "name": "controller",
              "image": "gcr.io/knative-releases/knative.dev/serving/cmd/controller@sha256:30ce73388ae53e44edb52c1ef3b73b755e47004a90781fa9e0257cd021b20327",
              "resources": {
                "seccompProfile": {
                  "type": "RuntimeDefault"
                }
              },
              "env": [
                {
                  "name": "SYSTEM_NAMESPACE",
                  "valueFrom": {
                    "fieldRef": {
                      "fieldPath": "metadata.namespace"
                    }
                  }
                },
                {
                  "name": "CONFIG_LOGGING_NAME",
                  "value": "config-logging"
                },
                {
                  "name": "CONFIG_OBSERVABILITY_NAME",
                  "value": "config-observability"
                },
                {
                  "name": "METRICS_DOMAIN",
                  "value": "knative.dev/internal/serving"
                }
              ],
              "securityContext": {
                "allowPrivilegeEscalation": false,
                "capabilities": {
                  "drop": {
                    "": "NET_RAW"
                  }
                },
                "readOnlyRootFilesystem": true
              },
              "ports": [
                {
                  "name": "metrics",
                  "containerPort": 9090
                },
                {
                  "name": "profiling",
                  "containerPort": 8008
                }
              ]
            }
          ]
        }
      }
    }
  },
  {
    "apiVersion": "apps/v1",
    "kind": "Deployment",
    "metadata": {
      "name": "webhook",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "spec": {
      "selector": {
        "matchLabels": {
          "app": "webhook",
          "role": "webhook"
        }
      },
      "template": {
        "metadata": {
          "annotations": {
            "cluster-autoscaler.kubernetes.io/safe-to-evict": "false"
          },
          "labels": {
            "app": "webhook",
            "role": "webhook",
            "serving.knative.dev/release": "v0.16.0"
          }
        },
        "spec": {
          "serviceAccountName": "controller",
          "containers": [
            {
              "name": "webhook",
              "image": "gcr.io/knative-releases/knative.dev/serving/cmd/webhook@sha256:f16c0e022203f70a4228fba7d4cd951739ee43b491af9dbc569f233c9588e92a",
              "resources": {
                "seccompProfile": {
                  "type": "RuntimeDefault"
                }
              },
              "env": [
                {
                  "name": "SYSTEM_NAMESPACE",
                  "valueFrom": {
                    "fieldRef": {
                      "fieldPath": "metadata.namespace"
                    }
                  }
                },
                {
                  "name": "CONFIG_LOGGING_NAME",
                  "value": "config-logging"
                },
                {
                  "name": "CONFIG_OBSERVABILITY_NAME",
                  "value": "config-observability"
                },
                {
                  "name": "WEBHOOK_PORT",
                  "value": "8443"
                },
                {
                  "name": "METRICS_DOMAIN",
                  "value": "knative.dev/serving"
                }
              ],
              "securityContext": {
                "allowPrivilegeEscalation": false,
                "capabilities": {
                  "drop": {
                    "": "NET_RAW"
                  }
                },
                "readOnlyRootFilesystem": true
              },
              "ports": [
                {
                  "name": "metrics",
                  "containerPort": 9090
                },
                {
                  "name": "profiling",
                  "containerPort": 8008
                },
                {
                  "name": "https-webhook",
                  "containerPort": 8443
                }
              ],
              "readinessProbe": {
                "periodSeconds": 1,
                "httpGet": {
                  "scheme": "HTTPS",
                  "port": 8443,
                  "httpHeaders": [
                    {
                      "name": "k-kubelet-probe",
                      "value": "webhook"
                    }
                  ]
                }
              },
              "livenessProbe": {
                "periodSeconds": 1,
                "httpGet": {
                  "scheme": "HTTPS",
                  "port": 8443,
                  "httpHeaders": [
                    {
                      "name": "k-kubelet-probe",
                      "value": "webhook"
                    }
                  ]
                }
              }
            }
          ]
        }
      }
    }
  },
  {
    "apiVersion": "autoscaling/v2beta1",
    "kind": "HorizontalPodAutoscaler",
    "metadata": {
      "name": "activator",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0",
        "helm.sh/chart": "knative-serving-3.0.0",
        "app.kubernetes.io/name": "knative-serving",
        "app.kubernetes.io/instance": "release-name",
        "app.kubernetes.io/version": "v0.16.0",
        "app.kubernetes.io/managed-by": "Helm"
      }
    },
    "spec": {
      "minReplicas": 1,
      "maxReplicas": 20,
      "scaleTargetRef": {
        "apiVersion": "apps/v1",
        "kind": "Deployment",
        "name": "activator"
      },
      "metrics": [
        {
          "type": "Resource",
          "resource": {
            "name": "cpu",
            "targetAverageUtilization": 100
          }
        }
      ]
    }
  },
  {
    "apiVersion": "caching.internal.knative.dev/v1alpha1",
    "kind": "Image",
    "metadata": {
      "name": "queue-proxy",
      "namespace": "knative-serving",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "spec": {
      "image": "gcr.io/knative-releases/knative.dev/serving/cmd/queue@sha256:ab38418f2e13dfc21d48c64af0589f4eae5c40fc34a5e02f48b24b7156391d22"
    }
  },
  {
    "apiVersion": "admissionregistration.k8s.io/v1beta1",
    "kind": "MutatingWebhookConfiguration",
    "metadata": {
      "name": "webhook.serving.knative.dev",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "webhooks": [
      {
        "admissionReviewVersions": [
          "v1",
          "v1beta1"
        ],
        "clientConfig": {
          "service": {
            "name": "webhook",
            "namespace": "knative-serving"
          }
        },
        "failurePolicy": "Fail",
        "sideEffects": "None",
        "name": "webhook.serving.knative.dev",
        "timeoutSeconds": 10
      }
    ]
  },
  {
    "apiVersion": "admissionregistration.k8s.io/v1beta1",
    "kind": "ValidatingWebhookConfiguration",
    "metadata": {
      "name": "config.webhook.net-certmanager.networking.internal.knative.dev",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "webhooks": [
      {
        "admissionReviewVersions": [
          "v1beta1"
        ],
        "clientConfig": {
          "service": {
            "name": "net-certmanager-webhook",
            "namespace": "knative-serving"
          }
        },
        "failurePolicy": "Fail",
        "sideEffects": "None",
        "name": "config.webhook.net-certmanager.networking.internal.knative.dev",
        "namespaceSelector": {
          "matchExpressions": [
            {
              "key": "serving.knative.dev/release",
              "operator": "Exists"
            }
          ]
        }
      }
    ]
  },
  {
    "apiVersion": "admissionregistration.k8s.io/v1beta1",
    "kind": "ValidatingWebhookConfiguration",
    "metadata": {
      "name": "config.webhook.serving.knative.dev",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "webhooks": [
      {
        "admissionReviewVersions": [
          "v1",
          "v1beta1"
        ],
        "clientConfig": {
          "service": {
            "name": "webhook",
            "namespace": "knative-serving"
          }
        },
        "failurePolicy": "Fail",
        "sideEffects": "None",
        "name": "config.webhook.serving.knative.dev",
        "namespaceSelector": {
          "matchExpressions": [
            {
              "key": "serving.knative.dev/release",
              "operator": "Exists"
            }
          ]
        },
        "timeoutSeconds": 10
      }
    ]
  },
  {
    "apiVersion": "admissionregistration.k8s.io/v1beta1",
    "kind": "ValidatingWebhookConfiguration",
    "metadata": {
      "name": "validation.webhook.serving.knative.dev",
      "labels": {
        "serving.knative.dev/release": "v0.16.0"
      }
    },
    "webhooks": [
      {
        "admissionReviewVersions": [
          "v1",
          "v1beta1"
        ],
        "clientConfig": {
          "service": {
            "name": "webhook",
            "namespace": "knative-serving"
          }
        },
        "failurePolicy": "Fail",
        "sideEffects": "None",
        "name": "validation.webhook.serving.knative.dev",
        "timeoutSeconds": 10
      }
    ]
  }
]