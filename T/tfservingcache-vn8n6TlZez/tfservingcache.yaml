apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-tfservingcache
  labels:
    helm.sh/chart: tfservingcache-0.1.1
    app.kubernetes.io/name: tfservingcache
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  config.yaml: "\nproxyRestPort: 8093\nproxyGrpcPort: 8100\ncacheRestPort: 8094\ncacheGrpcPort: 8095\n\nmetrics:\n  path: \"/monitoring/prometheus/metrics\"\n  timeout: 3\n  modelLabels: false\n\nmodelProvider:\n  type: diskProvider\n  diskProvider:\n    baseDir: /model_repo\n\nmodelCache:\n  hostModelPath: /model_cache\n  size: 30000\n\nserving:\n  servingModelPath: /model_cache\n  grpcHost: \"localhost:8500\"\n  restHost: \"http://localhost:8501\"\n  maxConcurrentModels: 2\n  grpcConfigTimeout: 10 \n  grpcPredictTimeout: 60\n\nserviceDiscovery:\n  type: k8s\n  k8s:\n    fieldSelector:\n      metadata.name: release-name-tfservingcache-cache\n    portNames:\n      grpcCache: grpc-cache\n      httpCache: http-cache\n"
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-tfservingcache-cache
  labels:
    helm.sh/chart: tfservingcache-0.1.1
    app.kubernetes.io/name: tfservingcache
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8094
      protocol: TCP
      name: http-cache
    - port: 8095
      protocol: TCP
      name: grpc-cache
  selector:
    app.kubernetes.io/name: tfservingcache
    app.kubernetes.io/instance: release-name
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-tfservingcache-proxy
  labels:
    helm.sh/chart: tfservingcache-0.1.1
    app.kubernetes.io/name: tfservingcache
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8501
      targetPort: 8093
      protocol: TCP
      name: http-proxy
    - port: 8500
      targetPort: 8100
      protocol: TCP
      name: grpc-proxy
  selector:
    app.kubernetes.io/name: tfservingcache
    app.kubernetes.io/instance: release-name
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-tfservingcache
  labels:
    helm.sh/chart: tfservingcache-0.1.1
    app.kubernetes.io/name: tfservingcache
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: tfservingcache
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: tfservingcache
        app.kubernetes.io/instance: release-name
    spec:
      containers:
        - name: cache
          image: 'mkaloer/tfservingcache:'
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8093
              name: http-proxy
            - containerPort: 8100
              name: grpc-proxy
            - containerPort: 8094
              name: http-cache
            - containerPort: 8095
              name: grpc-cache
          volumeMounts:
            - name: cache-config
              mountPath: /tfservingcache/config.yaml
              subPath: config.yaml
            - name: models
              mountPath: /model_repo
            - name: cache
              mountPath: /model_cache
          resources:
            seccompProfile:
              type: RuntimeDefault
        - name: serving
          image: tensorflow/serving:latest
          imagePullPolicy: IfNotPresent
          command:
            - /bin/bash
            - -c
            - |
              echo 'model_config_list {}' > /models/models.config \ && echo 'prometheus_config { enable: true, path: "/monitoring/prometheus/metrics" }' > /models/monitoring.config \ && /usr/bin/tensorflow_model_server \
                --port=8500 \
                --rest_api_port=8501 \
                --model_config_file=/models/models.config \
                --monitoring_config_file=/models/monitoring.config
          volumeMounts:
            - name: cache
              mountPath: /model_cache
          resources: {}
      volumes:
        - name: cache-config
          configMap:
            name: release-name-tfservingcache
        - name: cache
          emptyDir: {}
        - name: models
          hostPath:
            path: /run/desktop/mnt/host/wsl/models
            type: Directory
