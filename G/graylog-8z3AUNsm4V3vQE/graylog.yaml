apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: elasticsearch-master-pdb
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: elasticsearch-master
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-mongodb
  namespace: 8z3AUNsm4V3vQE
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.31.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
secrets:
  - name: release-name-mongodb
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-graylog
  labels:
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: 4.2.7
---
apiVersion: v1
kind: Secret
metadata:
  name: release-name-graylog
  labels:
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: 4.2.7
type: Opaque
data:
  graylog-root-username: YWRtaW4=
  graylog-password-secret: cVdFZGJUNUFPUzViZENreg==
  graylog-password-sha2: MmIzNzdlMDE1YTgxNDYyMzhhOWVlN2ZiMjk0ZjMwOTc3MTllZDMyYzg2NTY3MmZjNGZlMzU2ZmQ4ZWI1NWQwZg==
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-mongodb-scripts
  namespace: 8z3AUNsm4V3vQE
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.31.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
data:
  setup.sh: |-
    #!/bin/bash

    . /opt/bitnami/scripts/mongodb-env.sh

    echo "Advertised Hostname: $MONGODB_ADVERTISED_HOSTNAME"
    echo "Advertised Port: $MONGODB_ADVERTISED_PORT_NUMBER"

    if [[ "$MY_POD_NAME" = "release-name-mongodb-0" ]]; then
        echo "Pod name matches initial primary pod name, configuring node as a primary"
        export MONGODB_REPLICA_SET_MODE="primary"
    else
        echo "Pod name doesn't match initial primary pod name, configuring node as a secondary"
        export MONGODB_REPLICA_SET_MODE="secondary"
        export MONGODB_INITIAL_PRIMARY_ROOT_USER="$MONGODB_ROOT_USER"
        export MONGODB_INITIAL_PRIMARY_ROOT_PASSWORD="$MONGODB_ROOT_PASSWORD"
        export MONGODB_INITIAL_PRIMARY_PORT_NUMBER="$MONGODB_PORT_NUMBER"
        export MONGODB_ROOT_PASSWORD=""
        export MONGODB_EXTRA_USERNAMES=""
        export MONGODB_EXTRA_DATABASES=""
        export MONGODB_EXTRA_PASSWORDS=""
        export MONGODB_ROOT_PASSWORD_FILE=""
        export MONGODB_EXTRA_USERNAMES_FILE=""
        export MONGODB_EXTRA_DATABASES_FILE=""
        export MONGODB_EXTRA_PASSWORDS_FILE=""
    fi

    exec /opt/bitnami/scripts/mongodb/entrypoint.sh /opt/bitnami/scripts/mongodb/run.sh
  setup-hidden.sh: |-
    #!/bin/bash

    . /opt/bitnami/scripts/mongodb-env.sh

    echo "Advertised Hostname: $MONGODB_ADVERTISED_HOSTNAME"
    echo "Advertised Port: $MONGODB_ADVERTISED_PORT_NUMBER"
    echo "Configuring node as a hidden node"
    export MONGODB_REPLICA_SET_MODE="hidden"
    export MONGODB_INITIAL_PRIMARY_ROOT_USER="$MONGODB_ROOT_USER"
    export MONGODB_INITIAL_PRIMARY_ROOT_PASSWORD="$MONGODB_ROOT_PASSWORD"
    export MONGODB_INITIAL_PRIMARY_PORT_NUMBER="$MONGODB_PORT_NUMBER"
    export MONGODB_ROOT_PASSWORD=""
    export MONGODB_EXTRA_USERNAMES=""
    export MONGODB_EXTRA_DATABASES=""
    export MONGODB_EXTRA_PASSWORDS=""
    export MONGODB_ROOT_PASSWORD_FILE=""
    export MONGODB_EXTRA_USERNAMES_FILE=""
    export MONGODB_EXTRA_DATABASES_FILE=""
    export MONGODB_EXTRA_PASSWORDS_FILE=""
    exec /opt/bitnami/scripts/mongodb/entrypoint.sh /opt/bitnami/scripts/mongodb/run.sh
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-graylog
  labels:
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: 4.2.7
data:
  log4j2.xml: |-
    <?xml version="1.0" encoding="UTF-8"?>
    <Configuration packages="org.graylog2.log4j" shutdownHook="disable">
        <Appenders>
            <Console name="STDOUT" target="SYSTEM_OUT">
                <PatternLayout pattern="%d %-7level [%c{1}] - %m - %X%n"/>
            </Console>
            <RollingFile name="rolling-file" fileName="/usr/share/graylog/log/server.log" filePattern="/usr/share/graylog/log/server.log.%i.gz">
                <PatternLayout>
                    <Pattern>%d{yyyy-MM-dd'T'HH:mm:ss.SSSXXX} %-5p [%c{1}] %m%n</Pattern>
                </PatternLayout>
                <Policies>
                    <SizeBasedTriggeringPolicy size="50MB"/>
                </Policies>
                <DefaultRolloverStrategy max="10" fileIndex="min"/>
            </RollingFile>
            <!-- Internal Graylog log appender. Please do not disable. This makes internal log messages available via REST calls. -->
            <Memory name="graylog-internal-logs" bufferSize="500"/>
            <!-- Rotate audit logs daily -->
            <RollingFile name="AUDITLOG" fileName="/usr/share/graylog/log/audit.log" filePattern="/usr/share/graylog/log/audit-%d{yyyy-MM-dd}.log.gz">
                <PatternLayout>
                    <Pattern>%d [%c{1}] - %m - %X%n</Pattern>
                </PatternLayout>
                <Policies>
                    <TimeBasedTriggeringPolicy />
                </Policies>
            </RollingFile>
        </Appenders>
        <Loggers>
            <!-- Application Loggers -->
            <Logger name="org.graylog2" level="warn"/>
            <Logger name="com.github.joschi.jadconfig" level="warn"/>
            <!-- This emits a harmless warning for ActiveDirectory every time which we can't work around :( -->
            <Logger name="org.apache.directory.api.ldap.model.message.BindRequestImpl" level="error"/>
            <!-- Prevent DEBUG message about Lucene Expressions not found. -->
            <Logger name="org.elasticsearch.script" level="warn"/>
            <!-- Disable messages from the version check -->
            <Logger name="org.graylog2.periodical.VersionCheckThread" level="off"/>
            <!-- Suppress crazy byte array dump of Drools -->
            <Logger name="org.drools.compiler.kie.builder.impl.KieRepositoryImpl" level="warn"/>
            <!-- Silence chatty natty -->
            <Logger name="com.joestelmach.natty.Parser" level="warn"/>
            <!-- Silence Kafka log chatter -->
            <Logger name="kafka.log.Log" level="warn"/>
            <Logger name="kafka.log.OffsetIndex" level="warn"/>
            <!-- Silence useless session validation messages -->
            <Logger name="org.apache.shiro.session.mgt.AbstractValidatingSessionManager" level="warn"/>
            <Root level="warn">
                <AppenderRef ref="STDOUT"/>
            </Root>
            <!-- Security Loggers -->
          <Logger name="org.graylog2.security.realm.PasswordAuthenticator" level="trace" additivity="false">
                <AppenderRef ref="AUDITLOG"/>
            </Logger>
            <Logger name="org.graylog2.security.realm.AccessTokenAuthenticator" level="trace" additivity="false">
                <AppenderRef ref="AUDITLOG"/>
            </Logger>
            <Logger name="org.graylog2.security.realm.RootAccountRealm" level="trace" additivity="false">
                <AppenderRef ref="AUDITLOG"/>
            </Logger>
            <Logger name="org.graylog2.shared.security.ShiroAuthorizationFilter" level="trace" additivity="false">
                <AppenderRef ref="AUDITLOG"/>
            </Logger>
        </Loggers>
    </Configuration>
  graylog.conf: "node_id_file = /usr/share/graylog/data/journal/node-id\nroot_username = admin\nroot_email = \nroot_timezone = UTC\n\nhttp_bind_address = 0.0.0.0:9000\nelasticsearch_hosts = http://elasticsearch-master.default.svc.cluster.local:9200\nallow_leading_wildcard_searches = false\nallow_highlighting = false\noutput_batch_size = 500\noutput_flush_interval = 1\noutput_fault_count_threshold = 5\noutput_fault_penalty_seconds = 30\nprocessbuffer_processors = 5\noutputbuffer_processors = 3\nprocessor_wait_strategy = blocking\nring_size = 65536\ninputbuffer_ring_size = 65536\ninputbuffer_processors = 2\ninputbuffer_wait_strategy = blocking\nmessage_journal_enabled = true\n# Do not change `message_journal_dir` location\nmessage_journal_dir = /usr/share/graylog/data/journal\nmessage_journal_max_size = 5gb\nlb_recognition_period_seconds = 3\n# Use a replica set instead of a single host\nmongodb_uri = mongodb://release-name-mongodb-headless.default.svc.cluster.local:27017/graylog?replicaSet=rs0\nmongodb_max_connections = 1000\nmongodb_threads_allowed_to_block_multiplier = 5\n# Email transport\ntransport_email_enabled = false\ntransport_email_hostname = \ntransport_email_port = 2587\ntransport_email_use_auth = true\ntransport_email_use_tls = true\ntransport_email_use_ssl = false\ntransport_email_auth_username = \ntransport_email_auth_password = \ntransport_email_subject_prefix = [graylog]\ntransport_email_from_email = \ncontent_packs_dir = /usr/share/graylog/data/contentpacks\ncontent_packs_auto_load = grok-patterns.json\nproxied_requests_thread_pool_size = 32"
  entrypoint.sh: |-
    #!/usr/bin/env bash

    GRAYLOG_HOME=/usr/share/graylog
    export GRAYLOG_PLUGIN_DIR=${GRAYLOG_HOME}/plugin
    # Graylog 4.0.2 images move plugin dir to `plugins-default`
    find ${GRAYLOG_HOME}/plugins-default/ -type f -exec cp {} ${GRAYLOG_PLUGIN_DIR} \;
    # Looking for Master IP
    retry=1
    for i in {0..2}
    do
      MASTER_IP=`/k8s/kubectl --namespace default get pod -o jsonpath='{range .items[*]}{.metadata.name} {.status.podIP}{"\n"}{end}' -l graylog-role=master --field-selector=status.phase=Running|awk '{print $2}'`
      SELF_IP=`/k8s/kubectl --namespace default get pod $HOSTNAME -o jsonpath='{.status.podIP}'`
      echo "Current master is $MASTER_IP"
      echo "Self IP is $SELF_IP"
      retry=$((retry+1))
      [[ ! -z "$MASTER_IP" ]] && break
      echo "[Try ${retry}/3] Waiting for master node..."
      sleep 2
    done
    if [[ -z "$MASTER_IP" ]]; then
      echo "Launching $HOSTNAME as master"
      export GRAYLOG_IS_MASTER="true"
      /k8s/kubectl --namespace default label --overwrite pod $HOSTNAME graylog-role="master"
    else
      # When container was recreated or restart, MASTER_IP == SELF_IP, running as master and no need to change label graylog-role="master"
      if [ "$SELF_IP" == "$MASTER_IP" ];then
        echo "Launching $HOSTNAME as master"
        export GRAYLOG_IS_MASTER="true"
      else
        # MASTER_IP != SELF_IP, running as coordinating
        echo "Launching $HOSTNAME as coordinating"
        export GRAYLOG_IS_MASTER="false"
        /k8s/kubectl --namespace default label --overwrite pod $HOSTNAME graylog-role="coordinating"
      fi
    fi
    # Download plugins
    # Start Graylog
    echo "Starting graylog"
    # Original docker-entrypoint.sh in Graylog Docker will error while executing since you can't chown readonly files in `config`
    # exec /docker-entrypoint.sh graylog
    export GRAYLOG_ELASTICSEARCH_VERSION=7
    echo "Graylog Home ${GRAYLOG_HOME}"
    echo "Graylog Plugin Dir ${GRAYLOG_PLUGIN_DIR}"
    echo "Graylog Elasticsearch Version ${GRAYLOG_ELASTICSEARCH_VERSION}"
    "${JAVA_HOME}/bin/java" \
      ${GRAYLOG_SERVER_JAVA_OPTS} \
      -jar \
      -Dlog4j.configurationFile=${GRAYLOG_HOME}/config/log4j2.xml \
      -Djava.library.path=${GRAYLOG_HOME}/lib/sigar/ \
      -Dgraylog2.installation_source=docker \
      ${GRAYLOG_HOME}/graylog.jar \
      server \
      -f ${GRAYLOG_HOME}/config/graylog.conf
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-graylog
  labels:
    app.kubernetes.io/name: graylog
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 4.2.7
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - secrets
    verbs:
      - get
      - list
      - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-graylog
  labels:
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: 4.2.7
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-graylog
subjects:
  - kind: ServiceAccount
    name: release-name-graylog
---
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-master
  labels:
    heritage: Helm
    release: release-name
    chart: elasticsearch
    app: elasticsearch-master
  annotations: {}
spec:
  type: ClusterIP
  selector:
    release: release-name
    chart: elasticsearch
    app: elasticsearch-master
  ports:
    - name: http
      protocol: TCP
      port: 9200
    - name: transport
      protocol: TCP
      port: 9300
---
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-master-headless
  labels:
    heritage: Helm
    release: release-name
    chart: elasticsearch
    app: elasticsearch-master
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app: elasticsearch-master
  ports:
    - name: http
      port: 9200
    - name: transport
      port: 9300
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-mongodb-arbiter-headless
  namespace: 8z3AUNsm4V3vQE
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.31.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: arbiter
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-mongodb
      port: 27017
      targetPort: mongodb
  selector:
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: arbiter
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-mongodb-headless
  namespace: 8z3AUNsm4V3vQE
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.31.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: mongodb
      port: 27017
      targetPort: mongodb
  selector:
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: mongodb
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-graylog
  labels:
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: 4.2.7
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  ports:
    - name: graylog
      port: 9000
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-graylog-master
  labels:
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: 4.2.7
    graylog-role: master
spec:
  ports:
    - name: graylog
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    graylog-role: master
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-graylog-web
  labels:
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: 4.2.7
    app.kubernetes.io/component: web
spec:
  ports:
    - name: graylog
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
  type: ClusterIP
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch-master
  labels:
    heritage: Helm
    release: release-name
    chart: elasticsearch
    app: elasticsearch-master
  annotations:
    esMajorVersion: "7"
spec:
  serviceName: elasticsearch-master-headless
  selector:
    matchLabels:
      app: elasticsearch-master
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
    - metadata:
        name: elasticsearch-master
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 8Gi
  template:
    metadata:
      name: elasticsearch-master
      labels:
        release: release-name
        chart: elasticsearch
        app: elasticsearch-master
      annotations: null
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - elasticsearch-master
      terminationGracePeriodSeconds: 120
      volumes: null
      enableServiceLinks: true
      initContainers:
        - name: configure-sysctl
          securityContext:
            runAsUser: 11376
            privileged: true
            capabilities:
              drop:
                "": NET_RAW
          image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2
          imagePullPolicy: IfNotPresent
          command:
            - sysctl
            - -w
            - vm.max_map_count=262144
          resources:
            seccompProfile:
              type: RuntimeDefault
      containers:
        - name: elasticsearch
          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 11436
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2
          imagePullPolicy: IfNotPresent
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - |
                  #!/usr/bin/env bash -e
                  # If the node is starting up wait for the cluster to be ready (request params: "wait_for_status=green&timeout=1s" )
                  # Once it has started only check that the node itself is responding
                  START_FILE=/tmp/.es_start_file

                  # Disable nss cache to avoid filling dentry cache when calling curl
                  # This is required with Elasticsearch Docker using nss < 3.52
                  export NSS_SDB_USE_CACHE=no

                  http () {
                    local path="${1}"
                    local args="${2}"
                    set -- -XGET -s

                    if [ "$args" != "" ]; then
                      set -- "$@" $args
                    fi

                    if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                      set -- "$@" -u "${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                    fi

                    curl --output /dev/null -k "$@" "http://127.0.0.1:9200${path}"
                  }

                  if [ -f "${START_FILE}" ]; then
                    echo 'Elasticsearch is already running, lets check the node is healthy'
                    HTTP_CODE=$(http "/" "-w %{http_code}")
                    RC=$?
                    if [[ ${RC} -ne 0 ]]; then
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with RC ${RC}"
                      exit ${RC}
                    fi
                    # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
                    if [[ ${HTTP_CODE} == "200" ]]; then
                      exit 0
                    elif [[ ${HTTP_CODE} == "503" && "7" == "6" ]]; then
                      exit 0
                    else
                      echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} http://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"
                      exit 1
                    fi

                  else
                    echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )'
                    if http "/_cluster/health?wait_for_status=green&timeout=1s" "--fail" ; then
                      touch ${START_FILE}
                      exit 0
                    else
                      echo 'Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )'
                      exit 1
                    fi
                  fi
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 3
            timeoutSeconds: 5
          ports:
            - name: http
              containerPort: 9200
            - name: transport
              containerPort: 9300
          resources:
            limits:
              cpu: 1000m
              memory: 512M
            requests:
              cpu: 100m
              memory: 512M
          env:
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: cluster.initial_master_nodes
              value: elasticsearch-master-0,
            - name: discovery.seed_hosts
              value: elasticsearch-master-headless
            - name: cluster.name
              value: elasticsearch
            - name: network.host
              value: 0.0.0.0
            - name: ES_JAVA_OPTS
              value: -Xmx128m -Xms128m
            - name: node.data
              value: "true"
            - name: node.ingest
              value: "true"
            - name: node.master
              value: "true"
            - name: node.remote_cluster_client
              value: "true"
          volumeMounts:
            - name: elasticsearch-master
              mountPath: /usr/share/elasticsearch/data
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-mongodb-arbiter
  namespace: 8z3AUNsm4V3vQE
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.31.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: arbiter
spec:
  serviceName: release-name-mongodb-arbiter-headless
  selector:
    matchLabels:
      app.kubernetes.io/name: mongodb
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: arbiter
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mongodb
        helm.sh/chart: mongodb-10.31.2
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: arbiter
    spec:
      serviceAccountName: release-name-mongodb
      affinity:
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: mongodb
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: arbiter
                namespaces:
                  - default
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity: null
      securityContext:
        fsGroup: 1001
        sysctls: []
      initContainers: null
      containers:
        - name: mongodb-arbiter
          image: docker.io/bitnami/mongodb:4.4.11-debian-10-r7
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 10030
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            readOnlyRootFilesystem: true
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: K8S_SERVICE_NAME
              value: release-name-mongodb-arbiter-headless
            - name: MONGODB_REPLICA_SET_MODE
              value: arbiter
            - name: MONGODB_INITIAL_PRIMARY_HOST
              value: release-name-mongodb-0.release-name-mongodb-headless.$(MY_POD_NAMESPACE).svc.cluster.local
            - name: MONGODB_REPLICA_SET_NAME
              value: rs0
            - name: MONGODB_ADVERTISED_HOSTNAME
              value: $(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
          ports:
            - containerPort: 27017
              name: mongodb
          livenessProbe:
            tcpSocket:
              port: mongodb
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            tcpSocket:
              port: mongodb
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          resources:
            limits: {}
            requests: {}
            seccompProfile:
              type: RuntimeDefault
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-mongodb
  namespace: 8z3AUNsm4V3vQE
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.31.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
spec:
  serviceName: release-name-mongodb-headless
  podManagementPolicy: OrderedReady
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: mongodb
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: mongodb
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mongodb
        helm.sh/chart: mongodb-10.31.2
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: mongodb
    spec:
      serviceAccountName: release-name-mongodb
      affinity:
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: mongodb
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: mongodb
                namespaces:
                  - default
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity: null
      securityContext:
        fsGroup: 1001
        sysctls: []
      containers:
        - name: mongodb
          image: docker.io/bitnami/mongodb:4.4.11-debian-10-r7
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsNonRoot: true
            runAsUser: 11824
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            readOnlyRootFilesystem: true
          command:
            - /scripts/setup.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: MY_POD_HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: K8S_SERVICE_NAME
              value: release-name-mongodb-headless
            - name: MONGODB_INITIAL_PRIMARY_HOST
              value: release-name-mongodb-0.$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local
            - name: MONGODB_REPLICA_SET_NAME
              value: rs0
            - name: MONGODB_ADVERTISED_HOSTNAME
              value: $(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: MONGODB_SYSTEM_LOG_VERBOSITY
              value: "0"
            - name: MONGODB_DISABLE_SYSTEM_LOG
              value: "no"
            - name: MONGODB_DISABLE_JAVASCRIPT
              value: "no"
            - name: MONGODB_ENABLE_JOURNAL
              value: "yes"
            - name: MONGODB_ENABLE_IPV6
              value: "no"
            - name: MONGODB_ENABLE_DIRECTORY_PER_DB
              value: "no"
          ports:
            - containerPort: 27017
              name: mongodb
          livenessProbe:
            exec:
              command:
                - mongo
                - --disableImplicitSessions
                - --eval
                - db.adminCommand('ping')
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - bash
                - -ec
                - |
                  # Run the proper check depending on the version
                  [[ $(mongo --version | grep "MongoDB shell") =~ ([0-9]+\.[0-9]+\.[0-9]+) ]] && VERSION=${BASH_REMATCH[1]}
                  . /opt/bitnami/scripts/libversion.sh
                  VERSION_MAJOR="$(get_sematic_version "$VERSION" 1)"
                  VERSION_MINOR="$(get_sematic_version "$VERSION" 2)"
                  VERSION_PATCH="$(get_sematic_version "$VERSION" 3)"
                  if [[ "$VERSION_MAJOR" -ge 4 ]] && [[ "$VERSION_MINOR" -ge 4 ]] && [[ "$VERSION_PATCH" -ge 2 ]]; then
                      mongo --disableImplicitSessions $TLS_OPTIONS --eval 'db.hello().isWritablePrimary || db.hello().secondary' | grep -q 'true'
                  else
                      mongo --disableImplicitSessions $TLS_OPTIONS --eval 'db.isMaster().ismaster || db.isMaster().secondary' | grep -q 'true'
                  fi
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          resources:
            limits: {}
            requests: {}
            seccompProfile:
              type: RuntimeDefault
          volumeMounts:
            - name: datadir
              mountPath: /bitnami/mongodb
              subPath: null
            - name: scripts
              mountPath: /scripts/setup.sh
              subPath: setup.sh
      volumes:
        - name: scripts
          configMap:
            name: release-name-mongodb-scripts
            defaultMode: 493
  volumeClaimTemplates:
    - metadata:
        name: datadir
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 8Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-graylog
  labels:
    helm.sh/chart: graylog-2.1.3
    app.kubernetes.io/name: graylog
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: 4.2.7
spec:
  serviceName: release-name-graylog
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: graylog
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/managed-by: Helm
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        helm.sh/chart: graylog-2.1.3
        app.kubernetes.io/name: graylog
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: 4.2.7
      annotations: null
    spec:
      serviceAccountName: release-name-graylog
      securityContext: {}
      initContainers:
        - name: setup
          image: alpine
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
            - -c
            - |
              rm -rf /usr/share/graylog/data/journal/lost+found
              wget https://storage.googleapis.com/kubernetes-release/release/v1.23.0/bin/linux/amd64/kubectl -O /k8s/kubectl
              chmod +x /k8s/kubectl

              GRAYLOG_HOME=/usr/share/graylog
              chown -R 1100:1100 ${GRAYLOG_HOME}/data/
          env: null
          volumeMounts:
            - name: journal
              mountPath: /usr/share/graylog/data/journal
            - name: kubectl
              mountPath: /k8s
      containers:
        - name: graylog-server
          image: graylog/graylog:4.2.3-1
          imagePullPolicy: IfNotPresent
          command:
            - /entrypoint.sh
          env:
            - name: GRAYLOG_SERVER_JAVA_OPTS
              value: -Dlog4j2.formatMsgNoLookups=true -Djdk.tls.acknowledgeCloseNotify=true -XX:+UnlockExperimentalVMOptions -XX:NewRatio=1 -XX:MaxMetaspaceSize=256m -server -XX:+ResizeTLAB -XX:-OmitStackTraceInFastThrow -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap
            - name: GRAYLOG_PASSWORD_SECRET
              valueFrom:
                secretKeyRef:
                  name: release-name-graylog
                  key: graylog-password-secret
            - name: GRAYLOG_ROOT_PASSWORD_SHA2
              valueFrom:
                secretKeyRef:
                  name: release-name-graylog
                  key: graylog-password-sha2
          securityContext:
            privileged: false
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            readOnlyRootFilesystem: true
          ports:
            - containerPort: 9000
              name: graylog
          resources:
            limits:
              cpu: "1"
            requests:
              cpu: 500m
              memory: 1024Mi
          startupProbe:
            httpGet:
              path: /api/system/lbstatus
              port: 9000
            periodSeconds: 60
            failureThreshold: 3
            successThreshold: 1
            timeoutSeconds: 5
          livenessProbe:
            httpGet:
              path: /api/system/lbstatus
              port: 9000
            initialDelaySeconds: 0
            periodSeconds: 30
            failureThreshold: 3
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /api/system/lbstatus
              port: 9000
            initialDelaySeconds: 0
            periodSeconds: 10
            failureThreshold: 3
            successThreshold: 1
            timeoutSeconds: 5
          volumeMounts:
            - name: journal
              mountPath: /usr/share/graylog/data/journal
            - name: config
              mountPath: /usr/share/graylog/config
            - name: entrypoint
              mountPath: /entrypoint.sh
              subPath: entrypoint.sh
            - name: kubectl
              mountPath: /k8s
      terminationGracePeriodSeconds: 120
      volumes:
        - name: config
          configMap:
            name: release-name-graylog
            items:
              - key: graylog.conf
                path: graylog.conf
                mode: 292
              - key: log4j2.xml
                path: log4j2.xml
                mode: 292
        - name: entrypoint
          configMap:
            name: release-name-graylog
            items:
              - key: entrypoint.sh
                path: entrypoint.sh
                mode: 365
        - name: kubectl
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: journal
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 20Gi
---
apiVersion: v1
kind: Pod
metadata:
  name: release-name-xyfsj-test
  annotations:
    helm.sh/hook: test
    helm.sh/hook-delete-policy: hook-succeeded
spec:
  securityContext:
    fsGroup: 1000
    runAsUser: 1000
  containers:
    - name: release-name-plyuj-test
      image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2
      imagePullPolicy: IfNotPresent
      command:
        - sh
        - -c
        - |
          #!/usr/bin/env bash -e
          curl -XGET --fail 'elasticsearch-master:9200/_cluster/health?wait_for_status=green&timeout=1s'
  restartPolicy: Never
