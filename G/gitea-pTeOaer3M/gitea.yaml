apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql-credentials
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 14.3.0
    helm-revision: "1"
    helm.sh/chart: postgresql-8.0.5
stringData:
  postgresql-password: testpass
  postgresql-postgres-password: testroot
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    helm.sh/chart: gitea-8.0.1
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    helm-revision: "1"
    app.kubernetes.io/version: 1.16.8
    app.kubernetes.io/managed-by: Helm
  name: dbcreds
data:
  postgresql-password: ZDNmb2JteWNmdW00MjJrREM0Tm5iUmxiQ2llZ09DTUNnZm5aczhnNGV3SExxb0dBeVU=
  postgresql-postgres-password: b25hSlA4TTVYSVRUU2RSRnFuNGU4UVY2ZUh4ZWxCb0xEU3REeXkxZGZNOFczVEx3OVM=
  url: cG9zdGdyZXNxbDovL2dpdGVhOmQzZm9ibXljZnVtNDIya0RDNE5uYlJsYkNpZWdPQ01DZ2ZuWnM4ZzRld0hMcW9HQXlVQHJlbGVhc2UtbmFtZS1wb3N0Z3Jlc3FsOjU0MzIvZ2l0ZWE=
  url-noql: cG9zdGdyZXM6Ly9naXRlYTpkM2ZvYm15Y2Z1bTQyMmtEQzRObmJSbGJDaWVnT0NNQ2dmblpzOGc0ZXdITHFvR0F5VUByZWxlYXNlLW5hbWUtcG9zdGdyZXNxbDo1NDMyL2dpdGVh
  urlnossl: cG9zdGdyZXNxbDovL2dpdGVhOmQzZm9ibXljZnVtNDIya0RDNE5uYlJsYkNpZWdPQ01DZ2ZuWnM4ZzRld0hMcW9HQXlVQHJlbGVhc2UtbmFtZS1wb3N0Z3Jlc3FsOjU0MzIvZ2l0ZWE/c3NsbW9kZT1kaXNhYmxl
  plainporthost: cmVsZWFzZS1uYW1lLXBvc3RncmVzcWw=
  plainhost: cmVsZWFzZS1uYW1lLXBvc3RncmVzcWw=
  jdbc: amRiYzpwb3N0Z3Jlc3FsOi8vcmVsZWFzZS1uYW1lLXBvc3RncmVzcWw6NTQzMi9naXRlYQ==
type: Opaque
---
apiVersion: v1
kind: Secret
metadata:
  name: release-name-gitea
  labels:
    helm.sh/chart: gitea-8.0.1
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    helm-revision: "1"
    app.kubernetes.io/version: 1.16.8
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  app.ini: |-
    APP_NAME = Gitea: Git with a cup of tea
    RUN_MODE = dev

    [cache]
    ADAPTER = memcache
    ENABLED = true
    HOST = release-name-memcached:11211

    [database]
    DB_TYPE = postgres
    HOST = release-name-postgresql:5432
    NAME = gitea
    PASSWD = "d3fobmycfum422kDC4NnbRlbCiegOCMCgfnZs8g4ewHLqoGAyU"
    USER = gitea

    [metrics]
    ENABLED = false

    [repository]
    ROOT = /data/git/gitea-repositories


    [security]
    INSTALL_LOCK = true

    [server]
    APP_DATA_PATH = /data
    DOMAIN = "release-name-gitea.default.svc.cluster.local"
    ENABLE_PPROF = false
    HTTP_PORT = 3000
    PROTOCOL = http
    ROOT_URL = http://"release-name-gitea.default.svc.cluster.local"
    SSH_DOMAIN = "release-name-gitea.default.svc.cluster.local"
    SSH_LISTEN_PORT = 2222
    SSH_PORT = 2222
    START_SSH_SERVER = true
---
apiVersion: v1
kind: Secret
metadata:
  name: release-name-gitea-init
  labels:
    helm.sh/chart: gitea-8.0.1
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    helm-revision: "1"
    app.kubernetes.io/version: 1.16.8
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    set -x

    mkdir -p /data/git/.ssh
    chmod -R 700 /data/git/.ssh
    [ ! -d /data/gitea ] && mkdir -p /data/gitea/conf

    # prepare temp directory structure
    mkdir -p "${GITEA_TEMP}"
    chown -Rf 1000:1000 "${GITEA_TEMP}"
    chmod ug+rwx "${GITEA_TEMP}"

    # Copy config file to writable volume
    cp /etc/gitea/conf/app.ini /data/gitea/conf/app.ini
    chown -Rf 1000:1000  "/data"
    chmod a+rwx /data/gitea/conf/app.ini

    # Patch dockercontainer for dynamic users
    chown -Rf 1000:1000  "/var/lib/gitea"
  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail


    # Connection retry inspired by https://gist.github.com/dublx/e99ea94858c07d2ca6de
    function test_db_connection() {
      local RETRY=0
      local MAX=30

      echo 'Wait for database to become avialable...'
      until [ "${RETRY}" -ge "${MAX}" ]; do
        nc -vz -w2 release-name-postgresql 5432 && break
        RETRY=$[${RETRY}+1]
        echo "...not ready yet (${RETRY}/${MAX})"
      done

      if [ "${RETRY}" -ge "${MAX}" ]; then
        echo "Database not reachable after '${MAX}' attempts!"
        exit 1
      fi
    }

    test_db_connection


    echo '==== BEGIN GITEA MIGRATION ===='

    gitea migrate

    echo '==== BEGIN GITEA CONFIGURATION ===='
    function configure_admin_user() {
      local ACCOUNT_ID=$(gitea admin user list --admin | grep -e "\s\+${GITEA_ADMIN_USERNAME}\s\+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create --admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "gitea@local.domain" --must-change-password=false
        echo '...created.'
      else
        echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
        gitea admin user change-password --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}"
        echo '...password sync done.'
      fi
    }

    configure_admin_user

    echo '==== END GITEA CONFIGURATION ===='
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gitea-env
data:
  GITEA_APP_INI: /data/gitea/conf/app.ini
  GITEA_CUSTOM: /data/gitea
  GITEA_WORK_DIR: /data
  GITEA_TEMP: /tmp/gitea
  GITEA_ADMIN_USERNAME: giteaadmin
  GITEA_ADMIN_PASSWORD: r8sA8CPHD9!bt6d
  SSH_PORT: "2222"
  SSH_LISTEN_PORT: "2222"
  TMPDIR: /tmp/gitea
  GNUPGHOME: /data/git/.gnupg
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name-gitea-data
  labels:
    helm.sh/chart: gitea-8.0.1
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    helm-revision: "1"
    app.kubernetes.io/version: 1.16.8
    app.kubernetes.io/managed-by: Helm
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 999Gi
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-memcached
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: memcached
    app.kubernetes.io/version: 1.6.15
    helm-revision: "1"
    helm.sh/chart: memcached-3.0.5
  annotations: null
spec:
  type: ClusterIP
  ipFamilyPolicy: SingleStack
  ports:
    - port: 11211
      targetPort: 11211
      protocol: TCP
      name: main
  selector:
    app.kubernetes.io/name: memcached
    app.kubernetes.io/instance: release-name
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 14.3.0
    helm-revision: "1"
    helm.sh/chart: postgresql-8.0.5
  annotations: null
spec:
  type: ClusterIP
  ipFamilyPolicy: SingleStack
  ports:
    - port: 5432
      targetPort: 5432
      protocol: TCP
      name: main
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-gitea
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gitea
    app.kubernetes.io/version: 1.16.8
    helm-revision: "1"
    helm.sh/chart: gitea-8.0.1
  annotations: null
spec:
  type: ClusterIP
  ipFamilyPolicy: SingleStack
  ports:
    - port: 10037
      targetPort: 3000
      protocol: TCP
      name: main
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-gitea-ssh
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gitea
    app.kubernetes.io/version: 1.16.8
    helm-revision: "1"
    helm.sh/chart: gitea-8.0.1
  annotations: null
spec:
  type: ClusterIP
  ports:
    - port: 2222
      targetPort: 2222
      protocol: TCP
      name: ssh
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-memcached
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: memcached
    app.kubernetes.io/version: 1.6.15
    helm-revision: "1"
    helm.sh/chart: memcached-3.0.5
spec:
  revisionHistoryLimit: 3
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: memcached
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations: null
      labels:
        app.kubernetes.io/name: memcached
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: default
      securityContext:
        fsGroup: 568
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 568
        runAsUser: 568
        supplementalGroups:
          - 568
      dnsPolicy: ClusterFirst
      dnsConfig:
        options:
          - name: ndots
            value: "1"
      enableServiceLinks: false
      terminationGracePeriodSeconds: 10
      initContainers:
        - name: autopermissions
          image: ghcr.io/truecharts/alpine:v3.15.2@sha256:29ed3480a0ee43f7af681fed5d4fc215516abf1c41eade6938b26d8c9c2c7583
          securityContext:
            runAsUser: 11549
            privileged: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          resources:
            limits:
              cpu: 4000m
              memory: 8Gi
            requests:
              cpu: 10m
              memory: 50Mi
          command:
            - /bin/sh
            - -c
            - |
              /bin/bash <<'EOF'
              echo "Automatically correcting permissions..."
              echo "increasing inotify limits..."
              ( sysctl -w fs.inotify.max_user_watches=524288 || echo "error setting inotify") && ( sysctl -w fs.inotify.max_user_instances=512 || echo "error setting inotify")
              EOF
          volumeMounts: null
      containers:
        - name: release-name-memcached
          image: ghcr.io/truecharts/memcached:v1.6.15@sha256:63e7a592d3052815084996150a0b42d5f19ffd194a97d73b8c46e2c44507fcad
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            privileged: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: PUID
              value: "568"
            - name: USER_ID
              value: "568"
            - name: UID
              value: "568"
            - name: UMASK
              value: "2"
            - name: UMASK_SET
              value: "2"
            - name: PGID
              value: "568"
            - name: GROUP_ID
              value: "568"
            - name: GID
              value: "568"
            - name: S6_READ_ONLY_ROOT
              value: "1"
            - name: NVIDIA_VISIBLE_DEVICES
              value: void
            - name: TZ
              value: UTC
          envFrom: null
          ports:
            - name: main
              containerPort: 11211
              protocol: TCP
          volumeMounts:
            - mountPath: /shared
              name: shared
            - mountPath: /tmp
              name: temp
            - mountPath: /var/logs
              name: varlogs
          livenessProbe:
            tcpSocket:
              port: 11211
            initialDelaySeconds: 10
            failureThreshold: 5
            timeoutSeconds: 5
            periodSeconds: 10
          readinessProbe:
            tcpSocket:
              port: 11211
            initialDelaySeconds: 10
            failureThreshold: 5
            timeoutSeconds: 5
            periodSeconds: 10
          startupProbe:
            tcpSocket:
              port: 11211
            initialDelaySeconds: 10
            failureThreshold: 60
            timeoutSeconds: 2
            periodSeconds: 5
          resources:
            limits:
              cpu: 4000m
              memory: 8Gi
            requests:
              cpu: 10m
              memory: 50Mi
      volumes:
        - name: shared
          emptyDir: {}
        - name: temp
          emptyDir:
            medium: Memory
        - name: varlogs
          emptyDir: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-gitea
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gitea
    app.kubernetes.io/version: 1.16.8
    helm-revision: "1"
    helm.sh/chart: gitea-8.0.1
spec:
  revisionHistoryLimit: 3
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations: null
      labels:
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: default
      securityContext:
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 1000
        runAsUser: 1000
        supplementalGroups:
          - 568
      dnsPolicy: ClusterFirst
      dnsConfig:
        options:
          - name: ndots
            value: "1"
      enableServiceLinks: false
      terminationGracePeriodSeconds: 10
      initContainers:
        - name: autopermissions
          image: ghcr.io/truecharts/alpine:v3.15.2@sha256:29ed3480a0ee43f7af681fed5d4fc215516abf1c41eade6938b26d8c9c2c7583
          securityContext:
            runAsUser: 11678
            privileged: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          resources:
            limits:
              cpu: 4000m
              memory: 8Gi
            requests:
              cpu: 10m
              memory: 50Mi
          command:
            - /bin/sh
            - -c
            - |
              /bin/bash <<'EOF'
              echo "Automatically correcting permissions..."
              echo "increasing inotify limits..."
              ( sysctl -w fs.inotify.max_user_watches=524288 || echo "error setting inotify") && ( sysctl -w fs.inotify.max_user_instances=512 || echo "error setting inotify")
              EOF
          volumeMounts: null
        - name: postgresql-init
          image: ghcr.io/truecharts/postgresql:v14.3.0@sha256:a05700459c7d20acebb13edfe713174cccbdb63c727f8a6cd421be8592b172a4
          securityContext:
            capabilities:
              drop:
                - ALL
          resources:
            limits:
              cpu: 4000m
              memory: 8Gi
            requests:
              cpu: 10m
              memory: 50Mi
          command:
            - sh
            - -c
            - until pg_isready -U gitea -h release-name-postgresql; do sleep 2 ; done
          imagePullPolicy: IfNotPresent
        - command:
            - /usr/sbin/init_directory_structure.sh
          envFrom:
            - configMapRef:
                name: gitea-env
          image: tccr.io/truecharts/gitea:v1.16.8@sha256:41322049f68a361e463ba1137574d380922a32719976fab0145fa0a78d32bbf3
          name: 1-init-directories
          securityContext:
            runAsNonRoot: false
            runAsUser: 0
          volumeMounts:
            - mountPath: /usr/sbin
              name: init
            - mountPath: /tmp
              name: temp
            - mountPath: /etc/gitea/conf
              name: config
            - mountPath: /data
              name: data
        - command:
            - /usr/sbin/configure_gitea.sh
          envFrom:
            - configMapRef:
                name: gitea-env
          image: tccr.io/truecharts/gitea:v1.16.8@sha256:41322049f68a361e463ba1137574d380922a32719976fab0145fa0a78d32bbf3
          name: 2-configure-gitea
          volumeMounts:
            - mountPath: /usr/sbin
              name: init
            - mountPath: /tmp
              name: temp
            - mountPath: /data
              name: data
      containers:
        - name: release-name-gitea
          image: tccr.io/truecharts/gitea:v1.16.8@sha256:41322049f68a361e463ba1137574d380922a32719976fab0145fa0a78d32bbf3
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            privileged: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
          env:
            - name: PUID
              value: "568"
            - name: USER_ID
              value: "568"
            - name: UID
              value: "568"
            - name: UMASK
              value: "2"
            - name: UMASK_SET
              value: "2"
            - name: PGID
              value: "1000"
            - name: GROUP_ID
              value: "1000"
            - name: GID
              value: "1000"
            - name: S6_READ_ONLY_ROOT
              value: "1"
            - name: NVIDIA_VISIBLE_DEVICES
              value: void
            - name: TZ
              value: UTC
          envFrom:
            - configMapRef:
                name: gitea-env
          ports:
            - name: main
              containerPort: 3000
              protocol: TCP
            - name: ssh
              containerPort: 2222
              protocol: TCP
          volumeMounts:
            - mountPath: /secrets/config
              name: config
              readOnly: true
            - mountPath: /data
              name: data
            - mountPath: /secrets/ini
              name: init
              readOnly: true
            - mountPath: /shared
              name: shared
            - mountPath: /tmp
              name: temp
            - mountPath: /var/lib/gitea
              name: varlib
            - mountPath: /var/logs
              name: varlogs
          livenessProbe:
            tcpSocket:
              port: 3000
            initialDelaySeconds: 10
            failureThreshold: 5
            timeoutSeconds: 5
            periodSeconds: 10
          readinessProbe:
            tcpSocket:
              port: 3000
            initialDelaySeconds: 10
            failureThreshold: 5
            timeoutSeconds: 5
            periodSeconds: 10
          startupProbe:
            tcpSocket:
              port: 3000
            initialDelaySeconds: 10
            failureThreshold: 60
            timeoutSeconds: 2
            periodSeconds: 5
          resources:
            limits:
              cpu: 4000m
              memory: 8Gi
            requests:
              cpu: 10m
              memory: 50Mi
      volumes:
        - name: config
          secret:
            secretName: release-name-gitea
        - name: data
          persistentVolumeClaim:
            claimName: release-name-gitea-data
        - name: init
          secret:
            defaultMode: 511
            secretName: release-name-gitea-init
        - name: shared
          emptyDir: {}
        - name: temp
          emptyDir:
            medium: Memory
        - name: varlib
          emptyDir: {}
        - name: varlogs
          emptyDir: {}
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 14.3.0
    helm-revision: "1"
    helm.sh/chart: postgresql-8.0.5
spec:
  revisionHistoryLimit: 3
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: release-name
  serviceName: release-name-postgresql
  template:
    metadata:
      labels:
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: default
      securityContext:
        fsGroup: 568
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 0
        runAsUser: 568
        supplementalGroups:
          - 568
      dnsPolicy: ClusterFirst
      dnsConfig:
        options:
          - name: ndots
            value: "1"
      enableServiceLinks: false
      terminationGracePeriodSeconds: 10
      initContainers:
        - name: autopermissions
          image: ghcr.io/truecharts/alpine:v3.15.2@sha256:29ed3480a0ee43f7af681fed5d4fc215516abf1c41eade6938b26d8c9c2c7583
          securityContext:
            runAsUser: 10795
            privileged: true
            allowPrivilegeEscalation: false
          resources:
            limits:
              cpu: 4000m
              memory: 8Gi
            requests:
              cpu: 10m
              memory: 50Mi
          command:
            - /bin/sh
            - -c
            - |
              /bin/bash <<'EOF'
              echo "Automatically correcting permissions..."
              echo "increasing inotify limits..."
              ( sysctl -w fs.inotify.max_user_watches=524288 || echo "error setting inotify") && ( sysctl -w fs.inotify.max_user_instances=512 || echo "error setting inotify")
              EOF
          volumeMounts: null
      containers:
        - name: release-name-postgresql
          image: ghcr.io/truecharts/postgresql:v14.3.0@sha256:a05700459c7d20acebb13edfe713174cccbdb63c727f8a6cd421be8592b172a4
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            privileged: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: PUID
              value: "568"
            - name: USER_ID
              value: "568"
            - name: UID
              value: "568"
            - name: UMASK
              value: "2"
            - name: UMASK_SET
              value: "2"
            - name: PGID
              value: "568"
            - name: GROUP_ID
              value: "568"
            - name: GID
              value: "568"
            - name: S6_READ_ONLY_ROOT
              value: "1"
            - name: NVIDIA_VISIBLE_DEVICES
              value: void
            - name: TZ
              value: UTC
            - name: POSTGRESQL_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: postgresql-postgres-password
                  name: dbcreds
            - name: POSTGRES_DB
              value: gitea
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: postgresql-password
                  name: dbcreds
            - name: POSTGRES_USER
              value: gitea
          envFrom: null
          ports:
            - name: main
              containerPort: 5432
              protocol: TCP
          volumeMounts:
            - mountPath: /shared
              name: shared
            - mountPath: /tmp
              name: temp
            - mountPath: /var/logs
              name: varlogs
            - mountPath: /bitnami/postgresql
              name: db
          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - until pg_isready -U ${POSTGRES_USER} -h localhost; do sleep 2 ; done
            failureThreshold: 5
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - until pg_isready -U ${POSTGRES_USER} -h localhost; do sleep 2 ; done
            failureThreshold: 5
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
          startupProbe:
            exec:
              command:
                - sh
                - -c
                - until pg_isready -U ${POSTGRES_USER} -h localhost; do sleep 2 ; done
            failureThreshold: 60
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 2
          resources:
            limits:
              cpu: 4000m
              memory: 8Gi
            requests:
              cpu: 10m
              memory: 50Mi
      volumes:
        - name: shared
          emptyDir: {}
        - name: temp
          emptyDir:
            medium: Memory
        - name: varlogs
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: db
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 999Gi
