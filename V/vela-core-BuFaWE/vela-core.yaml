apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-vela-core
  labels:
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: vela-addon-registry
  namespace: BuFaWE
data:
  registries: '{ "KubeVela":{ "name": "KubeVela", "helm": { "url": "https://addons.kubevela.net" } } }'
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: service-applied-resources-view
  namespace: BuFaWE
data:
  template: |
    import (
        "vela/ql"
    )
    parameter: {
        appName:    string
        appNs:      string
        name?:      string
        cluster?:   string
        clusterNs?: string
    }
    response: ql.#ListAppliedResources & {
        app: {
            name:      parameter.appName
            namespace: parameter.appNs
            filter: {
                if parameter.cluster != _|_ {
                    cluster: parameter.cluster
                }
                if parameter.clusterNs != _|_ {
                    clusterNamespace: parameter.clusterNs
                }
                if parameter.name != _|_ {
                    components: [parameter.name]
                }
            }
        }
    }
    if response.err == _|_ {
        status: {
            resources: response.list
        }
    }
    if response.err != _|_ {
        status: {
            error: response.err
        }
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: service-endpoints-view
  namespace: BuFaWE
data:
  template: |
    import (
        "vela/ql"
    )
    parameter: {
        appName:    string
        appNs:      string
        name?:      string
        cluster?:   string
        clusterNs?: string
    }
    resources: ql.#CollectServiceEndpoints & {
        app: {
            name:      parameter.appName
            namespace: parameter.appNs
            filter: {
                if parameter.cluster != _|_ {
                    cluster: parameter.cluster
                }
                if parameter.clusterNs != _|_ {
                    clusterNamespace: parameter.clusterNs
                }
                if parameter.name != _|_ {
                    components: [parameter.name]
                }
            }
        }
    }
    if resources.err == _|_ {
        status: {
            endpoints: resources.list
        }
    }
    if resources.err != _|_ {
        status: {
            error: resources.err
        }
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: application-resource-tree-view
  namespace: BuFaWE
data:
  template: |
    import (
        "vela/ql"
    )
    parameter: {
        appName:    string
        appNs:      string
        name?:      string
        cluster?:   string
        clusterNs?: string
    }
    response: ql.#GetApplicationTree & {
        app: {
            name:      parameter.appName
            namespace: parameter.appNs
            filter: {
                if parameter.cluster != _|_ {
                    cluster: parameter.cluster
                }
                if parameter.clusterNs != _|_ {
                    clusterNamespace: parameter.clusterNs
                }
                if parameter.name != _|_ {
                    components: [parameter.name]
                }
            }
        }
    }

    if response.err == _|_ {
        status: {
            resources: response.list
        }
    }
    if response.err != _|_ {
        status: {
            error: response.err
        }
    }
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-vela-core:cluster-gateway:proxy
rules:
  - apiGroups:
      - cluster.core.oam.dev
    resources:
      - clustergateways/proxy
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-vela-core:cluster-gateway:proxy
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-vela-core:cluster-gateway:proxy
subjects:
  - kind: Group
    name: kubevela:client
    apiGroup: rbac.authorization.k8s.io
  - kind: ServiceAccount
    name: release-name-vela-core
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-vela-core:manager-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: release-name-vela-core
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-vela-core:leader-election-role
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - ""
    resources:
      - configmaps/status
    verbs:
      - get
      - update
      - patch
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-vela-core:leader-election-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-vela-core:leader-election-role
subjects:
  - kind: ServiceAccount
    name: release-name-vela-core
---
apiVersion: v1
kind: Service
metadata:
  name: vela-core-webhook
  namespace: BuFaWE
  labels:
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 443
      targetPort: 9443
      protocol: TCP
      name: https
  selector:
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-cluster-gateway-service
  namespace: BuFaWE
spec:
  selector:
    app.kubernetes.io/name: vela-core-cluster-gateway
    app.kubernetes.io/instance: release-name-cluster-gateway
  ports:
    - protocol: TCP
      port: 9443
      targetPort: 9443
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-cluster-gateway
  namespace: BuFaWE
  labels:
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: vela-core-cluster-gateway
      app.kubernetes.io/instance: release-name-cluster-gateway
  template:
    metadata:
      labels:
        app.kubernetes.io/name: vela-core-cluster-gateway
        app.kubernetes.io/instance: release-name-cluster-gateway
    spec:
      serviceAccountName: release-name-vela-core
      securityContext: {}
      containers:
        - name: release-name-vela-core-cluster-gateway
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            readOnlyRootFilesystem: true
            seccompProfile:
              type: RuntimeDefault
          args:
            - apiserver
            - --secure-port=9443
            - --secret-namespace=default
            - --feature-gates=APIPriorityAndFairness=false,ClientIdentityPenetration=false
            - --tls-cert-file=/etc/k8s-cluster-gateway-certs/tls.crt
            - --tls-private-key-file=/etc/k8s-cluster-gateway-certs/tls.key
          image: oamdev/cluster-gateway:v1.4.0
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 100m
              memory: 200Mi
          ports:
            - containerPort: 9443
          volumeMounts:
            - mountPath: /etc/k8s-cluster-gateway-certs
              name: tls-cert-vol
              readOnly: true
      volumes:
        - name: tls-cert-vol
          secret:
            defaultMode: 420
            secretName: release-name-vela-core-cluster-gateway-tls-v2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-vela-core
  namespace: BuFaWE
  labels:
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: vela-core
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: vela-core
        app.kubernetes.io/instance: release-name
      annotations:
        prometheus.io/path: /metrics
        prometheus.io/port: "8080"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: release-name-vela-core
      securityContext: {}
      containers:
        - name: release-name
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            readOnlyRootFilesystem: true
            seccompProfile:
              type: RuntimeDefault
          args:
            - --metrics-addr=:8080
            - --enable-leader-election
            - --use-webhook=true
            - --webhook-port=9443
            - --webhook-cert-dir=/etc/k8s-webhook-certs
            - --optimize-mark-with-prob=0.1
            - --health-addr=:9440
            - --disable-caps=rollout
            - --system-definition-namespace=default
            - --application-revision-limit=10
            - --definition-revision-limit=20
            - --oam-spec-ver=v0.3
            - --enable-cluster-gateway
            - --application-re-sync-period=5m
            - --concurrent-reconciles=4
            - --kube-api-qps=50
            - --kube-api-burst=100
            - --max-workflow-wait-backoff-time=60
            - --max-workflow-failed-backoff-time=300
            - --max-workflow-step-error-retry-times=10
            - --feature-gates=EnableSuspendOnFailure=false
            - --feature-gates=AuthenticateApplication=false
          image: oamdev/vela-core:v1.4.1
          imagePullPolicy: Always
          resources:
            limits:
              cpu: 500m
              memory: 1Gi
            requests:
              cpu: 50m
              memory: 20Mi
          ports:
            - containerPort: 9443
              name: webhook-server
              protocol: TCP
            - containerPort: 9440
              name: healthz
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /readyz
              port: healthz
            initialDelaySeconds: 30
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /healthz
              port: healthz
            initialDelaySeconds: 90
            periodSeconds: 5
          volumeMounts:
            - mountPath: /etc/k8s-webhook-certs
              name: tls-cert-vol
              readOnly: true
      volumes:
        - name: tls-cert-vol
          secret:
            defaultMode: 420
            secretName: release-name-vela-core-admission
---
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: v1alpha1.cluster.core.oam.dev
  annotations: null
  labels:
    api: cluster-extension-apiserver
    apiserver: "true"
spec:
  version: v1alpha1
  group: cluster.core.oam.dev
  groupPriorityMinimum: 2000
  service:
    name: release-name-cluster-gateway-service
    namespace: default
    port: 9443
  versionPriority: 10
  insecureSkipTLSVerify: false
  caBundle: Cg==
---
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    custom.definition.oam.dev/alias.config.oam.dev: Image Registry
    definition.oam.dev/description: Config information to authenticate image registry
  labels:
    custom.definition.oam.dev/catalog.config.oam.dev: velacore-config
    custom.definition.oam.dev/multi-cluster.config.oam.dev: "true"
    custom.definition.oam.dev/type.config.oam.dev: image-registry
    custom.definition.oam.dev/ui-hidden: "true"
  name: config-image-registry
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"encoding/base64"
        	"encoding/json"
        )

        output: {
        	apiVersion: "v1"
        	kind:       "Secret"
        	metadata: {
        		name:      context.name
        		namespace: context.namespace
        		labels: {
        			"config.oam.dev/catalog":       "velacore-config"
        			"config.oam.dev/type":          "image-registry"
        			"config.oam.dev/multi-cluster": "true"
        			"config.oam.dev/identifier":    parameter.registry
        			"config.oam.dev/sub-type":      "auth"
        		}
        	}
        	if parameter.auth != _|_ {
        		type: "kubernetes.io/dockerconfigjson"
        	}
        	if parameter.auth == _|_ {
        		type: "Opaque"
        	}
        	if parameter.auth != _|_ {
        		stringData: ".dockerconfigjson": json.Marshal({
        			auths: "\(parameter.registry)": {
        				username: parameter.auth.username
        				password: parameter.auth.password
        				if parameter.auth.email != _|_ {
        					email: parameter.auth.email
        				}
        				auth: base64.Encode(null, (parameter.auth.username + ":" + parameter.auth.password))
        			}
        		})
        	}
        }
        parameter: {
        	// +usage=Image registry FQDN
        	registry: string
        	// +usage=Authenticate the image registry
        	auth?: {
        		// +usage=Private Image registry username
        		username: string
        		// +usage=Private Image registry password
        		password: string
        		// +usage=Private Image registry email
        		email?: string
        	}
        }
  workload:
    type: autodetects.core.oam.dev
---
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    definition.oam.dev/description: Describes cron jobs that run code or a script to completion.
  name: cron-task
  namespace: default
spec:
  schematic:
    cue:
      template: |
        output: {
        	apiVersion: "batch/v1beta1"
        	kind:       "CronJob"
        	spec: {
        		schedule:                   parameter.schedule
        		concurrencyPolicy:          parameter.concurrencyPolicy
        		suspend:                    parameter.suspend
        		successfulJobsHistoryLimit: parameter.successfulJobsHistoryLimit
        		failedJobsHistoryLimit:     parameter.failedJobsHistoryLimit
        		if parameter.startingDeadlineSeconds != _|_ {
        			startingDeadlineSeconds: parameter.startingDeadlineSeconds
        		}
        		jobTemplate: {
        			metadata: {
        				labels: {
        					if parameter.labels != _|_ {
        						parameter.labels
        					}
        					"app.oam.dev/name":      context.appName
        					"app.oam.dev/component": context.name
        				}
        				if parameter.annotations != _|_ {
        					annotations: parameter.annotations
        				}
        			}
        			spec: {
        				parallelism: parameter.count
        				completions: parameter.count
        				if parameter.ttlSecondsAfterFinished != _|_ {
        					ttlSecondsAfterFinished: parameter.ttlSecondsAfterFinished
        				}
        				if parameter.activeDeadlineSeconds != _|_ {
        					activeDeadlineSeconds: parameter.activeDeadlineSeconds
        				}
        				backoffLimit: parameter.backoffLimit
        				template: {
        					metadata: {
        						labels: {
        							if parameter.labels != _|_ {
        								parameter.labels
        							}
        							"app.oam.dev/name":      context.appName
        							"app.oam.dev/component": context.name
        						}
        						if parameter.annotations != _|_ {
        							annotations: parameter.annotations
        						}
        					}
        					spec: {
        						restartPolicy: parameter.restart
        						containers: [{
        							name:  context.name
        							image: parameter.image
        							if parameter["imagePullPolicy"] != _|_ {
        								imagePullPolicy: parameter.imagePullPolicy
        							}
        							if parameter["cmd"] != _|_ {
        								command: parameter.cmd
        							}
        							if parameter["env"] != _|_ {
        								env: parameter.env
        							}
        							if parameter["cpu"] != _|_ {
        								resources: {
        									limits: cpu:   parameter.cpu
        									requests: cpu: parameter.cpu
        								}
        							}
        							if parameter["memory"] != _|_ {
        								resources: {
        									limits: memory:   parameter.memory
        									requests: memory: parameter.memory
        								}
        							}
        							if parameter["volumes"] != _|_ {
        								volumeMounts: [ for v in parameter.volumes {
        									{
        										mountPath: v.mountPath
        										name:      v.name
        									}}]
        							}
        						}]
        						if parameter["volumes"] != _|_ {
        							volumes: [ for v in parameter.volumes {
        								{
        									name: v.name
        									if v.type == "pvc" {
        										persistentVolumeClaim: claimName: v.claimName
        									}
        									if v.type == "configMap" {
        										configMap: {
        											defaultMode: v.defaultMode
        											name:        v.cmName
        											if v.items != _|_ {
        												items: v.items
        											}
        										}
        									}
        									if v.type == "secret" {
        										secret: {
        											defaultMode: v.defaultMode
        											secretName:  v.secretName
        											if v.items != _|_ {
        												items: v.items
        											}
        										}
        									}
        									if v.type == "emptyDir" {
        										emptyDir: medium: v.medium
        									}
        								}}]
        						}
        						if parameter["imagePullSecrets"] != _|_ {
        							imagePullSecrets: [ for v in parameter.imagePullSecrets {
        								name: v
        							},
        							]
        						}
        						if parameter.hostAliases != _|_ {
        							hostAliases: [ for v in parameter.hostAliases {
        								ip:        v.ip
        								hostnames: v.hostnames
        							},
        							]
        						}
        					}
        				}
        			}
        		}
        	}
        }
        parameter: {
        	// +usage=Specify the labels in the workload
        	labels?: [string]: string

        	// +usage=Specify the annotations in the workload
        	annotations?: [string]: string

        	// +usage=Specify the schedule in Cron format, see https://en.wikipedia.org/wiki/Cron
        	schedule: string

        	// +usage=Specify deadline in seconds for starting the job if it misses scheduled
        	startingDeadlineSeconds?: int

        	// +usage=suspend subsequent executions
        	suspend: *false | bool

        	// +usage=Specifies how to treat concurrent executions of a Job
        	concurrencyPolicy: *"Allow" | "Allow" | "Forbid" | "Replace"

        	// +usage=The number of successful finished jobs to retain
        	successfulJobsHistoryLimit: *3 | int

        	// +usage=The number of failed finished jobs to retain
        	failedJobsHistoryLimit: *1 | int

        	// +usage=Specify number of tasks to run in parallel
        	// +short=c
        	count: *1 | int

        	// +usage=Which image would you like to use for your service
        	// +short=i
        	image: string

        	// +usage=Specify image pull policy for your service
        	imagePullPolicy?: "Always" | "Never" | "IfNotPresent"

        	// +usage=Specify image pull secrets for your service
        	imagePullSecrets?: [...string]

        	// +usage=Define the job restart policy, the value can only be Never or OnFailure. By default, it's Never.
        	restart: *"Never" | string

        	// +usage=Commands to run in the container
        	cmd?: [...string]

        	// +usage=Define arguments by using environment variables
        	env?: [...{
        		// +usage=Environment variable name
        		name: string
        		// +usage=The value of the environment variable
        		value?: string
        		// +usage=Specifies a source the value of this var should come from
        		valueFrom?: {
        			// +usage=Selects a key of a secret in the pod's namespace
        			secretKeyRef: {
        				// +usage=The name of the secret in the pod's namespace to select from
        				name: string
        				// +usage=The key of the secret to select from. Must be a valid secret key
        				key: string
        			}
        			// +usage=Selects a key of a config map in the pod's namespace
        			configMapKeyRef: {
        				// +usage=The name of the config map in the pod's namespace to select from
        				name: string
        				// +usage=The key of the config map to select from. Must be a valid secret key
        				key: string
        			}
        		}
        	}]

        	// +usage=Number of CPU units for the service, like `0.5` (0.5 CPU core), `1` (1 CPU core)
        	cpu?: string

        	// +usage=Specifies the attributes of the memory resource required for the container.
        	memory?: string

        	// +usage=Declare volumes and volumeMounts
        	volumes?: [...{
        		name:      string
        		mountPath: string
        		// +usage=Specify volume type, options: "pvc","configMap","secret","emptyDir"
        		type: "pvc" | "configMap" | "secret" | "emptyDir"
        		if type == "pvc" {
        			claimName: string
        		}
        		if type == "configMap" {
        			defaultMode: *420 | int
        			cmName:      string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "secret" {
        			defaultMode: *420 | int
        			secretName:  string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "emptyDir" {
        			medium: *"" | "Memory"
        		}
        	}]

        	// +usage=An optional list of hosts and IPs that will be injected into the pod's hosts file
        	hostAliases?: [...{
        		ip: string
        		hostnames: [...string]
        	}]

        	// +usage=Limits the lifetime of a Job that has finished
        	ttlSecondsAfterFinished?: int

        	// +usage=The duration in seconds relative to the startTime that the job may be continuously active before the system tries to terminate it
        	activeDeadlineSeconds?: int

        	// +usage=The number of retries before marking this job failed
        	backoffLimit: *6 | int

        	// +usage=Instructions for assessing whether the container is alive.
        	livenessProbe?: #HealthProbe

        	// +usage=Instructions for assessing whether the container is in a suitable state to serve traffic.
        	readinessProbe?: #HealthProbe
        }
        #HealthProbe: {

        	// +usage=Instructions for assessing container health by executing a command. Either this attribute or the httpGet attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the httpGet attribute and the tcpSocket attribute.
        	exec?: {
        		// +usage=A command to be executed inside the container to assess its health. Each space delimited token of the command is a separate array element. Commands exiting 0 are considered to be successful probes, whilst all other exit codes are considered failures.
        		command: [...string]
        	}

        	// +usage=Instructions for assessing container health by executing an HTTP GET request. Either this attribute or the exec attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the tcpSocket attribute.
        	httpGet?: {
        		// +usage=The endpoint, relative to the port, to which the HTTP GET request should be directed.
        		path: string
        		// +usage=The TCP socket within the container to which the HTTP GET request should be directed.
        		port: int
        		httpHeaders?: [...{
        			name:  string
        			value: string
        		}]
        	}

        	// +usage=Instructions for assessing container health by probing a TCP socket. Either this attribute or the exec attribute or the httpGet attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the httpGet attribute.
        	tcpSocket?: {
        		// +usage=The TCP socket within the container that should be probed to assess container health.
        		port: int
        	}

        	// +usage=Number of seconds after the container is started before the first probe is initiated.
        	initialDelaySeconds: *0 | int

        	// +usage=How often, in seconds, to execute the probe.
        	periodSeconds: *10 | int

        	// +usage=Number of seconds after which the probe times out.
        	timeoutSeconds: *1 | int

        	// +usage=Minimum consecutive successes for the probe to be considered successful after having failed.
        	successThreshold: *1 | int

        	// +usage=Number of consecutive failures required to determine the container is not alive (liveness probe) or not ready (readiness probe).
        	failureThreshold: *3 | int
        }
  workload:
    definition:
      apiVersion: batch/v1beta1
      kind: CronJob
    type: cronjobs.batch
---
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    definition.oam.dev/description: K8s-objects allow users to specify raw K8s objects in properties
  name: k8s-objects
  namespace: default
spec:
  schematic:
    cue:
      template: |
        output: parameter.objects[0]
        outputs: {
        	for i, v in parameter.objects {
        		if i > 0 {
        			"objects-\(i)": v
        		}
        	}
        }
        parameter: objects: [...{}]
  workload:
    type: autodetects.core.oam.dev
---
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    definition.oam.dev/description: Raw allow users to specify raw K8s object in properties. This definition is DEPRECATED, please use 'k8s-objects' instead.
  labels:
    custom.definition.oam.dev/deprecated: "true"
  name: raw
  namespace: default
spec:
  schematic:
    cue:
      template: |
        output: parameter
        parameter: {}
  workload:
    type: autodetects.core.oam.dev
---
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    definition.oam.dev/description: Ref-objects allow users to specify ref objects to use. Notice that this component type have special handle logic.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: ref-objects
  namespace: default
spec:
  schematic:
    cue:
      template: |
        #K8sObject: {
        	apiVersion: string
        	kind:       string
        	metadata: {
        		name: string
        		...
        	}
        	...
        }
        output: parameter.objects[0]
        outputs: {
        	for i, v in parameter.objects {
        		if i > 0 {
        			"objects-\(i)": v
        		}
        	}
        }
        parameter: objects: [...#K8sObject]
  status:
    customStatus: |-
      if context.output.apiVersion == "apps/v1" && context.output.kind == "Deployment" {
      	ready: {
      		readyReplicas: *0 | int
      	} & {
      		if context.output.status.readyReplicas != _|_ {
      			readyReplicas: context.output.status.readyReplicas
      		}
      	}
      	message: "Ready:\(ready.readyReplicas)/\(context.output.spec.replicas)"
      }
      if context.output.apiVersion != "apps/v1" || context.output.kind != "Deployment" {
      	message: ""
      }
    healthPolicy: |-
      if context.output.apiVersion == "apps/v1" && context.output.kind == "Deployment" {
      	ready: {
      		updatedReplicas:    *0 | int
      		readyReplicas:      *0 | int
      		replicas:           *0 | int
      		observedGeneration: *0 | int
      	} & {
      		if context.output.status.updatedReplicas != _|_ {
      			updatedReplicas: context.output.status.updatedReplicas
      		}
      		if context.output.status.readyReplicas != _|_ {
      			readyReplicas: context.output.status.readyReplicas
      		}
      		if context.output.status.replicas != _|_ {
      			replicas: context.output.status.replicas
      		}
      		if context.output.status.observedGeneration != _|_ {
      			observedGeneration: context.output.status.observedGeneration
      		}
      	}
      	isHealth: (context.output.spec.replicas == ready.readyReplicas) && (context.output.spec.replicas == ready.updatedReplicas) && (context.output.spec.replicas == ready.replicas) && (ready.observedGeneration == context.output.metadata.generation || ready.observedGeneration > context.output.metadata.generation)
      }
      if context.output.apiVersion != "apps/v1" || context.output.kind != "Deployment" {
      	isHealth: true
      }
  workload:
    type: autodetects.core.oam.dev
---
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    definition.oam.dev/description: Describes jobs that run code or a script to completion.
  name: task
  namespace: default
spec:
  schematic:
    cue:
      template: |
        output: {
        	apiVersion: "batch/v1"
        	kind:       "Job"
        	spec: {
        		parallelism: parameter.count
        		completions: parameter.count
        		template: {
        			metadata: {
        				labels: {
        					if parameter.labels != _|_ {
        						parameter.labels
        					}
        					"app.oam.dev/name":      context.appName
        					"app.oam.dev/component": context.name
        				}
        				if parameter.annotations != _|_ {
        					annotations: parameter.annotations
        				}
        			}
        			spec: {
        				restartPolicy: parameter.restart
        				containers: [{
        					name:  context.name
        					image: parameter.image

        					if parameter["imagePullPolicy"] != _|_ {
        						imagePullPolicy: parameter.imagePullPolicy
        					}

        					if parameter["cmd"] != _|_ {
        						command: parameter.cmd
        					}

        					if parameter["env"] != _|_ {
        						env: parameter.env
        					}

        					if parameter["cpu"] != _|_ {
        						resources: {
        							limits: cpu:   parameter.cpu
        							requests: cpu: parameter.cpu
        						}
        					}

        					if parameter["memory"] != _|_ {
        						resources: {
        							limits: memory:   parameter.memory
        							requests: memory: parameter.memory
        						}
        					}

        					if parameter["volumes"] != _|_ {
        						volumeMounts: [ for v in parameter.volumes {
        							{
        								mountPath: v.mountPath
        								name:      v.name
        							}}]
        					}
        				}]

        				if parameter["volumes"] != _|_ {
        					volumes: [ for v in parameter.volumes {
        						{
        							name: v.name
        							if v.type == "pvc" {
        								persistentVolumeClaim: claimName: v.claimName
        							}
        							if v.type == "configMap" {
        								configMap: {
        									defaultMode: v.defaultMode
        									name:        v.cmName
        									if v.items != _|_ {
        										items: v.items
        									}
        								}
        							}
        							if v.type == "secret" {
        								secret: {
        									defaultMode: v.defaultMode
        									secretName:  v.secretName
        									if v.items != _|_ {
        										items: v.items
        									}
        								}
        							}
        							if v.type == "emptyDir" {
        								emptyDir: medium: v.medium
        							}
        						}}]
        				}

        				if parameter["imagePullSecrets"] != _|_ {
        					imagePullSecrets: [ for v in parameter.imagePullSecrets {
        						name: v
        					},
        					]
        				}

        			}
        		}
        	}
        }
        parameter: {
        	// +usage=Specify the labels in the workload
        	labels?: [string]: string

        	// +usage=Specify the annotations in the workload
        	annotations?: [string]: string

        	// +usage=Specify number of tasks to run in parallel
        	// +short=c
        	count: *1 | int

        	// +usage=Which image would you like to use for your service
        	// +short=i
        	image: string

        	// +usage=Specify image pull policy for your service
        	imagePullPolicy?: "Always" | "Never" | "IfNotPresent"

        	// +usage=Specify image pull secrets for your service
        	imagePullSecrets?: [...string]

        	// +usage=Define the job restart policy, the value can only be Never or OnFailure. By default, it's Never.
        	restart: *"Never" | string

        	// +usage=Commands to run in the container
        	cmd?: [...string]

        	// +usage=Define arguments by using environment variables
        	env?: [...{
        		// +usage=Environment variable name
        		name: string
        		// +usage=The value of the environment variable
        		value?: string
        		// +usage=Specifies a source the value of this var should come from
        		valueFrom?: {
        			// +usage=Selects a key of a secret in the pod's namespace
        			secretKeyRef: {
        				// +usage=The name of the secret in the pod's namespace to select from
        				name: string
        				// +usage=The key of the secret to select from. Must be a valid secret key
        				key: string
        			}
        			// +usage=Selects a key of a config map in the pod's namespace
        			configMapKeyRef: {
        				// +usage=The name of the config map in the pod's namespace to select from
        				name: string
        				// +usage=The key of the config map to select from. Must be a valid secret key
        				key: string
        			}
        		}
        	}]

        	// +usage=Number of CPU units for the service, like `0.5` (0.5 CPU core), `1` (1 CPU core)
        	cpu?: string

        	// +usage=Specifies the attributes of the memory resource required for the container.
        	memory?: string

        	// +usage=Declare volumes and volumeMounts
        	volumes?: [...{
        		name:      string
        		mountPath: string
        		// +usage=Specify volume type, options: "pvc","configMap","secret","emptyDir"
        		type: "pvc" | "configMap" | "secret" | "emptyDir"
        		if type == "pvc" {
        			claimName: string
        		}
        		if type == "configMap" {
        			defaultMode: *420 | int
        			cmName:      string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "secret" {
        			defaultMode: *420 | int
        			secretName:  string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "emptyDir" {
        			medium: *"" | "Memory"
        		}
        	}]

        	// +usage=Instructions for assessing whether the container is alive.
        	livenessProbe?: #HealthProbe

        	// +usage=Instructions for assessing whether the container is in a suitable state to serve traffic.
        	readinessProbe?: #HealthProbe
        }
        #HealthProbe: {

        	// +usage=Instructions for assessing container health by executing a command. Either this attribute or the httpGet attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the httpGet attribute and the tcpSocket attribute.
        	exec?: {
        		// +usage=A command to be executed inside the container to assess its health. Each space delimited token of the command is a separate array element. Commands exiting 0 are considered to be successful probes, whilst all other exit codes are considered failures.
        		command: [...string]
        	}

        	// +usage=Instructions for assessing container health by executing an HTTP GET request. Either this attribute or the exec attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the tcpSocket attribute.
        	httpGet?: {
        		// +usage=The endpoint, relative to the port, to which the HTTP GET request should be directed.
        		path: string
        		// +usage=The TCP socket within the container to which the HTTP GET request should be directed.
        		port: int
        		httpHeaders?: [...{
        			name:  string
        			value: string
        		}]
        	}

        	// +usage=Instructions for assessing container health by probing a TCP socket. Either this attribute or the exec attribute or the httpGet attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the httpGet attribute.
        	tcpSocket?: {
        		// +usage=The TCP socket within the container that should be probed to assess container health.
        		port: int
        	}

        	// +usage=Number of seconds after the container is started before the first probe is initiated.
        	initialDelaySeconds: *0 | int

        	// +usage=How often, in seconds, to execute the probe.
        	periodSeconds: *10 | int

        	// +usage=Number of seconds after which the probe times out.
        	timeoutSeconds: *1 | int

        	// +usage=Minimum consecutive successes for the probe to be considered successful after having failed.
        	successThreshold: *1 | int

        	// +usage=Number of consecutive failures required to determine the container is not alive (liveness probe) or not ready (readiness probe).
        	failureThreshold: *3 | int
        }
  status:
    customStatus: |-
      status: {
      	active:    *0 | int
      	failed:    *0 | int
      	succeeded: *0 | int
      } & {
      	if context.output.status.active != _|_ {
      		active: context.output.status.active
      	}
      	if context.output.status.failed != _|_ {
      		failed: context.output.status.failed
      	}
      	if context.output.status.succeeded != _|_ {
      		succeeded: context.output.status.succeeded
      	}
      }
      message: "Active/Failed/Succeeded:\(status.active)/\(status.failed)/\(status.succeeded)"
    healthPolicy: |-
      succeeded: *0 | int
      if context.output.status.succeeded != _|_ {
      	succeeded: context.output.status.succeeded
      }
      isHealth: succeeded == context.output.spec.parallelism
  workload:
    definition:
      apiVersion: batch/v1
      kind: Job
    type: jobs.batch
---
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    definition.oam.dev/description: Describes long-running, scalable, containerized services that have a stable network endpoint to receive external network traffic from customers.
  name: webservice
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"strconv"
        )

        mountsArray: {
        	pvc: *[
        		for v in parameter.volumeMounts.pvc {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []

        	configMap: *[
        			for v in parameter.volumeMounts.configMap {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []

        	secret: *[
        		for v in parameter.volumeMounts.secret {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []

        	emptyDir: *[
        			for v in parameter.volumeMounts.emptyDir {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []

        	hostPath: *[
        			for v in parameter.volumeMounts.hostPath {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []
        }
        volumesArray: {
        	pvc: *[
        		for v in parameter.volumeMounts.pvc {
        			{
        				name: v.name
        				persistentVolumeClaim: claimName: v.claimName
        			}
        		},
        	] | []

        	configMap: *[
        			for v in parameter.volumeMounts.configMap {
        			{
        				name: v.name
        				configMap: {
        					defaultMode: v.defaultMode
        					name:        v.cmName
        					if v.items != _|_ {
        						items: v.items
        					}
        				}
        			}
        		},
        	] | []

        	secret: *[
        		for v in parameter.volumeMounts.secret {
        			{
        				name: v.name
        				secret: {
        					defaultMode: v.defaultMode
        					secretName:  v.secretName
        					if v.items != _|_ {
        						items: v.items
        					}
        				}
        			}
        		},
        	] | []

        	emptyDir: *[
        			for v in parameter.volumeMounts.emptyDir {
        			{
        				name: v.name
        				emptyDir: medium: v.medium
        			}
        		},
        	] | []

        	hostPath: *[
        			for v in parameter.volumeMounts.hostPath {
        			{
        				name: v.name
        				hostPath: path: v.path
        			}
        		},
        	] | []
        }
        output: {
        	apiVersion: "apps/v1"
        	kind:       "Deployment"
        	spec: {
        		selector: matchLabels: "app.oam.dev/component": context.name

        		template: {
        			metadata: {
        				labels: {
        					if parameter.labels != _|_ {
        						parameter.labels
        					}
        					if parameter.addRevisionLabel {
        						"app.oam.dev/revision": context.revision
        					}
        					"app.oam.dev/name":      context.appName
        					"app.oam.dev/component": context.name
        				}
        				if parameter.annotations != _|_ {
        					annotations: parameter.annotations
        				}
        			}

        			spec: {
        				containers: [{
        					name:  context.name
        					image: parameter.image
        					if parameter["port"] != _|_ && parameter["ports"] == _|_ {
        						ports: [{
        							containerPort: parameter.port
        						}]
        					}
        					if parameter["ports"] != _|_ {
        						ports: [ for v in parameter.ports {
        							{
        								containerPort: v.port
        								protocol:      v.protocol
        								if v.name != _|_ {
        									name: v.name
        								}
        								if v.name == _|_ {
        									name: "port-" + strconv.FormatInt(v.port, 10)
        								}
        							}}]
        					}

        					if parameter["imagePullPolicy"] != _|_ {
        						imagePullPolicy: parameter.imagePullPolicy
        					}

        					if parameter["cmd"] != _|_ {
        						command: parameter.cmd
        					}

        					if parameter["env"] != _|_ {
        						env: parameter.env
        					}

        					if context["config"] != _|_ {
        						env: context.config
        					}

        					if parameter["cpu"] != _|_ {
        						resources: {
        							limits: cpu:   parameter.cpu
        							requests: cpu: parameter.cpu
        						}
        					}

        					if parameter["memory"] != _|_ {
        						resources: {
        							limits: memory:   parameter.memory
        							requests: memory: parameter.memory
        						}
        					}

        					if parameter["volumes"] != _|_ && parameter["volumeMounts"] == _|_ {
        						volumeMounts: [ for v in parameter.volumes {
        							{
        								mountPath: v.mountPath
        								name:      v.name
        							}}]
        					}

        					if parameter["volumeMounts"] != _|_ {
        						volumeMounts: mountsArray.pvc + mountsArray.configMap + mountsArray.secret + mountsArray.emptyDir + mountsArray.hostPath
        					}

        					if parameter["livenessProbe"] != _|_ {
        						livenessProbe: parameter.livenessProbe
        					}

        					if parameter["readinessProbe"] != _|_ {
        						readinessProbe: parameter.readinessProbe
        					}

        				}]

        				if parameter["hostAliases"] != _|_ {
        					// +patchKey=ip
        					hostAliases: parameter.hostAliases
        				}

        				if parameter["imagePullSecrets"] != _|_ {
        					imagePullSecrets: [ for v in parameter.imagePullSecrets {
        						name: v
        					},
        					]
        				}

        				if parameter["volumes"] != _|_ && parameter["volumeMounts"] == _|_ {
        					volumes: [ for v in parameter.volumes {
        						{
        							name: v.name
        							if v.type == "pvc" {
        								persistentVolumeClaim: claimName: v.claimName
        							}
        							if v.type == "configMap" {
        								configMap: {
        									defaultMode: v.defaultMode
        									name:        v.cmName
        									if v.items != _|_ {
        										items: v.items
        									}
        								}
        							}
        							if v.type == "secret" {
        								secret: {
        									defaultMode: v.defaultMode
        									secretName:  v.secretName
        									if v.items != _|_ {
        										items: v.items
        									}
        								}
        							}
        							if v.type == "emptyDir" {
        								emptyDir: medium: v.medium
        							}
        						}
        					}]
        				}

        				if parameter["volumeMounts"] != _|_ {
        					volumes: volumesArray.pvc + volumesArray.configMap + volumesArray.secret + volumesArray.emptyDir + volumesArray.hostPath
        				}
        			}
        		}
        	}
        }
        exposePorts: [
        	for v in parameter.ports if v.expose == true {
        		port:       v.port
        		targetPort: v.port
        		if v.name != _|_ {
        			name: v.name
        		}
        		if v.name == _|_ {
        			name: "port-" + strconv.FormatInt(v.port, 10)
        		}
        	},
        ]
        outputs: {
        	if len(exposePorts) != 0 {
        		webserviceExpose: {
        			apiVersion: "v1"
        			kind:       "Service"
        			metadata: name: context.name
        			spec: {
        				selector: "app.oam.dev/component": context.name
        				ports: exposePorts
        				type:  parameter.exposeType
        			}
        		}
        	}
        }
        parameter: {
        	// +usage=Specify the labels in the workload
        	labels?: [string]: string

        	// +usage=Specify the annotations in the workload
        	annotations?: [string]: string

        	// +usage=Which image would you like to use for your service
        	// +short=i
        	image: string

        	// +usage=Specify image pull policy for your service
        	imagePullPolicy?: "Always" | "Never" | "IfNotPresent"

        	// +usage=Specify image pull secrets for your service
        	imagePullSecrets?: [...string]

        	// +ignore
        	// +usage=Deprecated field, please use ports instead
        	// +short=p
        	port?: int

        	// +usage=Which ports do you want customer traffic sent to, defaults to 80
        	ports?: [...{
        		// +usage=Number of port to expose on the pod's IP address
        		port: int
        		// +usage=Name of the port
        		name?: string
        		// +usage=Protocol for port. Must be UDP, TCP, or SCTP
        		protocol: *"TCP" | "UDP" | "SCTP"
        		// +usage=Specify if the port should be exposed
        		expose: *false | bool
        	}]

        	// +ignore
        	// +usage=Specify what kind of Service you want. options: "ClusterIP", "NodePort", "LoadBalancer", "ExternalName"
        	exposeType: *"ClusterIP" | "NodePort" | "LoadBalancer" | "ExternalName"

        	// +ignore
        	// +usage=If addRevisionLabel is true, the revision label will be added to the underlying pods
        	addRevisionLabel: *false | bool

        	// +usage=Commands to run in the container
        	cmd?: [...string]

        	// +usage=Define arguments by using environment variables
        	env?: [...{
        		// +usage=Environment variable name
        		name: string
        		// +usage=The value of the environment variable
        		value?: string
        		// +usage=Specifies a source the value of this var should come from
        		valueFrom?: {
        			// +usage=Selects a key of a secret in the pod's namespace
        			secretKeyRef?: {
        				// +usage=The name of the secret in the pod's namespace to select from
        				name: string
        				// +usage=The key of the secret to select from. Must be a valid secret key
        				key: string
        			}
        			// +usage=Selects a key of a config map in the pod's namespace
        			configMapKeyRef?: {
        				// +usage=The name of the config map in the pod's namespace to select from
        				name: string
        				// +usage=The key of the config map to select from. Must be a valid secret key
        				key: string
        			}
        		}
        	}]

        	// +usage=Number of CPU units for the service, like `0.5` (0.5 CPU core), `1` (1 CPU core)
        	cpu?: string

        	// +usage=Specifies the attributes of the memory resource required for the container.
        	memory?: string

        	volumeMounts?: {
        		// +usage=Mount PVC type volume
        		pvc?: [...{
        			name:      string
        			mountPath: string
        			// +usage=The name of the PVC
        			claimName: string
        		}]
        		// +usage=Mount ConfigMap type volume
        		configMap?: [...{
        			name:        string
        			mountPath:   string
        			defaultMode: *420 | int
        			cmName:      string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}]
        		// +usage=Mount Secret type volume
        		secret?: [...{
        			name:        string
        			mountPath:   string
        			defaultMode: *420 | int
        			secretName:  string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}]
        		// +usage=Mount EmptyDir type volume
        		emptyDir?: [...{
        			name:      string
        			mountPath: string
        			medium:    *"" | "Memory"
        		}]
        		// +usage=Mount HostPath type volume
        		hostPath?: [...{
        			name:      string
        			mountPath: string
        			path:      string
        		}]
        	}

        	// +usage=Deprecated field, use volumeMounts instead.
        	volumes?: [...{
        		name:      string
        		mountPath: string
        		// +usage=Specify volume type, options: "pvc","configMap","secret","emptyDir"
        		type: "pvc" | "configMap" | "secret" | "emptyDir"
        		if type == "pvc" {
        			claimName: string
        		}
        		if type == "configMap" {
        			defaultMode: *420 | int
        			cmName:      string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "secret" {
        			defaultMode: *420 | int
        			secretName:  string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "emptyDir" {
        			medium: *"" | "Memory"
        		}
        	}]

        	// +usage=Instructions for assessing whether the container is alive.
        	livenessProbe?: #HealthProbe

        	// +usage=Instructions for assessing whether the container is in a suitable state to serve traffic.
        	readinessProbe?: #HealthProbe

        	// +usage=Specify the hostAliases to add
        	hostAliases?: [...{
        		ip: string
        		hostnames: [...string]
        	}]
        }
        #HealthProbe: {

        	// +usage=Instructions for assessing container health by executing a command. Either this attribute or the httpGet attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the httpGet attribute and the tcpSocket attribute.
        	exec?: {
        		// +usage=A command to be executed inside the container to assess its health. Each space delimited token of the command is a separate array element. Commands exiting 0 are considered to be successful probes, whilst all other exit codes are considered failures.
        		command: [...string]
        	}

        	// +usage=Instructions for assessing container health by executing an HTTP GET request. Either this attribute or the exec attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the tcpSocket attribute.
        	httpGet?: {
        		// +usage=The endpoint, relative to the port, to which the HTTP GET request should be directed.
        		path: string
        		// +usage=The TCP socket within the container to which the HTTP GET request should be directed.
        		port:    int
        		host?:   string
        		scheme?: *"HTTP" | string
        		httpHeaders?: [...{
        			name:  string
        			value: string
        		}]
        	}

        	// +usage=Instructions for assessing container health by probing a TCP socket. Either this attribute or the exec attribute or the httpGet attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the httpGet attribute.
        	tcpSocket?: {
        		// +usage=The TCP socket within the container that should be probed to assess container health.
        		port: int
        	}

        	// +usage=Number of seconds after the container is started before the first probe is initiated.
        	initialDelaySeconds: *0 | int

        	// +usage=How often, in seconds, to execute the probe.
        	periodSeconds: *10 | int

        	// +usage=Number of seconds after which the probe times out.
        	timeoutSeconds: *1 | int

        	// +usage=Minimum consecutive successes for the probe to be considered successful after having failed.
        	successThreshold: *1 | int

        	// +usage=Number of consecutive failures required to determine the container is not alive (liveness probe) or not ready (readiness probe).
        	failureThreshold: *3 | int
        }
  status:
    customStatus: |-
      ready: {
      	readyReplicas: *0 | int
      } & {
      	if context.output.status.readyReplicas != _|_ {
      		readyReplicas: context.output.status.readyReplicas
      	}
      }
      message: "Ready:\(ready.readyReplicas)/\(context.output.spec.replicas)"
    healthPolicy: |-
      ready: {
      	updatedReplicas:    *0 | int
      	readyReplicas:      *0 | int
      	replicas:           *0 | int
      	observedGeneration: *0 | int
      } & {
      	if context.output.status.updatedReplicas != _|_ {
      		updatedReplicas: context.output.status.updatedReplicas
      	}
      	if context.output.status.readyReplicas != _|_ {
      		readyReplicas: context.output.status.readyReplicas
      	}
      	if context.output.status.replicas != _|_ {
      		replicas: context.output.status.replicas
      	}
      	if context.output.status.observedGeneration != _|_ {
      		observedGeneration: context.output.status.observedGeneration
      	}
      }
      isHealth: (context.output.spec.replicas == ready.readyReplicas) && (context.output.spec.replicas == ready.updatedReplicas) && (context.output.spec.replicas == ready.replicas) && (ready.observedGeneration == context.output.metadata.generation || ready.observedGeneration > context.output.metadata.generation)
  workload:
    definition:
      apiVersion: apps/v1
      kind: Deployment
    type: deployments.apps
---
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    definition.oam.dev/description: Describes long-running, scalable, containerized services that running at backend. They do NOT have network endpoint to receive external network traffic.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: worker
  namespace: default
spec:
  schematic:
    cue:
      template: |
        mountsArray: {
        	pvc: *[
        		for v in parameter.volumeMounts.pvc {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []

        	configMap: *[
        			for v in parameter.volumeMounts.configMap {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []

        	secret: *[
        		for v in parameter.volumeMounts.secret {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []

        	emptyDir: *[
        			for v in parameter.volumeMounts.emptyDir {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []

        	hostPath: *[
        			for v in parameter.volumeMounts.hostPath {
        			{
        				mountPath: v.mountPath
        				name:      v.name
        			}
        		},
        	] | []
        }
        volumesArray: {
        	pvc: *[
        		for v in parameter.volumeMounts.pvc {
        			{
        				name: v.name
        				persistentVolumeClaim: claimName: v.claimName
        			}
        		},
        	] | []

        	configMap: *[
        			for v in parameter.volumeMounts.configMap {
        			{
        				name: v.name
        				configMap: {
        					defaultMode: v.defaultMode
        					name:        v.cmName
        					if v.items != _|_ {
        						items: v.items
        					}
        				}
        			}
        		},
        	] | []

        	secret: *[
        		for v in parameter.volumeMounts.secret {
        			{
        				name: v.name
        				secret: {
        					defaultMode: v.defaultMode
        					secretName:  v.secretName
        					if v.items != _|_ {
        						items: v.items
        					}
        				}
        			}
        		},
        	] | []

        	emptyDir: *[
        			for v in parameter.volumeMounts.emptyDir {
        			{
        				name: v.name
        				emptyDir: medium: v.medium
        			}
        		},
        	] | []

        	hostPath: *[
        			for v in parameter.volumeMounts.hostPath {
        			{
        				name: v.name
        				hostPath: path: v.path
        			}
        		},
        	] | []
        }
        output: {
        	apiVersion: "apps/v1"
        	kind:       "Deployment"
        	spec: {
        		selector: matchLabels: "app.oam.dev/component": context.name

        		template: {
        			metadata: labels: {
        				"app.oam.dev/name":      context.appName
        				"app.oam.dev/component": context.name
        			}

        			spec: {
        				containers: [{
        					name:  context.name
        					image: parameter.image

        					if parameter["imagePullPolicy"] != _|_ {
        						imagePullPolicy: parameter.imagePullPolicy
        					}

        					if parameter["cmd"] != _|_ {
        						command: parameter.cmd
        					}

        					if parameter["env"] != _|_ {
        						env: parameter.env
        					}

        					if parameter["cpu"] != _|_ {
        						resources: {
        							limits: cpu:   parameter.cpu
        							requests: cpu: parameter.cpu
        						}
        					}

        					if parameter["memory"] != _|_ {
        						resources: {
        							limits: memory:   parameter.memory
        							requests: memory: parameter.memory
        						}
        					}

        					if parameter["volumes"] != _|_ && parameter["volumeMounts"] == _|_ {
        						volumeMounts: [ for v in parameter.volumes {
        							{
        								mountPath: v.mountPath
        								name:      v.name
        							}}]
        					}

        					if parameter["volumeMounts"] != _|_ {
        						volumeMounts: mountsArray.pvc + mountsArray.configMap + mountsArray.secret + mountsArray.emptyDir + mountsArray.hostPath
        					}

        					if parameter["livenessProbe"] != _|_ {
        						livenessProbe: parameter.livenessProbe
        					}

        					if parameter["readinessProbe"] != _|_ {
        						readinessProbe: parameter.readinessProbe
        					}

        				}]

        				if parameter["imagePullSecrets"] != _|_ {
        					imagePullSecrets: [ for v in parameter.imagePullSecrets {
        						name: v
        					},
        					]
        				}

        				if parameter["volumes"] != _|_ && parameter["volumeMounts"] == _|_ {
        					volumes: [ for v in parameter.volumes {
        						{
        							name: v.name
        							if v.type == "pvc" {
        								persistentVolumeClaim: claimName: v.claimName
        							}
        							if v.type == "configMap" {
        								configMap: {
        									defaultMode: v.defaultMode
        									name:        v.cmName
        									if v.items != _|_ {
        										items: v.items
        									}
        								}
        							}
        							if v.type == "secret" {
        								secret: {
        									defaultMode: v.defaultMode
        									secretName:  v.secretName
        									if v.items != _|_ {
        										items: v.items
        									}
        								}
        							}
        							if v.type == "emptyDir" {
        								emptyDir: medium: v.medium
        							}
        						}
        					}]
        				}
        				if parameter["volumeMounts"] != _|_ {
        					volumes: volumesArray.pvc + volumesArray.configMap + volumesArray.secret + volumesArray.emptyDir + volumesArray.hostPath
        				}
        			}
        		}
        	}
        }
        parameter: {
        	// +usage=Which image would you like to use for your service
        	// +short=i
        	image: string

        	// +usage=Specify image pull policy for your service
        	imagePullPolicy?: string

        	// +usage=Specify image pull secrets for your service
        	imagePullSecrets?: [...string]

        	// +usage=Commands to run in the container
        	cmd?: [...string]

        	// +usage=Define arguments by using environment variables
        	env?: [...{
        		// +usage=Environment variable name
        		name: string
        		// +usage=The value of the environment variable
        		value?: string
        		// +usage=Specifies a source the value of this var should come from
        		valueFrom?: {
        			// +usage=Selects a key of a secret in the pod's namespace
        			secretKeyRef?: {
        				// +usage=The name of the secret in the pod's namespace to select from
        				name: string
        				// +usage=The key of the secret to select from. Must be a valid secret key
        				key: string
        			}
        			// +usage=Selects a key of a config map in the pod's namespace
        			configMapKeyRef?: {
        				// +usage=The name of the config map in the pod's namespace to select from
        				name: string
        				// +usage=The key of the config map to select from. Must be a valid secret key
        				key: string
        			}
        		}
        	}]

        	// +usage=Number of CPU units for the service, like `0.5` (0.5 CPU core), `1` (1 CPU core)
        	cpu?: string

        	// +usage=Specifies the attributes of the memory resource required for the container.
        	memory?: string

        	volumeMounts?: {
        		// +usage=Mount PVC type volume
        		pvc?: [...{
        			name:      string
        			mountPath: string
        			// +usage=The name of the PVC
        			claimName: string
        		}]
        		// +usage=Mount ConfigMap type volume
        		configMap?: [...{
        			name:        string
        			mountPath:   string
        			defaultMode: *420 | int
        			cmName:      string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}]
        		// +usage=Mount Secret type volume
        		secret?: [...{
        			name:        string
        			mountPath:   string
        			defaultMode: *420 | int
        			secretName:  string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}]
        		// +usage=Mount EmptyDir type volume
        		emptyDir?: [...{
        			name:      string
        			mountPath: string
        			medium:    *"" | "Memory"
        		}]
        		// +usage=Mount HostPath type volume
        		hostPath?: [...{
        			name:      string
        			mountPath: string
        			path:      string
        		}]
        	}

        	// +usage=Deprecated field, use volumeMounts instead.
        	volumes?: [...{
        		name:      string
        		mountPath: string
        		// +usage=Specify volume type, options: "pvc","configMap","secret","emptyDir"
        		type: "pvc" | "configMap" | "secret" | "emptyDir"
        		if type == "pvc" {
        			claimName: string
        		}
        		if type == "configMap" {
        			defaultMode: *420 | int
        			cmName:      string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "secret" {
        			defaultMode: *420 | int
        			secretName:  string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "emptyDir" {
        			medium: *"" | "Memory"
        		}
        	}]

        	// +usage=Instructions for assessing whether the container is alive.
        	livenessProbe?: #HealthProbe

        	// +usage=Instructions for assessing whether the container is in a suitable state to serve traffic.
        	readinessProbe?: #HealthProbe
        }
        #HealthProbe: {

        	// +usage=Instructions for assessing container health by executing a command. Either this attribute or the httpGet attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the httpGet attribute and the tcpSocket attribute.
        	exec?: {
        		// +usage=A command to be executed inside the container to assess its health. Each space delimited token of the command is a separate array element. Commands exiting 0 are considered to be successful probes, whilst all other exit codes are considered failures.
        		command: [...string]
        	}

        	// +usage=Instructions for assessing container health by executing an HTTP GET request. Either this attribute or the exec attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the tcpSocket attribute.
        	httpGet?: {
        		// +usage=The endpoint, relative to the port, to which the HTTP GET request should be directed.
        		path: string
        		// +usage=The TCP socket within the container to which the HTTP GET request should be directed.
        		port: int
        		httpHeaders?: [...{
        			name:  string
        			value: string
        		}]
        	}

        	// +usage=Instructions for assessing container health by probing a TCP socket. Either this attribute or the exec attribute or the httpGet attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the httpGet attribute.
        	tcpSocket?: {
        		// +usage=The TCP socket within the container that should be probed to assess container health.
        		port: int
        	}

        	// +usage=Number of seconds after the container is started before the first probe is initiated.
        	initialDelaySeconds: *0 | int

        	// +usage=How often, in seconds, to execute the probe.
        	periodSeconds: *10 | int

        	// +usage=Number of seconds after which the probe times out.
        	timeoutSeconds: *1 | int

        	// +usage=Minimum consecutive successes for the probe to be considered successful after having failed.
        	successThreshold: *1 | int

        	// +usage=Number of consecutive failures required to determine the container is not alive (liveness probe) or not ready (readiness probe).
        	failureThreshold: *3 | int
        }
  status:
    customStatus: |-
      ready: {
      	readyReplicas: *0 | int
      } & {
      	if context.output.status.readyReplicas != _|_ {
      		readyReplicas: context.output.status.readyReplicas
      	}
      }
      message: "Ready:\(ready.readyReplicas)/\(context.output.spec.replicas)"
    healthPolicy: |-
      ready: {
      	updatedReplicas:    *0 | int
      	readyReplicas:      *0 | int
      	replicas:           *0 | int
      	observedGeneration: *0 | int
      } & {
      	if context.output.status.updatedReplicas != _|_ {
      		updatedReplicas: context.output.status.updatedReplicas
      	}
      	if context.output.status.readyReplicas != _|_ {
      		readyReplicas: context.output.status.readyReplicas
      	}
      	if context.output.status.replicas != _|_ {
      		replicas: context.output.status.replicas
      	}
      	if context.output.status.observedGeneration != _|_ {
      		observedGeneration: context.output.status.observedGeneration
      	}
      }
      isHealth: (context.output.spec.replicas == ready.readyReplicas) && (context.output.spec.replicas == ready.updatedReplicas) && (context.output.spec.replicas == ready.replicas) && (ready.observedGeneration == context.output.metadata.generation || ready.observedGeneration > context.output.metadata.generation)
  workload:
    definition:
      apiVersion: apps/v1
      kind: Deployment
    type: deployments.apps
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: release-name-vela-core-admission
  namespace: default
webhooks:
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /mutating-core-oam-dev-v1beta1-approllout
    failurePolicy: Ignore
    name: mutating.core.oam.dev.v1beta1.approllouts
    sideEffects: None
    rules:
      - apiGroups:
          - core.oam.dev
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - approllouts
        scope: Namespaced
    admissionReviewVersions:
      - v1beta1
      - v1
    timeoutSeconds: 5
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /mutate-standard-oam-dev-v1alpha1-podspecworkload
    failurePolicy: Ignore
    name: mcontainerized.kb.io
    sideEffects: None
    admissionReviewVersions:
      - v1beta1
    rules:
      - apiGroups:
          - standard.oam.dev
        apiVersions:
          - v1alpha1
        operations:
          - CREATE
          - UPDATE
        resources:
          - podspecworkloads
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /mutating-core-oam-dev-v1beta1-applications
    failurePolicy: Ignore
    name: mutating.core.oam.dev.v1beta1.applications
    admissionReviewVersions:
      - v1beta1
      - v1
    sideEffects: None
    rules:
      - apiGroups:
          - core.oam.dev
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - applications
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /mutating-core-oam-dev-v1beta1-componentdefinitions
    failurePolicy: Ignore
    name: mutating.core.oam-dev.v1beta1.componentdefinitions
    sideEffects: None
    admissionReviewVersions:
      - v1beta1
      - v1
    rules:
      - apiGroups:
          - core.oam.dev
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - componentdefinitions
---
apiVersion: core.oam.dev/v1beta1
kind: PolicyDefinition
metadata:
  annotations:
    definition.oam.dev/description: Determining the destination where components should be deployed to, and support override configuration
  labels:
    custom.definition.oam.dev/deprecated: "true"
  name: envbinding
  namespace: default
spec:
  schematic:
    cue:
      template: |
        #PatchParams: {
        	// +usage=Specify the name of the patch component, if empty, all components will be merged
        	name?: string
        	// +usage=Specify the type of the patch component.
        	type?: string
        	properties?: {...}
        	traits?: [...{
        		type: string
        		properties?: {...}
        		// +usage=Specify if the trait shoued be remove, default false
        		disable: *false | bool
        	}]
        }
        parameter: envs: [...{
        	name: string
        	placement?: {
        		clusterSelector?: {
        			// +usage=Specify cluster name, defualt local
        			name: *"local" | string
        			labels?: [string]: string
        		}
        		namespaceSelector?: {
        			// +usage=Specify namespace name.
        			name?: string
        			labels?: [string]: string
        		}
        	}
        	selector?: components: [...string]
        	patch?: components: [...#PatchParams]
        }]
---
apiVersion: core.oam.dev/v1beta1
kind: PolicyDefinition
metadata:
  annotations:
    definition.oam.dev/description: Apply periodical health checking to the application.
  name: health
  namespace: default
spec:
  manageHealthCheck: true
  schematic:
    cue:
      template: |
        output: {
        	apiVersion: "core.oam.dev/v1alpha2"
        	kind:       "HealthScope"
        	spec: {
        		"probe-timeout":  parameter.probeTimeout
        		"probe-interval": parameter.probeInterval
        		appReferences: [{
        			appName: context.appName
        		}]
        		workloadRefs: []
        		manageHealthCheck: true
        	}
        }
        parameter: {
        	// +usage=Specify health checking timeout(seconds), default 10s
        	probeTimeout: *10 | int
        	// +usage=Specify health checking interval(seconds), default 30s
        	probeInterval: *30 | int
        }
---
apiVersion: core.oam.dev/v1beta1
kind: PolicyDefinition
metadata:
  annotations:
    definition.oam.dev/description: Override configuration when deploying resources
  name: override
  namespace: default
spec:
  schematic:
    cue:
      template: |
        #PatchParams: {
        	// +usage=Specify the name of the patch component, if empty, all components will be merged
        	name?: string
        	// +usage=Specify the type of the patch component.
        	type?: string
        	properties?: {...}
        	traits?: [...{
        		type: string
        		properties?: {...}
        		// +usage=Specify if the trait shoued be remove, default false
        		disable: *false | bool
        	}]
        }
        parameter: {
        	// +usage=Specify the overridden component configuration.
        	components: [...#PatchParams]
        	// +usage=Specify a list of component names to use, if empty, all components will be selected.
        	selector?: [...string]
        }
---
apiVersion: core.oam.dev/v1beta1
kind: PolicyDefinition
metadata:
  annotations:
    definition.oam.dev/description: Determining the destination where components should be deployed to.
  name: topology
  namespace: default
spec:
  schematic:
    cue:
      template: |
        parameter: {
        	// +usage=Specify the names of the clusters to select.
        	cluster?: [...string]
        	// +usage=Specify the label selector for clusters
        	clusterLabelSelector?: [string]: string
        	// +usage=Deprecated: Use clusterLabelSelector instead.
        	clusterSelector?: [string]: string
        	// +usage=Specify the target namespace to deploy in the selected clusters, default inherit the original namespace.
        	namespace?: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: ScopeDefinition
metadata:
  name: healthscopes.core.oam.dev
  namespace: default
spec:
  workloadRefsPath: spec.workloadRefs
  allowComponentOverlap: true
  definitionRef:
    name: healthscopes.core.oam.dev
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: affinity specify affinity and tolerationon K8s pod for your workload which follows the pod spec in path 'spec.template'.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: affinity
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: spec: template: spec: {
        	if parameter.podAffinity != _|_ {
        		affinity: podAffinity: {
        			if parameter.podAffinity.required != _|_ {
        				requiredDuringSchedulingIgnoredDuringExecution: [
        					for k in parameter.podAffinity.required {
        						if k.labelSelector != _|_ {
        							labelSelector: k.labelSelector
        						}
        						if k.namespace != _|_ {
        							namespace: k.namespace
        						}
        						topologyKey: k.topologyKey
        						if k.namespaceSelector != _|_ {
        							namespaceSelector: k.namespaceSelector
        						}
        					}]
        			}
        			if parameter.podAffinity.preferred != _|_ {
        				preferredDuringSchedulingIgnoredDuringExecution: [
        					for k in parameter.podAffinity.preferred {
        						weight:          k.weight
        						podAffinityTerm: k.podAffinityTerm
        					}]
        			}
        		}
        	}
        	if parameter.podAntiAffinity != _|_ {
        		affinity: podAntiAffinity: {
        			if parameter.podAntiAffinity.required != _|_ {
        				requiredDuringSchedulingIgnoredDuringExecution: [
        					for k in parameter.podAntiAffinity.required {
        						if k.labelSelector != _|_ {
        							labelSelector: k.labelSelector
        						}
        						if k.namespace != _|_ {
        							namespace: k.namespace
        						}
        						topologyKey: k.topologyKey
        						if k.namespaceSelector != _|_ {
        							namespaceSelector: k.namespaceSelector
        						}
        					}]
        			}
        			if parameter.podAntiAffinity.preferred != _|_ {
        				preferredDuringSchedulingIgnoredDuringExecution: [
        					for k in parameter.podAntiAffinity.preferred {
        						weight:          k.weight
        						podAffinityTerm: k.podAffinityTerm
        					}]
        			}
        		}
        	}
        	if parameter.nodeAffinity != _|_ {
        		affinity: nodeAffinity: {
        			if parameter.nodeAffinity.required != _|_ {
        				requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: [
        					for k in parameter.nodeAffinity.required.nodeSelectorTerms {
        						if k.matchExpressions != _|_ {
        							matchExpressions: k.matchExpressions
        						}
        						if k.matchFields != _|_ {
        							matchFields: k.matchFields
        						}
        					}]
        			}
        			if parameter.nodeAffinity.preferred != _|_ {
        				preferredDuringSchedulingIgnoredDuringExecution: [
        					for k in parameter.nodeAffinity.preferred {
        						weight:     k.weight
        						preference: k.preference
        					}]
        			}
        		}
        	}
        	if parameter.tolerations != _|_ {
        		tolerations: [
        			for k in parameter.tolerations {
        				if k.key != _|_ {
        					key: k.key
        				}
        				if k.effect != _|_ {
        					effect: k.effect
        				}
        				if k.value != _|_ {
        					value: k.value
        				}
        				operator: k.operator
        				if k.tolerationSeconds != _|_ {
        					tolerationSeconds: k.tolerationSeconds
        				}
        			}]
        	}
        }
        #labelSelector: {
        	matchLabels?: [string]: string
        	matchExpressions?: [...{
        		key:      string
        		operator: *"In" | "NotIn" | "Exists" | "DoesNotExist"
        		values?: [...string]
        	}]
        }
        #podAffinityTerm: {
        	labelSelector?: #labelSelector
        	namespaces?: [...string]
        	topologyKey:        string
        	namespaceSelector?: #labelSelector
        }
        #nodeSelecor: {
        	key:      string
        	operator: *"In" | "NotIn" | "Exists" | "DoesNotExist" | "Gt" | "Lt"
        	values?: [...string]
        }
        #nodeSelectorTerm: {
        	matchExpressions?: [...#nodeSelecor]
        	matchFields?: [...#nodeSelecor]
        }
        parameter: {
        	// +usage=Specify the pod affinity scheduling rules
        	podAffinity?: {
        		// +usage=Specify the required during scheduling ignored during execution
        		required?: [...#podAffinityTerm]
        		// +usage=Specify the preferred during scheduling ignored during execution
        		preferred?: [...{
        			// +usage=Specify weight associated with matching the corresponding podAffinityTerm
        			weight: int & >=1 & <=100
        			// +usage=Specify a set of pods
        			podAffinityTerm: #podAffinityTerm
        		}]
        	}
        	// +usage=Specify the pod anti-affinity scheduling rules
        	podAntiAffinity?: {
        		// +usage=Specify the required during scheduling ignored during execution
        		required?: [...#podAffinityTerm]
        		// +usage=Specify the preferred during scheduling ignored during execution
        		preferred?: [...{
        			// +usage=Specify weight associated with matching the corresponding podAffinityTerm
        			weight: int & >=1 & <=100
        			// +usage=Specify a set of pods
        			podAffinityTerm: #podAffinityTerm
        		}]
        	}
        	// +usage=Specify the node affinity scheduling rules for the pod
        	nodeAffinity?: {
        		// +usage=Specify the required during scheduling ignored during execution
        		required?: {
        			// +usage=Specify a list of node selector
        			nodeSelectorTerms: [...#nodeSelectorTerm]
        		}
        		// +usage=Specify the preferred during scheduling ignored during execution
        		preferred?: [...{
        			// +usage=Specify weight associated with matching the corresponding nodeSelector
        			weight: int & >=1 & <=100
        			// +usage=Specify a node selector
        			preference: #nodeSelectorTerm
        		}]
        	}
        	// +usage=Specify tolerant taint
        	tolerations?: [...{
        		key?:     string
        		operator: *"Equal" | "Exists"
        		value?:   string
        		effect?:  "NoSchedule" | "PreferNoSchedule" | "NoExecute"
        		// +usage=Specify the period of time the toleration
        		tolerationSeconds?: int
        	}]
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add annotations on K8s pod for your workload which follows the pod spec in path 'spec.template'.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: annotations
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        // +patchStrategy=jsonMergePatch
        patch: {
        	metadata: annotations: {
        		for k, v in parameter {
        			"\(k)": v
        		}
        	}
        	if context.output.spec != _|_ && context.output.spec.template != _|_ {
        		spec: template: metadata: annotations: {
        			for k, v in parameter {
        				"\(k)": v
        			}
        		}
        	}
        }
        parameter: [string]: string | null
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add command on K8s pod for your workload which follows the pod spec in path 'spec.template'
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: command
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  schematic:
    cue:
      template: |
        #PatchParams: {
        	// +usage=Specify the name of the target container, if not set, use the component name
        	containerName: *"" | string
        	// +usage=Specify the command to use in the target container, if not set, it will not be changed
        	command: *null | [...string]
        	// +usage=Specify the args to use in the target container, if set, it will override existing args
        	args: *null | [...string]
        	// +usage=Specify the args to add in the target container, existing args will be kept, cannot be used with `args`
        	addArgs: *null | [...string]
        	// +usage=Specify the existing args to delete in the target container, cannot be used with `args`
        	delArgs: *null | [...string]
        }
        PatchContainer: {
        	_params:         #PatchParams
        	name:            _params.containerName
        	_baseContainers: context.output.spec.template.spec.containers
        	_matchContainers_: [ for _container_ in _baseContainers if _container_.name == name {_container_}]
        	_baseContainer: *_|_ | {...}
        	if len(_matchContainers_) == 0 {
        		err: "container \(name) not found"
        	}
        	if len(_matchContainers_) > 0 {
        		_baseContainer: _matchContainers_[0]
        		if _params.command != null {
        			// +patchStrategy=replace
        			command: _params.command
        		}
        		if (_params.addArgs != null || _params.delArgs != null) && _params.args != null {
        			err: "cannot set addArgs/delArgs and args at the same time"
        		}
        		_delArgs: {...}
        		if _params.delArgs != null {
        			_delArgs: {for k in _params.delArgs {"\(k)": ""}}
        		}
        		if _params.delArgs == null {
        			_delArgs: {}
        		}
        		_args: [...string]
        		if _params.args != null {
        			_args: _params.args
        		}
        		if _params.args == null && _baseContainer.args != _|_ {
        			_args: _baseContainer.args
        		}
        		if _params.args == null && _baseContainer.args == _|_ {
        			_args: []
        		}
        		_argsMap: {for a in _args {"\(a)": ""}}
        		_addArgs: [...string]
        		if _params.addArgs != null {
        			_addArgs: _params.addArgs
        		}
        		if _params.addArgs == null {
        			_addArgs: []
        		}

        		// +patchStrategy=replace
        		args: [ for a in _args if _delArgs[a] == _|_ {a}] + [ for a in _addArgs if _delArgs[a] == _|_ && _argsMap[a] == _|_ {a}]
        	}
        }
        // +patchStrategy=open
        patch: spec: template: spec: {
        	if parameter.containers == _|_ {
        		// +patchKey=name
        		containers: [{
        			PatchContainer & {_params: {
        				if parameter.containerName == "" {
        					containerName: context.name
        				}
        				if parameter.containerName != "" {
        					containerName: parameter.containerName
        				}
        				command: parameter.command
        				args:    parameter.args
        				addArgs: parameter.addArgs
        				delArgs: parameter.delArgs
        			}}
        		}]
        	}
        	if parameter.containers != _|_ {
        		// +patchKey=name
        		containers: [ for c in parameter.containers {
        			if c.containerName == "" {
        				err: "container name must be set for containers"
        			}
        			if c.containerName != "" {
        				PatchContainer & {_params: c}
        			}
        		}]
        	}
        }
        parameter: *#PatchParams | close({
        	// +usage=Specify the commands for multiple containers
        	containers: [...#PatchParams]
        })
        errs: [ for c in patch.spec.template.spec.containers if c.err != _|_ {c.err}]
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Create/Attach configmaps on K8s pod for your workload which follows the pod spec in path 'spec.template'. This definition is DEPRECATED, please specify configmap in 'storage' instead.
  labels:
    custom.definition.oam.dev/deprecated: "true"
  name: configmap
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: spec: template: spec: {
        	containers: [{
        		// +patchKey=name
        		volumeMounts: [
        			for v in parameter.volumes {
        				{
        					name:      "volume-\(v.name)"
        					mountPath: v.mountPath
        					readOnly:  v.readOnly
        				}
        			},
        		]
        	}, ...]
        	// +patchKey=name
        	volumes: [
        		for v in parameter.volumes {
        			{
        				name: "volume-\(v.name)"
        				configMap: name: v.name
        			}
        		},
        	]
        }
        outputs: {
        	for v in parameter.volumes {
        		if v.data != _|_ {
        			"\(v.name)": {
        				apiVersion: "v1"
        				kind:       "ConfigMap"
        				metadata: name: v.name
        				data: v.data
        			}
        		}
        	}
        }
        parameter: {
        	// +usage=Specify mounted configmap names and their mount paths in the container
        	volumes: [...{
        		name:      string
        		mountPath: string
        		readOnly:  *false | bool
        		data?: [string]: string
        	}]
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Set the image of the container.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: container-image
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        #PatchParams: {
        	// +usage=Specify the name of the target container, if not set, use the component name
        	containerName: *"" | string
        	// +usage=Specify the image of the container
        	image: string
        	// +usage=Specify the image pull policy of the container
        	imagePullPolicy: *"" | "IfNotPresent" | "Always" | "Never"
        }
        PatchContainer: {
        	_params:         #PatchParams
        	name:            _params.containerName
        	_baseContainers: context.output.spec.template.spec.containers
        	_matchContainers_: [ for _container_ in _baseContainers if _container_.name == name {_container_}]
        	_baseContainer: *_|_ | {...}
        	if len(_matchContainers_) == 0 {
        		err: "container \(name) not found"
        	}
        	if len(_matchContainers_) > 0 {
        		// +patchStrategy=retainKeys
        		image: _params.image

        		if _params.imagePullPolicy != "" {
        			// +patchStrategy=retainKeys
        			imagePullPolicy: _params.imagePullPolicy
        		}
        	}
        }
        patch: spec: template: spec: {
        	if parameter.containers == _|_ {
        		// +patchKey=name
        		containers: [{
        			PatchContainer & {_params: {
        				if parameter.containerName == "" {
        					containerName: context.name
        				}
        				if parameter.containerName != "" {
        					containerName: parameter.containerName
        				}
        				image:           parameter.image
        				imagePullPolicy: parameter.imagePullPolicy
        			}}
        		}]
        	}
        	if parameter.containers != _|_ {
        		// +patchKey=name
        		containers: [ for c in parameter.containers {
        			if c.containerName == "" {
        				err: "containerName must be set for containers"
        			}
        			if c.containerName != "" {
        				PatchContainer & {_params: c}
        			}
        		}]
        	}
        }
        parameter: *#PatchParams | close({
        	// +usage=Specify the container image for multiple containers
        	containers: [...#PatchParams]
        })
        errs: [ for c in patch.spec.template.spec.containers if c.err != _|_ {c.err}]
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Automatically scale the component based on CPU usage.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: cpuscaler
  namespace: default
spec:
  appliesToWorkloads:
    - deployments.apps
  schematic:
    cue:
      template: |
        outputs: cpuscaler: {
        	apiVersion: "autoscaling/v1"
        	kind:       "HorizontalPodAutoscaler"
        	metadata: name: context.name
        	spec: {
        		scaleTargetRef: {
        			apiVersion: parameter.targetAPIVersion
        			kind:       parameter.targetKind
        			name:       context.name
        		}
        		minReplicas:                    parameter.min
        		maxReplicas:                    parameter.max
        		targetCPUUtilizationPercentage: parameter.cpuUtil
        	}
        }
        parameter: {
        	// +usage=Specify the minimal number of replicas to which the autoscaler can scale down
        	min: *1 | int
        	// +usage=Specify the maximum number of of replicas to which the autoscaler can scale up
        	max: *10 | int
        	// +usage=Specify the average CPU utilization, for example, 50 means the CPU usage is 50%
        	cpuUtil: *50 | int
        	// +usage=Specify the apiVersion of scale target
        	targetAPIVersion: *"apps/v1" | string
        	// +usage=Specify the kind of scale target
        	targetKind: *"Deployment" | string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add env on K8s pod for your workload which follows the pod spec in path 'spec.template'
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: env
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  schematic:
    cue:
      template: |
        #PatchParams: {
        	// +usage=Specify the name of the target container, if not set, use the component name
        	containerName: *"" | string
        	// +usage=Specify if replacing the whole environment settings for the container
        	replace: *false | bool
        	// +usage=Specify the  environment variables to merge, if key already existing, override its value
        	env: [string]: string
        	// +usage=Specify which existing environment variables to unset
        	unset: *[] | [...string]
        }
        PatchContainer: {
        	_params: #PatchParams
        	name:    _params.containerName
        	_delKeys: {for k in _params.unset {"\(k)": ""}}
        	_baseContainers: context.output.spec.template.spec.containers
        	_matchContainers_: [ for _container_ in _baseContainers if _container_.name == name {_container_}]
        	_baseContainer: *_|_ | {...}
        	if len(_matchContainers_) == 0 {
        		err: "container \(name) not found"
        	}
        	if len(_matchContainers_) > 0 {
        		_baseContainer: _matchContainers_[0]
        		_baseEnv:       _baseContainer.env
        		if _baseEnv == _|_ {
        			// +patchStrategy=replace
        			env: [ for k, v in _params.env if _delKeys[k] == _|_ {
        				name:  k
        				value: v
        			}]
        		}
        		if _baseEnv != _|_ {
        			_baseEnvMap: {for envVar in _baseEnv {"\(envVar.name)": envVar}}
        			// +patchStrategy=replace
        			env: [ for envVar in _baseEnv if _delKeys[envVar.name] == _|_ && !_params.replace {
        				name: envVar.name
        				if _params.env[envVar.name] != _|_ {
        					value: _params.env[envVar.name]
        				}
        				if _params.env[envVar.name] == _|_ {
        					if envVar.value != _|_ {
        						value: envVar.value
        					}
        					if envVar.valueFrom != _|_ {
        						valueFrom: envVar.valueFrom
        					}
        				}
        			}] + [ for k, v in _params.env if _delKeys[k] == _|_ && (_params.replace || _baseEnvMap[k] == _|_) {
        				name:  k
        				value: v
        			}]
        		}
        	}
        }
        patch: spec: template: spec: {
        	if parameter.containers == _|_ {
        		// +patchKey=name
        		containers: [{
        			PatchContainer & {_params: {
        				if parameter.containerName == "" {
        					containerName: context.name
        				}
        				if parameter.containerName != "" {
        					containerName: parameter.containerName
        				}
        				replace: parameter.replace
        				env:     parameter.env
        				unset:   parameter.unset
        			}}
        		}]
        	}
        	if parameter.containers != _|_ {
        		// +patchKey=name
        		containers: [ for c in parameter.containers {
        			if c.containerName == "" {
        				err: "containerName must be set for containers"
        			}
        			if c.containerName != "" {
        				PatchContainer & {_params: c}
        			}
        		}]
        	}
        }
        parameter: *#PatchParams | close({
        	// +usage=Specify the environment variables for multiple containers
        	containers: [...#PatchParams]
        })
        errs: [ for c in patch.spec.template.spec.containers if c.err != _|_ {c.err}]
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Expose port to enable web traffic for your component.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: expose
  namespace: default
spec:
  podDisruptive: false
  schematic:
    cue:
      template: |
        outputs: service: {
        	apiVersion: "v1"
        	kind:       "Service"
        	metadata: name: context.name
        	spec: {
        		selector: "app.oam.dev/component": context.name
        		ports: [
        			for p in parameter.port {
        				port:       p
        				targetPort: p
        			},
        		]
        		type: parameter.type
        	}
        }
        parameter: {
        	// +usage=Specify the exposion ports
        	port: [...int]
        	// +usage=Specify what kind of Service you want. options: "ClusterIP","NodePort","LoadBalancer","ExternalName"
        	type: *"ClusterIP" | "NodePort" | "LoadBalancer" | "ExternalName"
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Enable public web traffic for the component, the ingress API matches K8s v1.20+.
  name: gateway
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: false
  schematic:
    cue:
      template: |
        // trait template can have multiple outputs in one trait
        outputs: service: {
        	apiVersion: "v1"
        	kind:       "Service"
        	metadata: name: context.name
        	spec: {
        		selector: "app.oam.dev/component": context.name
        		ports: [
        			for k, v in parameter.http {
        				port:       v
        				targetPort: v
        			},
        		]
        	}
        }
        outputs: ingress: {
        	apiVersion: "networking.k8s.io/v1"
        	kind:       "Ingress"
        	metadata: {
        		name: context.name
        		annotations: {
        			if !parameter.classInSpec {
        				"kubernetes.io/ingress.class": parameter.class
        			}
        		}
        	}
        	spec: {
        		if parameter.classInSpec {
        			ingressClassName: parameter.class
        		}
        		if parameter.secretName != _|_ {
        			tls: [{
        				hosts: [
        					parameter.domain,
        				]
        				secretName: parameter.secretName
        			}]
        		}
        		rules: [{
        			if parameter.domain != _|_ {
        				host: parameter.domain
        			}
        			http: paths: [
        				for k, v in parameter.http {
        					path:     k
        					pathType: "ImplementationSpecific"
        					backend: service: {
        						name: context.name
        						port: number: v
        					}
        				},
        			]
        		}]
        	}
        }
        parameter: {
        	// +usage=Specify the domain you want to expose
        	domain?: string

        	// +usage=Specify the mapping relationship between the http path and the workload port
        	http: [string]: int

        	// +usage=Specify the class of ingress to use
        	class: *"nginx" | string

        	// +usage=Set ingress class in '.spec.ingressClassName' instead of 'kubernetes.io/ingress.class' annotation.
        	classInSpec: *false | bool

        	// +usage=Specify the secret name you want to quote.
        	secretName?: string
        }
  status:
    customStatus: |-
      let igs = context.outputs.ingress.status.loadBalancer.ingress
      if igs == _|_ {
        message: "No loadBalancer found, visiting by using 'vela port-forward " + context.appName + "'\n"
      }
      if len(igs) > 0 {
        if igs[0].ip != _|_ {
        	if igs[0].host != _|_ {
      	    message: "Visiting URL: " + context.outputs.ingress.spec.rules[0].host + ", IP: " + igs[0].ip
        	}
        	if igs[0].host == _|_ {
      	    message: "Host not specified, visit the cluster or load balancer in front of the cluster"
        	}
        }
        if igs[0].ip == _|_ {
        	if igs[0].host != _|_ {
      		  message: "Visiting URL: " + context.outputs.ingress.spec.rules[0].host
      		}
        	if igs[0].host != _|_ {
      	    message: "Host not specified, visit the cluster or load balancer in front of the cluster"
      		}
        }
      }
    healthPolicy: 'isHealth: len(context.outputs.service.spec.clusterIP) > 0'
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add host aliases on K8s pod for your workload which follows the pod spec in path 'spec.template'.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: hostalias
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: false
  schematic:
    cue:
      template: |
        patch: {
        	// +patchKey=ip
        	spec: template: spec: hostAliases: parameter.hostAliases
        }
        parameter: {
        	// +usage=Specify the hostAliases to add
        	hostAliases: [...{
        		ip: string
        		hostnames: [...string]
        	}]
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Import dashboards to Grafana
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: import-grafana-dashboard
  namespace: default
spec:
  appliesToWorkloads: []
  conflictsWith: []
  podDisruptive: false
  schematic:
    cue:
      template: |
        outputs: registerdatasource: {
        	apiVersion: "grafana.extension.oam.dev/v1alpha1"
        	kind:       "ImportDashboard"
        	spec: {
        		grafana: {
        			service:                   parameter.grafanaServiceName
        			namespace:                 parameter.grafanaServiceNamespace
        			credentialSecret:          parameter.credentialSecret
        			credentialSecretNamespace: parameter.credentialSecretNamespace
        		}
        		urls: parameter.urls
        	}
        }
        parameter: {
        	grafanaServiceName:        string
        	grafanaServiceNamespace:   *"default" | string
        	credentialSecret:          string
        	credentialSecretNamespace: *"default" | string
        	urls: [...string]

        }
  workloadRefPath: ""
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Enable public web traffic for the component, the ingress API matches K8s v1.20+.
  labels:
    custom.definition.oam.dev/deprecated: "true"
  name: ingress-1-20
  namespace: default
spec:
  podDisruptive: false
  schematic:
    cue:
      template: |
        // trait template can have multiple outputs in one trait
        outputs: service: {
        	apiVersion: "v1"
        	kind:       "Service"
        	metadata: name: context.name
        	spec: {
        		selector: "app.oam.dev/component": context.name
        		ports: [
        			for k, v in parameter.http {
        				port:       v
        				targetPort: v
        			},
        		]
        	}
        }
        outputs: ingress: {
        	apiVersion: "networking.k8s.io/v1"
        	kind:       "Ingress"
        	metadata: {
        		name: context.name
        		annotations: "kubernetes.io/ingress.class": parameter.class
        	}
        	spec: rules: [{
        		host: parameter.domain
        		http: paths: [
        			for k, v in parameter.http {
        				path:     k
        				pathType: "ImplementationSpecific"
        				backend: service: {
        					name: context.name
        					port: number: v
        				}
        			},
        		]
        	}]
        }
        parameter: {
        	// +usage=Specify the domain you want to expose
        	domain: string

        	// +usage=Specify the mapping relationship between the http path and the workload port
        	http: [string]: int

        	// +usage=Specify the class of ingress to use
        	class: *"nginx" | string
        }
  status:
    customStatus: |-
      let igs = context.outputs.ingress.status.loadBalancer.ingress
      if igs == _|_ {
        message: "No loadBalancer found, visiting by using 'vela port-forward " + context.appName + "'\n"
      }
      if len(igs) > 0 {
        if igs[0].ip != _|_ {
      	  message: "Visiting URL: " + context.outputs.ingress.spec.rules[0].host + ", IP: " + igs[0].ip
        }
        if igs[0].ip == _|_ {
      	  message: "Visiting URL: " + context.outputs.ingress.spec.rules[0].host
        }
      }
    healthPolicy: 'isHealth: len(context.outputs.service.spec.clusterIP) > 0'
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Enable public web traffic for the component.
  labels:
    custom.definition.oam.dev/deprecated: "true"
  name: ingress
  namespace: default
spec:
  podDisruptive: false
  schematic:
    cue:
      template: |
        // trait template can have multiple outputs in one trait
        outputs: service: {
        	apiVersion: "v1"
        	kind:       "Service"
        	metadata: name: context.name
        	spec: {
        		selector: "app.oam.dev/component": context.name
        		ports: [
        			for k, v in parameter.http {
        				port:       v
        				targetPort: v
        			},
        		]
        	}
        }
        outputs: ingress: {
        	apiVersion: "networking.k8s.io/v1beta1"
        	kind:       "Ingress"
        	metadata: name: context.name
        	spec: rules: [{
        		host: parameter.domain
        		http: paths: [
        			for k, v in parameter.http {
        				path: k
        				backend: {
        					serviceName: context.name
        					servicePort: v
        				}
        			},
        		]
        	}]
        }
        parameter: {
        	// +usage=Specify the domain you want to expose
        	domain: string

        	// +usage=Specify the mapping relationship between the http path and the workload port
        	http: [string]: int
        }
  status:
    customStatus: |-
      let igs = context.outputs.ingress.status.loadBalancer.ingress
      if igs == _|_ {
      	message: "No loadBalancer found, visiting by using 'vela port-forward " + context.appName + "'\n"
      }
      if len(igs) > 0 {
      	if igs[0].ip != _|_ {
      		message: "Visiting URL: " + context.outputs.ingress.spec.rules[0].host + ", IP: " + igs[0].ip
      	}
      	if igs[0].ip == _|_ {
      		message: "Visiting URL: " + context.outputs.ingress.spec.rules[0].host
      	}
      }
    healthPolicy: 'isHealth: len(context.outputs.service.spec.clusterIP) > 0'
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: add an init container and use shared volume with pod
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: init-container
  namespace: default
spec:
  appliesToWorkloads:
    - deployments.apps
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: spec: template: spec: {
        	// +patchKey=name
        	containers: [{
        		name: context.name
        		// +patchKey=name
        		volumeMounts: [{
        			name:      parameter.mountName
        			mountPath: parameter.appMountPath
        		}]
        	}]
        	initContainers: [{
        		name:  parameter.name
        		image: parameter.image
        		if parameter.cmd != _|_ {
        			command: parameter.cmd
        		}
        		if parameter.args != _|_ {
        			args: parameter.args
        		}
        		if parameter["env"] != _|_ {
        			env: parameter.env
        		}

        		// +patchKey=name
        		volumeMounts: [{
        			name:      parameter.mountName
        			mountPath: parameter.initMountPath
        		}]
        	}]
        	// +patchKey=name
        	volumes: [{
        		name: parameter.mountName
        		emptyDir: {}
        	}]
        }
        parameter: {
        	// +usage=Specify the name of init container
        	name: string

        	// +usage=Specify the image of init container
        	image: string

        	// +usage=Specify the commands run in the init container
        	cmd?: [...string]

        	// +usage=Specify the args run in the init container
        	args?: [...string]

        	// +usage=Specify the env run in the init container
        	env?: [...{
        		// +usage=Environment variable name
        		name: string
        		// +usage=The value of the environment variable
        		value?: string
        		// +usage=Specifies a source the value of this var should come from
        		valueFrom?: {
        			// +usage=Selects a key of a secret in the pod's namespace
        			secretKeyRef?: {
        				// +usage=The name of the secret in the pod's namespace to select from
        				name: string
        				// +usage=The key of the secret to select from. Must be a valid secret key
        				key: string
        			}
        			// +usage=Selects a key of a config map in the pod's namespace
        			configMapKeyRef?: {
        				// +usage=The name of the config map in the pod's namespace to select from
        				name: string
        				// +usage=The key of the config map to select from. Must be a valid secret key
        				key: string
        			}
        		}
        	}]

        	// +usage=Specify the mount name of shared volume
        	mountName: *"workdir" | string

        	// +usage=Specify the mount path of app container
        	appMountPath: string

        	// +usage=Specify the mount path of init container
        	initMountPath: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Patch the output following Json Merge Patch strategy, following RFC 7396.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: json-merge-patch
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        parameter: {...}
        // +patchStrategy=jsonMergePatch
        patch: parameter
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Patch the output following Json Patch strategy, following RFC 6902.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: json-patch
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        parameter: operations: [...{...}]
        // +patchStrategy=jsonPatch
        patch: parameter
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add labels on K8s pod for your workload which follows the pod spec in path 'spec.template'.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: labels
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        // +patchStrategy=jsonMergePatch
        patch: {
        	metadata: labels: {
        		for k, v in parameter {
        			"\(k)": v
        		}
        	}
        	if context.output.spec != _|_ && context.output.spec.template != _|_ {
        		spec: template: metadata: labels: {
        			for k, v in parameter {
        				"\(k)": v
        			}
        		}
        	}
        }
        parameter: [string]: string | null
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add lifecycle hooks for every container of K8s pod for your workload which follows the pod spec in path 'spec.template'.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: lifecycle
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: spec: template: spec: containers: [...{
        	lifecycle: {
        		if parameter.postStart != _|_ {
        			postStart: parameter.postStart
        		}
        		if parameter.preStop != _|_ {
        			preStop: parameter.preStop
        		}
        	}
        }]
        parameter: {
        	postStart?: #LifeCycleHandler
        	preStop?:   #LifeCycleHandler
        }
        #Port: int & >=1 & <=65535
        #LifeCycleHandler: {
        	exec?: command: [...string]
        	httpGet?: {
        		path?:  string
        		port:   #Port
        		host?:  string
        		scheme: *"HTTP" | "HTTPS"
        		httpHeaders?: [...{
        			name:  string
        			value: string
        		}]
        	}
        	tcpSocket?: {
        		port:  #Port
        		host?: string
        	}
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: nocalhost develop configuration.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: nocalhost
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        import (
        	"encoding/json"
        )

        outputs: nocalhostService: {
        	apiVersion: "v1"
        	kind:       "Service"
        	metadata: name: context.name
        	spec: {
        		selector: "app.oam.dev/component": context.name
        		ports: [
        			{
        				port:       parameter.port
        				targetPort: parameter.port
        			},
        		]
        		type: "ClusterIP"
        	}
        }
        patch: metadata: annotations: {
        	"dev.nocalhost/application-name":      context.appName
        	"dev.nocalhost/application-namespace": context.namespace
        	"dev.nocalhost":                       json.Marshal({
        		name:        context.name
        		serviceType: parameter.serviceType
        		containers: [
        			{
        				name: context.name
        				dev: {
        					if parameter.gitUrl != _|_ {
        						gitUrl: parameter.gitUrl
        					}
        					if parameter.image == "go" {
        						image: "nocalhost-docker.pkg.coding.net/nocalhost/dev-images/golang:latest"
        					}
        					if parameter.image == "java" {
        						image: "nocalhost-docker.pkg.coding.net/nocalhost/dev-images/java:latest"
        					}
        					if parameter.image == "python" {
        						image: "nocalhost-docker.pkg.coding.net/nocalhost/dev-images/python:latest"
        					}
        					if parameter.image == "node" {
        						image: "nocalhost-docker.pkg.coding.net/nocalhost/dev-images/node:latest"
        					}
        					if parameter.image == "ruby" {
        						image: "nocalhost-docker.pkg.coding.net/nocalhost/dev-images/ruby:latest"
        					}
        					if parameter.image != "go" && parameter.image != "java" && parameter.image != "python" && parameter.image != "node" && parameter.image != "ruby" {
        						image: parameter.image
        					}
        					shell:   parameter.shell
        					workDir: parameter.workDir
        					if parameter.storageClass != _|_ {
        						storageClass: parameter.storageClass
        					}
        					resources: {
        						limits:   parameter.resources.limits
        						requests: parameter.resources.requests
        					}
        					if parameter.persistentVolumeDirs != _|_ {
        						persistentVolumeDirs: [
        							for v in parameter.persistentVolumeDirs {
        								path:     v.path
        								capacity: v.capacity
        							},
        						]
        					}
        					if parameter.command != _|_ {
        						command: parameter.command
        					}
        					if parameter.debug != _|_ {
        						debug: parameter.debug
        					}
        					hotReload: parameter.hotReload
        					if parameter.sync != _|_ {
        						sync: parameter.sync
        					}
        					if parameter.env != _|_ {
        						env: [
        							for v in parameter.env {
        								name:  v.name
        								value: v.value
        							},
        						]
        					}
        					if parameter.portForward != _|_ {
        						portForward: parameter.portForward
        					}
        					if parameter.portForward == _|_ {
        						portForward: ["\(parameter.port)" + ":" + "\(parameter.port)"]
        					}
        				}
        			},
        		]
        	})
        }
        language: "go" | "java" | "python" | "node" | "ruby"
        parameter: {
        	port:          int
        	serviceType:   *"deployment" | string
        	gitUrl?:       string
        	image:         language | string
        	shell:         *"bash" | string
        	workDir:       *"/home/nocalhost-dev" | string
        	storageClass?: string
        	command: {
        		run:   *["sh", "run.sh"] | [...string]
        		debug: *["sh", "debug.sh"] | [...string]
        	}
        	debug?: remoteDebugPort?: int
        	hotReload: *true | bool
        	sync: {
        		type:              *"send" | string
        		filePattern:       *["./"] | [...string]
        		ignoreFilePattern: *[".git", ".vscode", ".idea", ".gradle", "build"] | [...string]
        	}
        	env?: [...{
        		name:  string
        		value: string
        	}]
        	portForward?: [...string]
        	persistentVolumeDirs?: [...{
        		path:     string
        		capacity: string
        	}]
        	resources: {
        		limits: {
        			memory: *"2Gi" | string
        			cpu:    *"2" | string
        		}
        		requests: {
        			memory: *"512Mi" | string
        			cpu:    *"0.5" | string
        		}
        	}
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: affinity specify node affinity and toleration on K8s pod for your workload which follows the pod spec in path 'spec.template'.
  labels:
    custom.definition.oam.dev/deprecated: "true"
    custom.definition.oam.dev/ui-hidden: "true"
  name: node-affinity
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: spec: template: spec: {
        	if parameter.affinity != _|_ {
        		affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: [{
        			matchExpressions: [
        				for k, v in parameter.affinity {
        					key:      k
        					operator: "In"
        					values:   v
        				},
        			]}]
        	}
        	if parameter.tolerations != _|_ {
        		tolerations: [
        			for k, v in parameter.tolerations {
        				effect:   "NoSchedule"
        				key:      k
        				operator: "Equal"
        				value:    v
        			}]
        	}
        }
        parameter: {
        	affinity?: [string]: [...string]
        	tolerations?: [string]: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Enable public web traffic for the component without creating a Service.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: pure-ingress
  namespace: default
spec:
  appliesToWorkloads: []
  conflictsWith: []
  podDisruptive: false
  schematic:
    cue:
      template: |
        outputs: ingress: {
        	apiVersion: "networking.k8s.io/v1beta1"
        	kind:       "Ingress"
        	metadata: name: context.name
        	spec: rules: [{
        		host: parameter.domain
        		http: paths: [
        			for k, v in parameter.http {
        				path: k
        				backend: {
        					serviceName: context.name
        					servicePort: v
        				}
        			},
        		]
        	}]
        }
        parameter: {
        	// +usage=Specify the domain you want to expose
        	domain: string

        	// +usage=Specify the mapping relationship between the http path and the workload port
        	http: [string]: int
        }
  status:
    customStatus: |-
      let igs = context.outputs.ingress.status.loadBalancer.ingress
      if igs == _|_ {
      	message: "No loadBalancer found, visiting by using 'vela port-forward " + context.appName + " --route'\n"
      }
      if len(igs) > 0 {
      	if igs[0].ip != _|_ {
      		message: "Visiting URL: " + context.outputs.ingress.spec.rules[0].host + ", IP: " + igs[0].ip
      	}
      	if igs[0].ip == _|_ {
      		message: "Visiting URL: " + context.outputs.ingress.spec.rules[0].host
      	}
      }
  workloadRefPath: ""
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Create a Persistent Volume Claim and mount the PVC as volume to the  first container in the pod. This definition is DEPRECATED, please specify pvc in 'storage' instead.
  labels:
    custom.definition.oam.dev/deprecated: "true"
  name: pvc
  namespace: default
spec:
  appliesToWorkloads:
    - deployments.apps
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: spec: template: spec: {
        	containers: [{
        		if parameter.volumeMode == "Block" {
        			// +patchKey=name
        			volumeDevices: [
        				for v in parameter.volumesToMount {
        					{
        						name:       v.name
        						devicePath: v.devicePath
        					}
        				},
        			]
        		}
        		if parameter.volumeMode == "Filesystem" {
        			// +patchKey=name
        			volumeMounts: [
        				for v in parameter.volumesToMount {
        					{
        						name:      v.name
        						mountPath: v.mountPath
        					}
        				},
        			]
        		}
        	}]

        	// +patchKey=name
        	volumes: [
        		for v in parameter.volumesToMount {
        			{
        				name: v.name
        				persistentVolumeClaim: claimName: parameter.claimName
        			}
        		},
        	]
        }
        outputs: "\(parameter.claimName)": {
        	apiVersion: "v1"
        	kind:       "PersistentVolumeClaim"
        	metadata: name: parameter.claimName
        	spec: {
        		accessModes: parameter.accessModes
        		volumeMode:  parameter.volumeMode
        		if parameter.volumeName != _|_ {
        			volumeName: parameter.volumeName
        		}

        		if parameter.storageClassName != _|_ {
        			storageClassName: parameter.storageClassName
        		}
        		resources: requests: storage: parameter.resources.requests.storage
        		if parameter.resources.limits.storage != _|_ {
        			resources: limits: storage: parameter.resources.limits.storage
        		}
        		if parameter.dataSourceRef != _|_ {
        			dataSourceRef: parameter.dataSourceRef
        		}
        		if parameter.dataSource != _|_ {
        			dataSource: parameter.dataSource
        		}
        		if parameter.selector != _|_ {
        			dataSource: parameter.selector
        		}
        	}
        }
        parameter: {
        	claimName:   string
        	volumeMode:  *"Filesystem" | string
        	volumeName?: string
        	accessModes: [...string]
        	storageClassName?: string
        	resources: {
        		requests: storage: =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        		limits?: storage:  =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        	}
        	dataSourceRef?: {
        		name:     string
        		kind:     string
        		apiGroup: string
        	}
        	dataSource?: {
        		name:     string
        		kind:     string
        		apiGroup: string
        	}
        	selector?: {
        		matchLabels?: [string]: string
        		matchExpressions?: {
        			key: string
        			values: [...string]
        			operator: string
        		}
        	}
        	volumesToMount: [...{
        		name: string
        		if volumeMode == "Block" {
        			devicePath: string
        		}
        		if volumeMode == "Filesystem" {
        			mountPath: string
        		}
        	}]
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add a datasource to Grafana
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: register-grafana-datasource
  namespace: default
spec:
  appliesToWorkloads: []
  conflictsWith: []
  podDisruptive: false
  schematic:
    cue:
      template: |
        outputs: registerdatasource: {
        	apiVersion: "grafana.extension.oam.dev/v1alpha1"
        	kind:       "DatasourceRegistration"
        	spec: {
        		grafana: {
        			service:                   parameter.grafanaServiceName
        			namespace:                 parameter.grafanaServiceNamespace
        			credentialSecret:          parameter.credentialSecret
        			credentialSecretNamespace: parameter.credentialSecretNamespace
        		}
        		datasource: {
        			name:      parameter.name
        			type:      parameter.type
        			access:    parameter.access
        			service:   parameter.service
        			namespace: parameter.namespace
        		}
        	}
        }
        parameter: {
        	grafanaServiceName:        string
        	grafanaServiceNamespace:   *"default" | string
        	credentialSecret:          string
        	credentialSecretNamespace: string
        	name:                      string
        	type:                      string
        	access:                    *"proxy" | string
        	service:                   string
        	namespace:                 *"default" | string
        }
  workloadRefPath: ""
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add resource requests and limits on K8s pod for your workload which follows the pod spec in path 'spec.template.'
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: resource
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: spec: template: spec: containers: [...{
        	resources: {
        		if parameter.cpu != _|_ && parameter.memory != _|_ && parameter.requests == _|_ && parameter.limits == _|_ {
        			requests: {
        				cpu:    parameter.cpu
        				memory: parameter.memory
        			}
        			limits: {
        				cpu:    parameter.cpu
        				memory: parameter.memory
        			}
        		}

        		if parameter.requests != _|_ {
        			requests: {
        				cpu:    parameter.requests.cpu
        				memory: parameter.requests.memory
        			}
        		}
        		if parameter.limits != _|_ {
        			limits: {
        				cpu:    parameter.limits.cpu
        				memory: parameter.limits.memory
        			}
        		}
        	}
        }]
        parameter: {
        	// +usage=Specify the amount of cpu for requests and limits
        	cpu?: *1 | number
        	// +usage=Specify the amount of memory for requests and limits
        	memory?: *"2048Mi" | =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        	// +usage=Specify the resources in requests
        	requests?: {
        		// +usage=Specify the amount of cpu for requests
        		cpu: *1 | number
        		// +usage=Specify the amount of memory for requests
        		memory: *"2048Mi" | =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        	}
        	// +usage=Specify the resources in limits
        	limits?: {
        		// +usage=Specify the amount of cpu for limits
        		cpu: *1 | number
        		// +usage=Specify the amount of memory for limits
        		memory: *"2048Mi" | =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        	}
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Manually scale K8s pod for your workload which follows the pod spec in path 'spec.template'.
  name: scaler
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: false
  schematic:
    cue:
      template: |
        parameter: {
        	// +usage=Specify the number of workload
        	replicas: *1 | int
        }
        // +patchStrategy=retainKeys
        patch: spec: replicas: parameter.replicas
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Specify serviceAccount for your workload which follows the pod spec in path 'spec.template'.
  name: service-account
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: false
  schematic:
    cue:
      template: |
        parameter: {
        	// +usage=Specify the name of ServiceAccount
        	name: string
        }
        // +patchStrategy=retainKeys
        patch: spec: template: spec: serviceAccountName: parameter.name
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Binding secrets of cloud resources to component env. This definition is DEPRECATED, please use 'storage' instead.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: service-binding
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  schematic:
    cue:
      template: |
        patch: spec: template: spec: {
        	// +patchKey=name
        	containers: [{
        		name: context.name
        		// +patchKey=name
        		env: [
        			for envName, v in parameter.envMappings {
        				name: envName
        				valueFrom: secretKeyRef: {
        					name: v.secret
        					if v["key"] != _|_ {
        						key: v.key
        					}
        					if v["key"] == _|_ {
        						key: envName
        					}
        				}
        			},
        		]
        	}]
        }
        parameter: {
        	// +usage=The mapping of environment variables to secret
        	envMappings: [string]: #KeySecret
        }
        #KeySecret: {
        	key?:   string
        	secret: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Inject a sidecar container to K8s pod for your workload which follows the pod spec in path 'spec.template'.
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: sidecar
  namespace: default
spec:
  appliesToWorkloads:
    - '*'
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: {
        	// +patchKey=name
        	spec: template: spec: containers: [{
        		name:  parameter.name
        		image: parameter.image
        		if parameter.cmd != _|_ {
        			command: parameter.cmd
        		}
        		if parameter.args != _|_ {
        			args: parameter.args
        		}
        		if parameter["env"] != _|_ {
        			env: parameter.env
        		}
        		if parameter["volumes"] != _|_ {
        			volumeMounts: [ for v in parameter.volumes {
        				{
        					mountPath: v.path
        					name:      v.name
        				}
        			}]
        		}
        		if parameter["livenessProbe"] != _|_ {
        			livenessProbe: parameter.livenessProbe
        		}

        		if parameter["readinessProbe"] != _|_ {
        			readinessProbe: parameter.readinessProbe
        		}
        	}]
        }
        parameter: {
        	// +usage=Specify the name of sidecar container
        	name: string

        	// +usage=Specify the image of sidecar container
        	image: string

        	// +usage=Specify the commands run in the sidecar
        	cmd?: [...string]

        	// +usage=Specify the args in the sidecar
        	args?: [...string]

        	// +usage=Specify the env in the sidecar
        	env?: [...{
        		// +usage=Environment variable name
        		name: string
        		// +usage=The value of the environment variable
        		value?: string
        		// +usage=Specifies a source the value of this var should come from
        		valueFrom?: {
        			// +usage=Selects a key of a secret in the pod's namespace
        			secretKeyRef?: {
        				// +usage=The name of the secret in the pod's namespace to select from
        				name: string
        				// +usage=The key of the secret to select from. Must be a valid secret key
        				key: string
        			}
        			// +usage=Selects a key of a config map in the pod's namespace
        			configMapKeyRef?: {
        				// +usage=The name of the config map in the pod's namespace to select from
        				name: string
        				// +usage=The key of the config map to select from. Must be a valid secret key
        				key: string
        			}
        		}
        	}]

        	// +usage=Specify the shared volume path
        	volumes?: [...{
        		name: string
        		path: string
        	}]

        	// +usage=Instructions for assessing whether the container is alive.
        	livenessProbe?: #HealthProbe

        	// +usage=Instructions for assessing whether the container is in a suitable state to serve traffic.
        	readinessProbe?: #HealthProbe
        }
        #HealthProbe: {

        	// +usage=Instructions for assessing container health by executing a command. Either this attribute or the httpGet attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the httpGet attribute and the tcpSocket attribute.
        	exec?: {
        		// +usage=A command to be executed inside the container to assess its health. Each space delimited token of the command is a separate array element. Commands exiting 0 are considered to be successful probes, whilst all other exit codes are considered failures.
        		command: [...string]
        	}

        	// +usage=Instructions for assessing container health by executing an HTTP GET request. Either this attribute or the exec attribute or the tcpSocket attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the tcpSocket attribute.
        	httpGet?: {
        		// +usage=The endpoint, relative to the port, to which the HTTP GET request should be directed.
        		path: string
        		// +usage=The TCP socket within the container to which the HTTP GET request should be directed.
        		port: int
        		httpHeaders?: [...{
        			name:  string
        			value: string
        		}]
        	}

        	// +usage=Instructions for assessing container health by probing a TCP socket. Either this attribute or the exec attribute or the httpGet attribute MUST be specified. This attribute is mutually exclusive with both the exec attribute and the httpGet attribute.
        	tcpSocket?: {
        		// +usage=The TCP socket within the container that should be probed to assess container health.
        		port: int
        	}

        	// +usage=Number of seconds after the container is started before the first probe is initiated.
        	initialDelaySeconds: *0 | int

        	// +usage=How often, in seconds, to execute the probe.
        	periodSeconds: *10 | int

        	// +usage=Number of seconds after which the probe times out.
        	timeoutSeconds: *1 | int

        	// +usage=Minimum consecutive successes for the probe to be considered successful after having failed.
        	successThreshold: *1 | int

        	// +usage=Number of consecutive failures required to determine the container is not alive (liveness probe) or not ready (readiness probe).
        	failureThreshold: *3 | int
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add storages on K8s pod for your workload which follows the pod spec in path 'spec.template'.
  name: storage
  namespace: default
spec:
  appliesToWorkloads:
    - deployments.apps
  podDisruptive: true
  schematic:
    cue:
      template: |
        pvcVolumesList: *[
        		for v in parameter.pvc {
        		{
        			name: "pvc-" + v.name
        			persistentVolumeClaim: claimName: v.name
        		}
        	},
        ] | []
        configMapVolumesList: *[
        			for v in parameter.configMap if v.mountPath != _|_ {
        		{
        			name: "configmap-" + v.name
        			configMap: {
        				defaultMode: v.defaultMode
        				name:        v.name
        				if v.items != _|_ {
        					items: v.items
        				}
        			}
        		}
        	},
        ] | []
        secretVolumesList: *[
        			for v in parameter.secret if v.mountPath != _|_ {
        		{
        			name: "secret-" + v.name
        			secret: {
        				defaultMode: v.defaultMode
        				secretName:  v.name
        				if v.items != _|_ {
        					items: v.items
        				}
        			}
        		}
        	},
        ] | []
        emptyDirVolumesList: *[
        			for v in parameter.emptyDir {
        		{
        			name: "emptydir-" + v.name
        			emptyDir: medium: v.medium
        		}
        	},
        ] | []
        pvcVolumeMountsList: *[
        			for v in parameter.pvc {
        		if v.volumeMode == "Filesystem" {
        			{
        				name:      "pvc-" + v.name
        				mountPath: v.mountPath
        			}
        		}
        	},
        ] | []
        configMapVolumeMountsList: *[
        				for v in parameter.configMap if v.mountPath != _|_ {
        		{
        			name:      "configmap-" + v.name
        			mountPath: v.mountPath
        		}
        	},
        ] | []
        configMapEnvMountsList: *[
        			for v in parameter.configMap if v.mountToEnv != _|_ {
        		{
        			name: v.mountToEnv.envName
        			valueFrom: configMapKeyRef: {
        				name: v.name
        				key:  v.mountToEnv.configMapKey
        			}
        		}
        	},
        ] | []
        configMountToEnvsList: *[
        			for v in parameter.configMap if v.mountToEnvs != _|_ for k in v.mountToEnvs {
        		{
        			name: k.envName
        			valueFrom: configMapKeyRef: {
        				name: v.name
        				key:  k.configMapKey
        			}
        		}
        	},
        ] | []
        secretVolumeMountsList: *[
        			for v in parameter.secret if v.mountPath != _|_ {
        		{
        			name:      "secret-" + v.name
        			mountPath: v.mountPath
        		}
        	},
        ] | []
        secretEnvMountsList: *[
        			for v in parameter.secret if v.mountToEnv != _|_ {
        		{
        			name: v.mountToEnv.envName
        			valueFrom: secretKeyRef: {
        				name: v.name
        				key:  v.mountToEnv.secretKey
        			}
        		}
        	},
        ] | []
        secretMountToEnvsList: *[
        			for v in parameter.secret if v.mountToEnvs != _|_ for k in v.mountToEnvs {
        		{
        			name: k.envName
        			valueFrom: secretKeyRef: {
        				name: v.name
        				key:  k.secretKey
        			}
        		}
        	},
        ] | []
        emptyDirVolumeMountsList: *[
        				for v in parameter.emptyDir {
        		{
        			name:      "emptydir-" + v.name
        			mountPath: v.mountPath
        		}
        	},
        ] | []
        volumeDevicesList: *[
        			for v in parameter.pvc if v.volumeMode == "Block" {
        		{
        			name:       "pvc-" + v.name
        			devicePath: v.mountPath
        		}
        	},
        ] | []
        patch: spec: template: spec: {
        	// +patchKey=name
        	volumes: pvcVolumesList + configMapVolumesList + secretVolumesList + emptyDirVolumesList

        	containers: [{
        		// +patchKey=name
        		env: configMapEnvMountsList + secretEnvMountsList + configMountToEnvsList + secretMountToEnvsList
        		// +patchKey=name
        		volumeDevices: volumeDevicesList
        		// +patchKey=name
        		volumeMounts: pvcVolumeMountsList + configMapVolumeMountsList + secretVolumeMountsList + emptyDirVolumeMountsList
        	}, ...]

        }
        outputs: {
        	for v in parameter.pvc {
        		if v.mountOnly == false {
        			"pvc-\(v.name)": {
        				apiVersion: "v1"
        				kind:       "PersistentVolumeClaim"
        				metadata: name: v.name
        				spec: {
        					accessModes: v.accessModes
        					volumeMode:  v.volumeMode
        					if v.volumeName != _|_ {
        						volumeName: v.volumeName
        					}
        					if v.storageClassName != _|_ {
        						storageClassName: v.storageClassName
        					}

        					if v.resources.requests.storage == _|_ {
        						resources: requests: storage: "8Gi"
        					}
        					if v.resources.requests.storage != _|_ {
        						resources: requests: storage: v.resources.requests.storage
        					}
        					if v.resources.limits.storage != _|_ {
        						resources: limits: storage: v.resources.limits.storage
        					}
        					if v.dataSourceRef != _|_ {
        						dataSourceRef: v.dataSourceRef
        					}
        					if v.dataSource != _|_ {
        						dataSource: v.dataSource
        					}
        					if v.selector != _|_ {
        						dataSource: v.selector
        					}
        				}
        			}
        		}
        	}

        	for v in parameter.configMap {
        		if v.mountOnly == false {
        			"configmap-\(v.name)": {
        				apiVersion: "v1"
        				kind:       "ConfigMap"
        				metadata: name: v.name
        				if v.data != _|_ {
        					data: v.data
        				}
        			}
        		}
        	}

        	for v in parameter.secret {
        		if v.mountOnly == false {
        			"secret-\(v.name)": {
        				apiVersion: "v1"
        				kind:       "Secret"
        				metadata: name: v.name
        				if v.data != _|_ {
        					data: v.data
        				}
        				if v.stringData != _|_ {
        					stringData: v.stringData
        				}
        			}
        		}
        	}

        }
        parameter: {
        	// +usage=Declare pvc type storage
        	pvc?: [...{
        		name:              string
        		mountOnly:         *false | bool
        		mountPath:         string
        		volumeMode:        *"Filesystem" | string
        		volumeName?:       string
        		accessModes:       *["ReadWriteOnce"] | [...string]
        		storageClassName?: string
        		resources?: {
        			requests: storage: =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        			limits?: storage:  =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        		}
        		dataSourceRef?: {
        			name:     string
        			kind:     string
        			apiGroup: string
        		}
        		dataSource?: {
        			name:     string
        			kind:     string
        			apiGroup: string
        		}
        		selector?: {
        			matchLabels?: [string]: string
        			matchExpressions?: {
        				key: string
        				values: [...string]
        				operator: string
        			}
        		}
        	}]

        	// +usage=Declare config map type storage
        	configMap?: [...{
        		name:      string
        		mountOnly: *false | bool
        		mountToEnv?: {
        			envName:      string
        			configMapKey: string
        		}
        		mountToEnvs?: [...{
        			envName:      string
        			configMapKey: string
        		}]
        		mountPath?:  string
        		defaultMode: *420 | int
        		readOnly:    *false | bool
        		data?: {...}
        		items?: [...{
        			key:  string
        			path: string
        			mode: *511 | int
        		}]
        	}]

        	// +usage=Declare secret type storage
        	secret?: [...{
        		name:      string
        		mountOnly: *false | bool
        		mountToEnv?: {
        			envName:   string
        			secretKey: string
        		}
        		mountToEnvs?: [...{
        			envName:   string
        			secretKey: string
        		}]
        		mountPath?:  string
        		defaultMode: *420 | int
        		readOnly:    *false | bool
        		stringData?: {...}
        		data?: {...}
        		items?: [...{
        			key:  string
        			path: string
        			mode: *511 | int
        		}]
        	}]

        	// +usage=Declare empty dir type storage
        	emptyDir?: [...{
        		name:      string
        		mountPath: string
        		medium:    *"" | "Memory"
        	}]
        }
---
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  annotations:
    definition.oam.dev/description: Add volumes on K8s pod for your workload which follows the pod spec in path 'spec.template'. This definition is DEPRECATED, please use 'storage' instead.
  labels:
    custom.definition.oam.dev/deprecated: "true"
  name: volumes
  namespace: default
spec:
  appliesToWorkloads:
    - deployments.apps
  podDisruptive: true
  schematic:
    cue:
      template: |
        patch: {
        	// +patchKey=name
        	spec: template: spec: volumes: [
        		for v in parameter.volumes {
        			{
        				name: v.name
        				if v.type == "pvc" {
        					persistentVolumeClaim: claimName: v.claimName
        				}
        				if v.type == "configMap" {
        					configMap: {
        						defaultMode: v.defaultMode
        						name:        v.cmName
        						if v.items != _|_ {
        							items: v.items
        						}
        					}
        				}
        				if v.type == "secret" {
        					secret: {
        						defaultMode: v.defaultMode
        						secretName:  v.secretName
        						if v.items != _|_ {
        							items: v.items
        						}
        					}
        				}
        				if v.type == "emptyDir" {
        					emptyDir: medium: v.medium
        				}
        			}
        		},
        	]
        }
        parameter: {
        	// +usage=Declare volumes and volumeMounts
        	volumes?: [...{
        		name: string
        		// +usage=Specify volume type, options: "pvc","configMap","secret","emptyDir"
        		type: "pvc" | "configMap" | "secret" | "emptyDir"
        		if type == "pvc" {
        			claimName: string
        		}
        		if type == "configMap" {
        			defaultMode: *420 | int
        			cmName:      string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "secret" {
        			defaultMode: *420 | int
        			secretName:  string
        			items?: [...{
        				key:  string
        				path: string
        				mode: *511 | int
        			}]
        		}
        		if type == "emptyDir" {
        			medium: *"" | "Memory"
        		}
        	}]
        }
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: release-name-vela-core-admission
  namespace: default
webhooks:
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /validating-core-oam-dev-v1beta1-approllout
    failurePolicy: Ignore
    name: validating.core.oam.dev.v1beta1.approllouts
    sideEffects: None
    rules:
      - apiGroups:
          - core.oam.dev
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - approllouts
        scope: Namespaced
    admissionReviewVersions:
      - v1beta1
      - v1
    timeoutSeconds: 5
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /validating-core-oam-dev-v1alpha2-traitdefinitions
    failurePolicy: Ignore
    name: validating.core.oam.dev.v1alpha2.traitdefinitions
    sideEffects: None
    admissionReviewVersions:
      - v1beta1
      - v1
    rules:
      - apiGroups:
          - core.oam.dev
        apiVersions:
          - v1alpha2
        operations:
          - CREATE
          - UPDATE
        resources:
          - traitdefinitions
        scope: Cluster
    timeoutSeconds: 5
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /validate-standard-oam-dev-v1alpha1-podspecworkload
    failurePolicy: Fail
    name: vcontainerized.kb.io
    admissionReviewVersions:
      - v1beta1
      - v1
    sideEffects: None
    rules:
      - apiGroups:
          - standard.oam.dev
        apiVersions:
          - v1alpha1
        operations:
          - CREATE
          - UPDATE
        resources:
          - podspecworkloads
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /validating-core-oam-dev-v1beta1-applications
    failurePolicy: Ignore
    name: validating.core.oam.dev.v1beta1.applications
    admissionReviewVersions:
      - v1beta1
      - v1
    sideEffects: None
    rules:
      - apiGroups:
          - core.oam.dev
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - applications
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /validating-core-oam-dev-v1beta1-componentdefinitions
    failurePolicy: Ignore
    name: validating.core.oam-dev.v1beta1.componentdefinitions
    sideEffects: None
    admissionReviewVersions:
      - v1beta1
      - v1
    rules:
      - apiGroups:
          - core.oam.dev
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - componentdefinitions
  - clientConfig:
      caBundle: Cg==
      service:
        name: vela-core-webhook
        namespace: default
        path: /validating-core-oam-dev-v1beta1-initializers
    failurePolicy: Ignore
    name: validating.core.oam-dev.v1beta1.initializers
    sideEffects: None
    admissionReviewVersions:
      - v1beta1
      - v1
    rules:
      - apiGroups:
          - core.oam.dev
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
          - DELETE
        resources:
          - initializers
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Apply components of an application in parallel for your workflow steps
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: apply-application-in-parallel
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        output: op.#ApplyApplicationInParallel & {}
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Apply application for your workflow steps
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: apply-application
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        // apply application
        output: op.#ApplyApplication & {}
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Apply raw kubernetes objects for your workflow steps
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: apply-object
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        apply: op.#Apply & {
        	value:   parameter.value
        	cluster: parameter.cluster
        }
        parameter: {
        	// +usage=Specify the value of the object
        	value: {...}
        	// +usage=Specify the cluster of the object
        	cluster: *"" | string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Apply remaining components and traits
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: apply-remaining
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        // apply remaining components and traits
        apply: op.#ApplyRemaining & {
        	parameter
        }
        parameter: {
        	// +usage=Declare the name of the component
        	exceptions?: [...string]
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: check or install depends-on Application
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: depends-on-app
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        	"encoding/yaml"
        )

        dependsOn: op.#Read & {
        	value: {
        		apiVersion: "core.oam.dev/v1beta1"
        		kind:       "Application"
        		metadata: {
        			name:      parameter.name
        			namespace: parameter.namespace
        		}
        	}
        }
        load: op.#Steps & {
        	if dependsOn.err != _|_ {
        		configMap: op.#Read & {
        			value: {
        				apiVersion: "v1"
        				kind:       "ConfigMap"
        				metadata: {
        					name:      parameter.name
        					namespace: parameter.namespace
        				}
        			}
        		}         @step(1)
        		template: configMap.value.data["application"]
        		apply:    op.#Apply & {
        			value: yaml.Unmarshal(template)
        		}     @step(2)
        		wait: op.#ConditionalWait & {
        			continue: apply.value.status.status == "running"
        		} @step(3)
        	}

        	if dependsOn.err == _|_ {
        		wait: op.#ConditionalWait & {
        			continue: dependsOn.value.status.status == "running"
        		}
        	}
        }
        parameter: {
        	// +usage=Specify the name of the dependent Application
        	name: string
        	// +usage=Specify the namespace of the dependent Application
        	namespace: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Deploy cloud resource and bind secret to clusters
  name: deploy-cloud-resource
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        app: op.#DeployCloudResource & {
        	env:    parameter.env
        	policy: parameter.policy
        	// context.namespace indicates the namespace of the app
        	namespace: context.namespace
        	// context.namespace indicates the name of the app
        	name: context.name
        }
        parameter: {
        	// +usage=Declare the name of the env-binding policy, if empty, the first env-binding policy will be used
        	policy: *"" | string
        	// +usage=Declare the name of the env in policy
        	env: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Deploy components with policies.
  name: deploy
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        deploy: op.#Deploy & {
        	policies:                 parameter.policies
        	parallelism:              parameter.parallelism
        	ignoreTerraformComponent: parameter.ignoreTerraformComponent
        }
        parameter: {
        	//+usage=If set false, the workflow will be suspend before this step.
        	auto: *true | bool
        	//+usage=Declare the policies used for this step.
        	policies?: [...string]
        	//+usage=Maximum number of concurrent delivered components.
        	parallelism: *5 | int
        	//+usage=If set false, this step will apply the components with the terraform workload.
        	ignoreTerraformComponent: *true | bool
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Deploy env binding component to target env
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: deploy2env
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        app: op.#ApplyEnvBindApp & {
        	env:      parameter.env
        	policy:   parameter.policy
        	parallel: parameter.parallel
        	app:      context.name
        	// context.namespace indicates the namespace of the app
        	namespace: context.namespace
        }
        parameter: {
        	// +usage=Declare the name of the env-binding policy, if empty, the first env-binding policy will be used
        	policy: *"" | string
        	// +usage=Declare the name of the env in policy
        	env: string
        	// +usage=components are applied in parallel
        	parallel: *false | bool
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Deploy application to runtime clusters
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: deploy2runtime
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        app: op.#Steps & {
        	load: op.#Load @step(1)
        	clusters: [...string]
        	if parameter.clusters == _|_ {
        		listClusters: op.#ListClusters @step(2)
        		clusters:     listClusters.outputs.clusters
        	}
        	if parameter.clusters != _|_ {
        		clusters: parameter.clusters
        	}

        	apply: op.#Steps & {
        		for _, cluster_ in clusters {
        			for name, c in load.value {
        				"\(cluster_)-\(name)": op.#ApplyComponent & {
        					value:   c
        					cluster: cluster_
        				}
        			}
        		}
        	} @step(3)
        }
        parameter: {
        	// +usage=Declare the runtime clusters to apply, if empty, all runtime clusters will be used
        	clusters?: [...string]
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Export data to config map for your workflow steps
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: export2config
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        apply: op.#Apply & {
        	value: {
        		apiVersion: "v1"
        		kind:       "ConfigMap"
        		metadata: {
        			name: parameter.configName
        			if parameter.namespace != _|_ {
        				namespace: parameter.namespace
        			}
        			if parameter.namespace == _|_ {
        				namespace: context.namespace
        			}
        		}
        		data: parameter.data
        	}
        	cluster: parameter.cluster
        }
        parameter: {
        	// +usage=Specify the name of the config map
        	configName: string
        	// +usage=Specify the namespace of the config map
        	namespace?: string
        	// +usage=Specify the data of config map
        	data: {}
        	// +usage=Specify the cluster of the config map
        	cluster: *"" | string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Export data to secret for your workflow steps
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: export2secret
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        apply: op.#Apply & {
        	value: {
        		apiVersion: "v1"
        		kind:       "Secret"
        		if parameter.type != _|_ {
        			type: parameter.type
        		}
        		metadata: {
        			name: parameter.secretName
        			if parameter.namespace != _|_ {
        				namespace: parameter.namespace
        			}
        			if parameter.namespace == _|_ {
        				namespace: context.namespace
        			}
        		}
        		stringData: parameter.data
        	}
        	cluster: parameter.cluster
        }
        parameter: {
        	// +usage=Specify the name of the secret
        	secretName: string
        	// +usage=Specify the namespace of the secret
        	namespace?: string
        	// +usage=Specify the type of the secret
        	type?: string
        	// +usage=Specify the data of secret
        	data: {}
        	// +usage=Specify the cluster of the config map
        	cluster: *"" | string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Generate a JDBC connection based on Component of alibaba-rds
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: generate-jdbc-connection
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        	"encoding/base64"
        )

        output: op.#Read & {
        	value: {
        		apiVersion: "v1"
        		kind:       "Secret"
        		metadata: {
        			name: parameter.name
        			if parameter.namespace != _|_ {
        				namespace: parameter.namespace
        			}
        		}
        	}
        }
        dbHost:   op.#ConvertString & {bt: base64.Decode(null, output.value.data["DB_HOST"])}
        dbPort:   op.#ConvertString & {bt: base64.Decode(null, output.value.data["DB_PORT"])}
        dbName:   op.#ConvertString & {bt: base64.Decode(null, output.value.data["DB_NAME"])}
        username: op.#ConvertString & {bt: base64.Decode(null, output.value.data["DB_USER"])}
        password: op.#ConvertString & {bt: base64.Decode(null, output.value.data["DB_PASSWORD"])}
        env: [
        	{name: "url", value:      "jdbc://" + dbHost.str + ":" + dbPort.str + "/" + dbName.str + "?characterEncoding=utf8&useSSL=false"},
        	{name: "username", value: username.str},
        	{name: "password", value: password.str},
        ]
        parameter: {
        	// +usage=Specify the name of the secret generated by database component
        	name: string
        	// +usage=Specify the namespace of the secret generated by database component
        	namespace?: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Send message to webhook
  name: notification
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        	"encoding/base64"
        )

        parameter: {
        	lark?: {
        		// +usage=Specify the the lark url, you can either sepcify it in value or use secretRef
        		url: {
        			value: string
        		} | {
        			secretRef: {
        				// +usage=name is the name of the secret
        				name: string
        				// +usage=key is the key in the secret
        				key: string
        			}
        		}
        		// +useage=Specify the message that you want to sent
        		message: {
        			// +usage=msg_type can be text, post, image, interactive, share_chat, share_user, audio, media, file, sticker
        			msg_type: string
        			// +usage=content should be json encode string
        			content: string
        		}
        	}

        	dingding?: {
        		// +usage=Specify the the dingding url, you can either sepcify it in value or use secretRef
        		url: {
        			value: string
        		} | {
        			secretRef: {
        				// +usage=name is the name of the secret
        				name: string
        				// +usage=key is the key in the secret
        				key: string
        			}
        		}
        		// +useage=Specify the message that you want to sent
        		message: {
        			text?: *null | {
        				content: string
        			}
        			// +usage=msgType can be text, link, mardown, actionCard, feedCard
        			msgtype: *"text" | "link" | "markdown" | "actionCard" | "feedCard"
        			link?:   *null | {
        				text?:       string
        				title?:      string
        				messageUrl?: string
        				picUrl?:     string
        			}
        			markdown?: *null | {
        				text:  string
        				title: string
        			}
        			at?: *null | {
        				atMobiles?: *null | [...string]
        				isAtAll?:   bool
        			}
        			actionCard?: *null | {
        				text:           string
        				title:          string
        				hideAvatar:     string
        				btnOrientation: string
        				singleTitle:    string
        				singleURL:      string
        				btns:           *null | [...*null | {
        					title:     string
        					actionURL: string
        				}]
        			}
        			feedCard?: *null | {
        				links: *null | [...*null | {
        					text?:       string
        					title?:      string
        					messageUrl?: string
        					picUrl?:     string
        				}]
        			}
        		}
        	}

        	slack?: {
        		// +usage=Specify the the slack url, you can either sepcify it in value or use secretRef
        		url: {
        			value: string
        		} | {
        			secretRef: {
        				// +usage=name is the name of the secret
        				name: string
        				// +usage=key is the key in the secret
        				key: string
        			}
        		}
        		// +useage=Specify the message that you want to sent
        		message: {
        			text:         string
        			blocks?:      *null | [...block]
        			attachments?: *null | {
        				blocks?: *null | [...block]
        				color?:  string
        			}
        			thread_ts?: string
        			mrkdwn?:    *true | bool
        		}
        	}

        	email?: {
        		// +usage=Specify the email info that you want to send from
        		from: {
        			// +usage=Specify the email address that you want to send from
        			address: string
        			// +usage=The alias is the email alias to show after sending the email
        			alias?: string
        			// +usage=Specify the password of the email, you can either sepcify it in value or use secretRef
        			password: {
        				value: string
        			} | {
        				secretRef: {
        					// +usage=name is the name of the secret
        					name: string
        					// +usage=key is the key in the secret
        					key: string
        				}
        			}
        			// +usage=Specify the host of your email
        			host: string
        			// +usage=Specify the port of the email host, default to 587
        			port: *587 | int
        		}
        		// +usage=Specify the email address that you want to send to
        		to: [...string]
        		// +usage=Specify the content of the email
        		content: {
        			// +usage=Specify the subject of the email
        			subject: string
        			// +usage=Specify the context body of the email
        			body: string
        		}
        	}
        }
        block: {
        	type:      string
        	block_id?: string
        	elements?: [...{
        		type:       string
        		action_id?: string
        		url?:       string
        		value?:     string
        		style?:     string
        		text?:      textType
        		confirm?: {
        			title:   textType
        			text:    textType
        			confirm: textType
        			deny:    textType
        			style?:  string
        		}
        		options?: [...option]
        		initial_options?: [...option]
        		placeholder?:  textType
        		initial_date?: string
        		image_url?:    string
        		alt_text?:     string
        		option_groups?: [...option]
        		max_selected_items?: int
        		initial_value?:      string
        		multiline?:          bool
        		min_length?:         int
        		max_length?:         int
        		dispatch_action_config?: trigger_actions_on?: [...string]
        		initial_time?: string
        	}]
        }
        textType: {
        	type:      string
        	text:      string
        	emoji?:    bool
        	verbatim?: bool
        }
        option: {
        	text:         textType
        	value:        string
        	description?: textType
        	url?:         string
        }
        // send webhook notification
        ding: op.#Steps & {
        	if parameter.dingding != _|_ {
        		if parameter.dingding.url.value != _|_ {
        			ding1: op.#DingTalk & {
        				message: parameter.dingding.message
        				dingUrl: parameter.dingding.url.value
        			}
        		}
        		if parameter.dingding.url.secretRef != _|_ && parameter.dingding.url.value == _|_ {
        			read: op.#Read & {
        				value: {
        					apiVersion: "v1"
        					kind:       "Secret"
        					metadata: {
        						name:      parameter.dingding.url.secretRef.name
        						namespace: context.namespace
        					}
        				}
        			}

        			decoded:     base64.Decode(null, read.value.data[parameter.dingding.url.secretRef.key])
        			stringValue: op.#ConvertString & {bt: decoded}
        			ding2:       op.#DingTalk & {
        				message: parameter.dingding.message
        				dingUrl: stringValue.str
        			}
        		}
        	}
        }
        lark: op.#Steps & {
        	if parameter.lark != _|_ {
        		if parameter.lark.url.value != _|_ {
        			lark1: op.#Lark & {
        				message: parameter.lark.message
        				larkUrl: parameter.lark.url.value
        			}
        		}
        		if parameter.lark.url.secretRef != _|_ && parameter.lark.url.value == _|_ {
        			read: op.#Read & {
        				value: {
        					apiVersion: "v1"
        					kind:       "Secret"
        					metadata: {
        						name:      parameter.lark.url.secretRef.name
        						namespace: context.namespace
        					}
        				}
        			}

        			decoded:     base64.Decode(null, read.value.data[parameter.lark.url.secretRef.key])
        			stringValue: op.#ConvertString & {bt: decoded}
        			lark2:       op.#Lark & {
        				message: parameter.lark.message
        				larkUrl: stringValue.str
        			}
        		}
        	}
        }
        slack: op.#Steps & {
        	if parameter.slack != _|_ {
        		if parameter.slack.url.value != _|_ {
        			slack1: op.#Slack & {
        				message:  parameter.slack.message
        				slackUrl: parameter.slack.url.value
        			}
        		}
        		if parameter.slack.url.secretRef != _|_ && parameter.slack.url.value == _|_ {
        			read: op.#Read & {
        				value: {
        					kind:       "Secret"
        					apiVersion: "v1"
        					metadata: {
        						name:      parameter.slack.url.secretRef.name
        						namespace: context.namespace
        					}
        				}
        			}

        			decoded:     base64.Decode(null, read.value.data[parameter.slack.url.secretRef.key])
        			stringValue: op.#ConvertString & {bt: decoded}
        			slack2:      op.#Slack & {
        				message:  parameter.slack.message
        				slackUrl: stringValue.str
        			}
        		}
        	}
        }
        email: op.#Steps & {
        	if parameter.email != _|_ {
        		if parameter.email.from.password.value != _|_ {
        			email1: op.#SendEmail & {
        				from: {
        					address: parameter.email.from.address
        					if parameter.email.from.alias != _|_ {
        						alias: parameter.email.from.alias
        					}
        					password: parameter.email.from.password.value
        					host:     parameter.email.from.host
        					port:     parameter.email.from.port
        				}
        				to:      parameter.email.to
        				content: parameter.email.content
        			}
        		}

        		if parameter.email.from.password.secretRef != _|_ && parameter.email.from.password.value == _|_ {
        			read: op.#Read & {
        				value: {
        					kind:       "Secret"
        					apiVersion: "v1"
        					metadata: {
        						name:      parameter.email.from.password.secretRef.name
        						namespace: context.namespace
        					}
        				}
        			}

        			decoded:     base64.Decode(null, read.value.data[parameter.email.from.password.secretRef.key])
        			stringValue: op.#ConvertString & {bt: decoded}
        			email2:      op.#SendEmail & {
        				from: {
        					address: parameter.email.from.address
        					if parameter.email.from.alias != _|_ {
        						alias: parameter.email.from.alias
        					}
        					password: stringValue.str
        					host:     parameter.email.from.host
        					port:     parameter.email.from.port
        				}
        				to:      parameter.email.to
        				content: parameter.email.content
        			}
        		}
        	}
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Read objects for your workflow steps
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: read-object
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        output: {
        	if parameter.apiVersion == _|_ && parameter.kind == _|_ {
        		op.#Read & {
        			value: {
        				apiVersion: "core.oam.dev/v1beta1"
        				kind:       "Application"
        				metadata: {
        					name: parameter.name
        					if parameter.namespace != _|_ {
        						namespace: parameter.namespace
        					}
        				}
        			}
        			cluster: parameter.cluster
        		}
        	}
        	if parameter.apiVersion != _|_ || parameter.kind != _|_ {
        		op.#Read & {
        			value: {
        				apiVersion: parameter.apiVersion
        				kind:       parameter.kind
        				metadata: {
        					name: parameter.name
        					if parameter.namespace != _|_ {
        						namespace: parameter.namespace
        					}
        				}
        			}
        			cluster: parameter.cluster
        		}
        	}
        }
        parameter: {
        	// +usage=Specify the apiVersion of the object, defaults to core.oam.dev/v1beta1
        	apiVersion?: string
        	// +usage=Specify the kind of the object, defaults to Application
        	kind?: string
        	// +usage=Specify the name of the object
        	name: string
        	// +usage=Specify the namespace of the object
        	namespace?: string
        	// +usage=Specify the cluster of the object
        	cluster: *"" | string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Sync secrets created by terraform component to runtime clusters so that runtime clusters can share the created cloud resource.
  name: share-cloud-resource
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        )

        app: op.#ShareCloudResource & {
        	env:        parameter.env
        	policy:     parameter.policy
        	placements: parameter.placements
        	// context.namespace indicates the namespace of the app
        	namespace: context.namespace
        	// context.namespace indicates the name of the app
        	name: context.name
        }
        parameter: {
        	// +usage=Declare the location to bind
        	placements: [...{
        		namespace?: string
        		cluster?:   string
        	}]
        	// +usage=Declare the name of the env-binding policy, if empty, the first env-binding policy will be used
        	policy: *"" | string
        	// +usage=Declare the name of the env in policy
        	env: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: step group
  labels:
    custom.definition.oam.dev/ui-hidden: "true"
  name: step-group
  namespace: default
spec:
  schematic:
    cue:
      template: |
        // no parameters
        parameter: {}
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Suspend your workflow
  name: suspend
  namespace: default
spec:
  schematic:
    cue:
      template: |
        parameter: {
        	// +usage=Specify the wait duration time to resume workflow such as "30s", "1min" or "2m15s"
        	duration?: string
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Send message to webhook. This definition is DEPRECATED, please use 'notification' instead.
  labels:
    custom.definition.oam.dev/deprecated: "true"
  name: webhook-notification
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        	"encoding/base64"
        )

        parameter: {
        	dingding?: {
        		url: value | secretRef
        		message: {
        			text?: *null | {
        				content: string
        			}
        			// +usage=msgType can be text, link, mardown, actionCard, feedCard
        			msgtype: string
        			link?:   *null | {
        				text?:       string
        				title?:      string
        				messageUrl?: string
        				picUrl?:     string
        			}
        			markdown?: *null | {
        				text:  string
        				title: string
        			}
        			at?: *null | {
        				atMobiles?: *null | [...string]
        				isAtAll?:   bool
        			}
        			actionCard?: *null | {
        				text:           string
        				title:          string
        				hideAvatar:     string
        				btnOrientation: string
        				singleTitle:    string
        				singleURL:      string
        				btns:           *null | [...*null | {
        					title:     string
        					actionURL: string
        				}]
        			}
        			feedCard?: *null | {
        				links: *null | [...*null | {
        					text?:       string
        					title?:      string
        					messageUrl?: string
        					picUrl?:     string
        				}]
        			}
        		}
        	}

        	slack?: {
        		url: value | secretRef
        		message: {
        			text:         string
        			blocks?:      *null | [...block]
        			attachments?: *null | {
        				blocks?: *null | [...block]
        				color?:  string
        			}
        			thread_ts?: string
        			mrkdwn?:    *true | bool
        		}
        	}

        	email?: {
        		from: {
        			address:  string
        			alias?:   string
        			password: value | secretRef
        			host:     string
        			port:     *587 | int
        		}
        		to: [...string]
        		content: {
        			subject: string
        			body:    string
        		}
        	}
        }
        block: {
        	type:      string
        	block_id?: string
        	elements?: [...{
        		type:       string
        		action_id?: string
        		url?:       string
        		value?:     string
        		style?:     string
        		text?:      textType
        		confirm?: {
        			title:   textType
        			text:    textType
        			confirm: textType
        			deny:    textType
        			style?:  string
        		}
        		options?: [...option]
        		initial_options?: [...option]
        		placeholder?:  textType
        		initial_date?: string
        		image_url?:    string
        		alt_text?:     string
        		option_groups?: [...option]
        		max_selected_items?: int
        		initial_value?:      string
        		multiline?:          bool
        		min_length?:         int
        		max_length?:         int
        		dispatch_action_config?: trigger_actions_on?: [...string]
        		initial_time?: string
        	}]
        }
        textType: {
        	type:      string
        	text:      string
        	emoji?:    bool
        	verbatim?: bool
        }
        option: {
        	text:         textType
        	value:        string
        	description?: textType
        	url?:         string
        }
        secretRef: {
        	name: string
        	key:  string
        }
        value: string
        // send webhook notification
        ding: op.#Steps & {
        	if parameter.dingding != _|_ {
        		if parameter.dingding.url.value != _|_ {
        			ding1: op.#DingTalk & {
        				message: parameter.dingding.message
        				dingUrl: parameter.dingding.url.value
        			}
        		}
        		if parameter.dingding.url.secretRef != _|_ && parameter.dingding.url.value == _|_ {
        			read: op.#Read & {
        				value: {
        					apiVersion: "v1"
        					kind:       "Secret"
        					metadata: {
        						name:      parameter.dingding.url.secretRef.name
        						namespace: context.namespace
        					}
        				}
        			}

        			decoded:     base64.Decode(null, read.value.data[parameter.dingding.url.secretRef.key])
        			stringValue: op.#ConvertString & {bt: decoded}
        			ding2:       op.#DingTalk & {
        				message: parameter.dingding.message
        				dingUrl: stringValue.str
        			}
        		}
        	}
        }
        slack: op.#Steps & {
        	if parameter.slack != _|_ {
        		if parameter.slack.url.value != _|_ {
        			slack1: op.#Slack & {
        				message:  parameter.slack.message
        				slackUrl: parameter.slack.url.value
        			}
        		}
        		if parameter.slack.url.secretRef != _|_ && parameter.slack.url.value == _|_ {
        			read: op.#Read & {
        				value: {
        					kind:       "Secret"
        					apiVersion: "v1"
        					metadata: {
        						name:      parameter.slack.url.secretRef.name
        						namespace: context.namespace
        					}
        				}
        			}

        			decoded:     base64.Decode(null, read.value.data[parameter.slack.url.secretRef.key])
        			stringValue: op.#ConvertString & {bt: decoded}
        			slack2:      op.#Slack & {
        				message:  parameter.slack.message
        				slackUrl: stringValue.str
        			}
        		}
        	}
        }
        email: op.#Steps & {
        	if parameter.email != _|_ {
        		if parameter.email.from.password.value != _|_ {
        			email1: op.#SendEmail & {
        				from: {
        					address:  parameter.email.from.value
        					alias:    parameter.email.from.alias
        					password: parameter.email.from.password.value
        					host:     parameter.email.from.host
        					port:     parameter.email.from.port
        				}
        				to:      parameter.email.to
        				content: parameter.email.content
        			}
        		}

        		if parameter.email.from.password.secretRef != _|_ && parameter.email.from.password.value == _|_ {
        			read: op.#Read & {
        				value: {
        					kind:       "Secret"
        					apiVersion: "v1"
        					metadata: {
        						name:      parameter.email.from.password.secretRef.name
        						namespace: context.namespace
        					}
        				}
        			}

        			decoded:     base64.Decode(null, read.value.data[parameter.email.from.password.secretRef.key])
        			stringValue: op.#ConvertString & {bt: decoded}
        			email2:      op.#SendEmail & {
        				from: {
        					address:  parameter.email.from.value
        					alias:    parameter.email.from.alias
        					password: stringValue.str
        					host:     parameter.email.from.host
        					port:     parameter.email.from.port
        				}
        				to:      parameter.email.to
        				content: parameter.email.content
        			}
        		}
        	}
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkflowStepDefinition
metadata:
  annotations:
    definition.oam.dev/description: Send webhook request to the url
  name: webhook
  namespace: default
spec:
  schematic:
    cue:
      template: |
        import (
        	"vela/op"
        	"encoding/json"
        	"encoding/base64"
        )

        data: op.#Steps & {
        	if parameter.data == _|_ {
        		read: op.#Read & {
        			value: {
        				apiVersion: "core.oam.dev/v1beta1"
        				kind:       "Application"
        				metadata: {
        					name:      context.name
        					namespace: context.namespace
        				}
        			}
        		}      @step(1)
        		value: json.Marshal(read.value) @step(2)
        	}
        	if parameter.data != _|_ {
        		value: json.Marshal(parameter.data) @step(3)
        	}
        }
        webhook: op.#Steps & {
        	if parameter.url.value != _|_ {
        		http: op.#HTTPPost & {
        			url: parameter.url.value
        			request: {
        				body: data.value
        				header: "Content-Type": "application/json"
        			}
        		} @step(4)
        	}
        	if parameter.url.secretRef != _|_ && parameter.url.value == _|_ {
        		read: op.#Read & {
        			value: {
        				apiVersion: "v1"
        				kind:       "Secret"
        				metadata: {
        					name:      parameter.url.secretRef.name
        					namespace: context.namespace
        				}
        			}
        		} @step(5)

        		decoded:     base64.Decode(null, read.value.data[parameter.url.secretRef.key]) @step(6)
        		stringValue: op.#ConvertString & {bt:                                          decoded} @step(7)
        		http:        op.#HTTPPost & {
        			url: stringValue.str
        			request: {
        				body: data.value
        				header: "Content-Type": "application/json"
        			}
        		} @step(8)
        	}
        }
        parameter: {
        	// +usage=Specify the webhook url
        	url: {
        		value: string
        	} | {
        		secretRef: {
        			// +usage=name is the name of the secret
        			name: string
        			// +usage=key is the key in the secret
        			key: string
        		}
        	}
        	// +usage=Specify the data you want to send
        	data?: {...}
        }
---
apiVersion: core.oam.dev/v1beta1
kind: WorkloadDefinition
metadata:
  annotations:
    definition.oam.dev/description: autodetects.core.oam.dev is the default workload type of ComponentDefinition
  name: autodetects.core.oam.dev
  namespace: default
spec:
  definitionRef:
    name: autodetects.core.oam.dev
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-vela-core-admission
  namespace: BuFaWE
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-admission
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-vela-core-cluster-gateway-admission
  namespace: BuFaWE
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-cluster-gateway-admission
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-vela-core-admission
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-admission
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - validatingwebhookconfigurations
      - mutatingwebhookconfigurations
    verbs:
      - get
      - update
  - apiGroups:
      - apiextensions.k8s.io
    resources:
      - customresourcedefinitions
    verbs:
      - get
      - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-vela-core-admission
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-admission
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-vela-core-admission
subjects:
  - kind: ServiceAccount
    name: release-name-vela-core-admission
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-vela-core-admission
  namespace: BuFaWE
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-admission
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-vela-core-cluster-gateway-admission
  namespace: BuFaWE
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-cluster-gateway-admission
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-vela-core-admission
  namespace: BuFaWE
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-admission
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-vela-core-admission
subjects:
  - kind: ServiceAccount
    name: release-name-vela-core-admission
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-vela-core-cluster-gateway-admission
  namespace: BuFaWE
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-cluster-gateway-admission
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-vela-core-cluster-gateway-admission
subjects:
  - kind: ServiceAccount
    name: release-name-vela-core-cluster-gateway-admission
    namespace: default
---
apiVersion: v1
kind: Pod
metadata:
  name: release-name-application-test
  namespace: BuFaWE
  annotations:
    helm.sh/hook: test
    helm.sh/hook-delete-policy: hook-succeeded
spec:
  serviceAccountName: release-name-vela-core
  containers:
    - name: release-name-application-test
      image: oamdev/alpine-k8s:1.18.2
      imagePullPolicy: IfNotPresent
      command:
        - /bin/bash
        - -ec
        - |2
          set -e

          echo "Waiting application is ready..."

          echo "waiting for application being Ready"
          kubectl -n default wait --for=condition=Ready applications.core.oam.dev helm-test-vela-app --timeout=3m
          echo "application is Ready"

          # wait for deploy being created
          echo "waiting for deployment being available"
          kubectl -n default wait --for=condition=available deployments helm-test-express-server --timeout 3m
          echo "deployment being available"

          # wait for ingress being created
          while ! [ `kubectl -n default get ing helm-test-express-server | grep -v NAME | wc -l` = 1 ]; do
            echo "waiting for ingress being created"
            sleep 1
          done



          echo "Application and its components are created"
  restartPolicy: Never
---
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-vela-core-admission-create
  namespace: BuFaWE
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-admission-create
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
spec:
  template:
    metadata:
      name: release-name-vela-core-admission-create
      labels:
        app: vela-core-admission-create
        helm.sh/chart: vela-core-1.4.1
        app.kubernetes.io/name: vela-core
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: 1.4.1
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
        - name: create
          image: oamdev/kube-webhook-certgen:v2.4.0
          imagePullPolicy: IfNotPresent
          args:
            - create
            - --host=vela-core-webhook,vela-core-webhook.default.svc
            - --namespace=default
            - --secret-name=release-name-vela-core-admission
            - --key-name=tls.key
            - --cert-name=tls.crt
      restartPolicy: OnFailure
      serviceAccountName: release-name-vela-core-admission
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
---
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-vela-core-admission-patch
  namespace: BuFaWE
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: vela-core-admission-patch
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
spec:
  template:
    metadata:
      name: release-name-vela-core-admission-patch
      labels:
        app: vela-core-admission-patch
        helm.sh/chart: vela-core-1.4.1
        app.kubernetes.io/name: vela-core
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: 1.4.1
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
        - name: patch
          image: oamdev/kube-webhook-certgen:v2.4.0
          imagePullPolicy: IfNotPresent
          args:
            - patch
            - --webhook-name=release-name-vela-core-admission
            - --namespace=default
            - --secret-name=release-name-vela-core-admission
            - --patch-failure-policy=Fail
      restartPolicy: OnFailure
      serviceAccountName: release-name-vela-core-admission
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
---
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-vela-core-cluster-gateway-tls-secret-create
  namespace: BuFaWE
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: release-name-vela-core-cluster-gateway-tls-secret-create
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
spec:
  template:
    metadata:
      name: release-name-vela-core-cluster-gateway-tls-secret-create
      labels:
        app: release-name-vela-core-cluster-gateway-tls-secret-create
        helm.sh/chart: vela-core-1.4.1
        app.kubernetes.io/name: vela-core
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: 1.4.1
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
        - name: create
          image: oamdev/kube-webhook-certgen:v2.4.0
          imagePullPolicy: IfNotPresent
          args:
            - create
            - --host=release-name-cluster-gateway-service,release-name-cluster-gateway-service.default.svc
            - --namespace=default
            - --secret-name=release-name-vela-core-cluster-gateway-tls-v2
            - --cert-name=tls.crt
            - --key-name=tls.key
      restartPolicy: OnFailure
      serviceAccountName: release-name-vela-core-cluster-gateway-admission
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
---
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-vela-core-cluster-gateway-tls-secret-patch
  namespace: BuFaWE
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: release-name-vela-core-cluster-gateway-tls-secret-patch
    helm.sh/chart: vela-core-1.4.1
    app.kubernetes.io/name: vela-core
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 1.4.1
    app.kubernetes.io/managed-by: Helm
spec:
  template:
    metadata:
      name: release-name-vela-core-cluster-gateway-tls-secret-patch
      labels:
        app: release-name-vela-core-cluster-gateway-tls-secret-patch
        helm.sh/chart: vela-core-1.4.1
        app.kubernetes.io/name: vela-core
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: 1.4.1
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
        - name: patch
          image: oamdev/cluster-gateway:v1.4.0
          imagePullPolicy: IfNotPresent
          command:
            - /patch
          args:
            - --secret-namespace=default
            - --secret-name=release-name-vela-core-cluster-gateway-tls-v2
      restartPolicy: OnFailure
      serviceAccountName: release-name-vela-core
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
---
apiVersion: core.oam.dev/v1beta1
kind: Application
metadata:
  annotations:
    helm.sh/hook: test-success
    helm.sh/hook-delete-policy: hook-succeeded
  name: helm-test-vela-app
  namespace: default
spec:
  components:
    - name: helm-test-express-server
      type: webservice
      properties:
        image: oamdev/hello-world:v1
        port: 8000
      traits:
        - type: ingress
          properties:
            domain: testsvc.example.com
            http:
              /: 8000
