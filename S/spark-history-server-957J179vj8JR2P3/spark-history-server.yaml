apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-spark-history-server
  labels:
    app.kubernetes.io/name: spark-history-server
    helm.sh/chart: spark-history-server-1.0.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-spark-history-server
  labels:
    app.kubernetes.io/name: spark-history-server
    helm.sh/chart: spark-history-server-1.0.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  enablePVC: "true"
  enableGCS: "false"
  enableS3: "false"
  enableWASBS: "false"
  eventsDir: /
  existingClaimName: nfs-pvc
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
  labels:
    app.kubernetes.io/name: nfs
    helm.sh/chart: nfs-0.1.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  capacity:
    storage: 1Mi
  accessModes:
    - ReadWriteMany
  nfs:
    server: release-name-nfs.default.svc.cluster.local
    path: /
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
  labels:
    app.kubernetes.io/name: nfs
    helm.sh/chart: nfs-0.1.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: ""
  resources:
    requests:
      storage: 1Mi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: release-name-nfs
  labels:
    app.kubernetes.io/name: nfs
    helm.sh/chart: nfs-0.1.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-spark-history-server-cr
  labels:
    app.kubernetes.io/name: spark-history-server
    helm.sh/chart: spark-history-server-1.0.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - deployments
      - pods
    verbs:
      - '*'
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-spark-history-server-crb
subjects:
  - kind: ServiceAccount
    name: release-name-spark-history-server
    namespace: default
roleRef:
  kind: ClusterRole
  name: release-name-spark-history-server-cr
  apiGroup: rbac.authorization.k8s.io
---
kind: Service
apiVersion: v1
metadata:
  name: release-name-nfs
  labels:
    app.kubernetes.io/name: nfs
    helm.sh/chart: nfs-0.1.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  ports:
    - name: nfs
      port: 2049
    - name: mountd
      port: 20048
    - name: rpcbind
      port: 111
  selector:
    app.kubernetes.io/name: nfs
    app.kubernetes.io/instance: release-name
---
apiVersion: v1
kind: Service
metadata:
  name: release-name-spark-history-server
  labels:
    app.kubernetes.io/name: spark-history-server
    helm.sh/chart: spark-history-server-1.0.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  type: LoadBalancer
  ports:
    - port: 18080
      targetPort: historyport
      protocol: TCP
      name: historyport
  selector:
    app.kubernetes.io/name: spark-history-server
    app.kubernetes.io/instance: release-name
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-nfs
  labels:
    app.kubernetes.io/name: nfs
    helm.sh/chart: nfs-0.1.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nfs
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nfs
        app.kubernetes.io/instance: release-name
    spec:
      containers:
        - name: release-name-nfs
          image: registry.cn-hangzhou.aliyuncs.com/kubeapps/k8s-gcr-volume-nfs:0.8
          ports:
            - name: nfs
              containerPort: 2049
            - name: mountd
              containerPort: 20048
            - name: rpcbind
              containerPort: 111
          securityContext:
            privileged: true
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                "": NET_RAW
            readOnlyRootFilesystem: true
          volumeMounts:
            - mountPath: /exports
              name: mypvc
      volumes:
        - name: mypvc
          persistentVolumeClaim:
            claimName: release-name-nfs
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-spark-history-server
  labels:
    app.kubernetes.io/name: spark-history-server
    helm.sh/chart: spark-history-server-1.0.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: spark-history-server
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: spark-history-server
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: release-name-spark-history-server
      containers:
        - name: spark-history-server
          image: lightbend/spark-history-server:2.4.0
          imagePullPolicy: IfNotPresent
          env:
            - name: HADOOP_CONF_DIR
              value: /etc/hadoop
            - name: SPARK_NO_DAEMONIZE
              value: "true"
          ports:
            - name: historyport
              containerPort: 18080
              protocol: TCP
          resources:
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/sh
            - -c
            - |
              if [ "$enablePVC" == "true" ]; then
                export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                -Dspark.history.fs.logDirectory=file:/mnt/$eventsDir";
              elif [ "$enableGCS" == "true" ]; then
                export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                -Dspark.hadoop.google.cloud.auth.service.account.json.keyfile=/etc/secrets/$key \
                -Dspark.history.fs.logDirectory=$logDirectory";
              elif [ "$enableS3" == "true" ]; then
                export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                  -Dspark.history.fs.logDirectory=$logDirectory \
                  -Dspark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem";
                if [ "$enableIAM" == "false" ]; then
                  export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                  -Dspark.hadoop.fs.s3a.access.key=$(cat /etc/secrets/${accessKeyName}) \
                  -Dspark.hadoop.fs.s3a.secret.key=$(cat /etc/secrets/${secretKeyName})";
                fi;
              elif [ "$enableWASBS" == "true" ]; then
                container=$(cat /etc/secrets/${containerKeyName})
                storageAccount=$(cat /etc/secrets/${storageAccountNameKeyName})

                export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                  -Dspark.history.fs.logDirectory=$logDirectory \
                  -Dspark.hadoop.fs.defaultFS=wasbs://$container@$storageAccount.blob.core.windows.net \
                  -Dspark.hadoop.fs.wasbs.impl=org.apache.hadoop.fs.azure.NativeAzureFileSystem \
                  -Dspark.hadoop.fs.AbstractFileSystem.wasbs.impl=org.apache.hadoop.fs.azure.Wasbs";
                if [ "$sasKeyMode" == "true" ]; then
                  export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                    -Dspark.hadoop.fs.azure.local.sas.key.mode=true \
                    -Dspark.hadoop.fs.azure.sas.$container.$storageAccount.blob.core.windows.net=$(cat /etc/secrets/${sasKeyName})";
                else
                  export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                    -Dspark.hadoop.fs.azure.account.key.$storageAccount.blob.core.windows.net=$(cat /etc/secrets/${storageAccountKeyName})";
                fi;
              else
                export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                -Dspark.history.fs.logDirectory=$logDirectory";
              fi; /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer;
          envFrom:
            - configMapRef:
                name: release-name-spark-history-server
          livenessProbe:
            httpGet:
              path: /
              port: historyport
          readinessProbe:
            httpGet:
              path: /
              port: historyport
          volumeMounts:
            - name: data
              mountPath: /mnt//
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: nfs-pvc
---
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-spark-history-server
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: hook-succeeded
  labels:
    app.kubernetes.io/name: spark-history-server
    helm.sh/chart: spark-history-server-1.0.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  template:
    spec:
      serviceAccountName: release-name-spark-history-server
      restartPolicy: OnFailure
      containers:
        - name: main
          image: lightbend/curl:7.47.0
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
            - -c
            - 'curl -ik -X DELETE -H ''Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)'' -H ''Accept: application/json'' -H ''Content-Type: application/json'' https://kubernetes.default.svc/api/v1/deployments/release-name-spark-history-server'
