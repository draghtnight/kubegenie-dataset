apiVersion: v1
kind: ServiceAccount
metadata:
  name: rally-db-init
  namespace: zw2oFEKLFrAP
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rally-ks-endpoints
  namespace: zw2oFEKLFrAP
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rally-ks-service
  namespace: zw2oFEKLFrAP
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rally-ks-user
  namespace: zw2oFEKLFrAP
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rally-manage-db
  namespace: zw2oFEKLFrAP
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rally-run-task
  namespace: zw2oFEKLFrAP
---
apiVersion: v1
kind: Secret
metadata:
  name: rally-etc
type: Opaque
data:
  rally.conf: W2RhdGFiYXNlXQpjb25uZWN0aW9uID0gbXlzcWwrcHlteXNxbDovL3JhbGx5OnBhc3N3b3JkQG1hcmlhZGIuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDozMzA2L3JhbGx5CltrZXlzdG9uZV9hdXRodG9rZW5dCmF1dGhfdHlwZSA9IHBhc3N3b3JkCmF1dGhfdXJpID0gaHR0cDovL2tleXN0b25lLWFwaS5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsOjUwMDAvdjMKYXV0aF91cmwgPSBodHRwOi8va2V5c3RvbmUtYXBpLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWw6NTAwMC92MwphdXRoX3ZlcnNpb24gPSB2MwptZW1jYWNoZV9zZWNyZXRfa2V5ID0gN0pvUEFNSjNoSGJjVWNWdGJDR2Z5QkJQRHF4N2pzQkZLb2w1aG45SW9leDliZUlmMElxaTdOM2NTYWlhWGxMcwptZW1jYWNoZWRfc2VydmVycyA9IG1lbWNhY2hlZC5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsOjExMjExCnBhc3N3b3JkID0gcGFzc3dvcmQKcHJvamVjdF9kb21haW5fbmFtZSA9IHNlcnZpY2UKcHJvamVjdF9uYW1lID0gc2VydmljZQpyZWdpb25fbmFtZSA9IFJlZ2lvbk9uZQp1c2VyX2RvbWFpbl9uYW1lID0gc2VydmljZQp1c2VybmFtZSA9IHJhbGx5CltyYWxseV9hcGldCmJpbmRfcG9ydCA9IDkzMTIK
---
apiVersion: v1
kind: Secret
metadata:
  name: rally-db-admin
type: Opaque
data:
  DB_CONNECTION: bXlzcWwrcHlteXNxbDovL3Jvb3Q6cGFzc3dvcmRAbWFyaWFkYi5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsOjMzMDYvcmFsbHk=
---
apiVersion: v1
kind: Secret
metadata:
  name: rally-db-user
type: Opaque
data:
  DB_CONNECTION: bXlzcWwrcHlteXNxbDovL3JhbGx5OnBhc3N3b3JkQG1hcmlhZGIuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDozMzA2L3JhbGx5
---
apiVersion: v1
kind: Secret
metadata:
  name: rally-keystone-admin
type: Opaque
data:
  OS_AUTH_URL: aHR0cDovL2tleXN0b25lLWFwaS5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsOjUwMDAvdjM=
  OS_REGION_NAME: UmVnaW9uT25l
  OS_INTERFACE: aW50ZXJuYWw=
  OS_PROJECT_DOMAIN_NAME: ZGVmYXVsdA==
  OS_PROJECT_NAME: YWRtaW4=
  OS_USER_DOMAIN_NAME: ZGVmYXVsdA==
  OS_USERNAME: YWRtaW4=
  OS_PASSWORD: cGFzc3dvcmQ=
  OS_DEFAULT_DOMAIN: ZGVmYXVsdA==
---
apiVersion: v1
kind: Secret
metadata:
  name: rally-keystone-user
type: Opaque
data:
  OS_AUTH_URL: aHR0cDovL2tleXN0b25lLWFwaS5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsOjUwMDAvdjM=
  OS_REGION_NAME: UmVnaW9uT25l
  OS_INTERFACE: aW50ZXJuYWw=
  OS_PROJECT_DOMAIN_NAME: c2VydmljZQ==
  OS_PROJECT_NAME: c2VydmljZQ==
  OS_USER_DOMAIN_NAME: c2VydmljZQ==
  OS_USERNAME: cmFsbHk=
  OS_PASSWORD: cGFzc3dvcmQ=
  OS_DEFAULT_DOMAIN: ZGVmYXVsdA==
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rally-bin
data:
  db-init.py: |
    #!/usr/bin/env python

    # Creates db and user for an OpenStack Service:
    # Set ROOT_DB_CONNECTION and DB_CONNECTION environment variables to contain
    # SQLAlchemy strings for the root connection to the database and the one you
    # wish the service to use. Alternatively, you can use an ini formatted config
    # at the location specified by OPENSTACK_CONFIG_FILE, and extract the string
    # from the key OPENSTACK_CONFIG_DB_KEY, in the section specified by
    # OPENSTACK_CONFIG_DB_SECTION.

    import os
    import sys
    try:
        import ConfigParser
        PARSER_OPTS = {}
    except ImportError:
        import configparser as ConfigParser
        PARSER_OPTS = {"strict": False}
    import logging
    from sqlalchemy import create_engine

    # Create logger, console handler and formatter
    logger = logging.getLogger('OpenStack-Helm DB Init')
    logger.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # Set the formatter and add the handler
    ch.setFormatter(formatter)
    logger.addHandler(ch)


    # Get the connection string for the service db root user
    if "ROOT_DB_CONNECTION" in os.environ:
        db_connection = os.environ['ROOT_DB_CONNECTION']
        logger.info('Got DB root connection')
    else:
        logger.critical('environment variable ROOT_DB_CONNECTION not set')
        sys.exit(1)

    mysql_x509 = os.getenv('MARIADB_X509', "")
    ssl_args = {}
    if mysql_x509:
        ssl_args = {'ssl': {'ca': '/etc/mysql/certs/ca.crt',
                    'key': '/etc/mysql/certs/tls.key',
                    'cert': '/etc/mysql/certs/tls.crt'}}

    # Get the connection string for the service db
    if "OPENSTACK_CONFIG_FILE" in os.environ:
        os_conf = os.environ['OPENSTACK_CONFIG_FILE']
        if "OPENSTACK_CONFIG_DB_SECTION" in os.environ:
            os_conf_section = os.environ['OPENSTACK_CONFIG_DB_SECTION']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_SECTION not set')
            sys.exit(1)
        if "OPENSTACK_CONFIG_DB_KEY" in os.environ:
            os_conf_key = os.environ['OPENSTACK_CONFIG_DB_KEY']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_KEY not set')
            sys.exit(1)
        try:
            config = ConfigParser.RawConfigParser(**PARSER_OPTS)
            logger.info("Using {0} as db config source".format(os_conf))
            config.read(os_conf)
            logger.info("Trying to load db config from {0}:{1}".format(
                os_conf_section, os_conf_key))
            user_db_conn = config.get(os_conf_section, os_conf_key)
            logger.info("Got config from {0}".format(os_conf))
        except:
            logger.critical("Tried to load config from {0} but failed.".format(os_conf))
            raise
    elif "DB_CONNECTION" in os.environ:
        user_db_conn = os.environ['DB_CONNECTION']
        logger.info('Got config from DB_CONNECTION env var')
    else:
        logger.critical('Could not get db config, either from config file or env var')
        sys.exit(1)

    # Root DB engine
    try:
        root_engine_full = create_engine(db_connection)
        root_user = root_engine_full.url.username
        root_password = root_engine_full.url.password
        drivername = root_engine_full.url.drivername
        host = root_engine_full.url.host
        port = root_engine_full.url.port
        root_engine_url = ''.join([drivername, '://', root_user, ':', root_password, '@', host, ':', str (port)])
        root_engine = create_engine(root_engine_url, connect_args=ssl_args)
        connection = root_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1} as {2}".format(
            host, port, root_user))
    except:
        logger.critical('Could not connect to database as root user')
        raise

    # User DB engine
    try:
        user_engine = create_engine(user_db_conn, connect_args=ssl_args)
        # Get our user data out of the user_engine
        database = user_engine.url.database
        user = user_engine.url.username
        password = user_engine.url.password
        logger.info('Got user db config')
    except:
        logger.critical('Could not get user database config')
        raise

    # Create DB
    try:
        root_engine.execute("CREATE DATABASE IF NOT EXISTS {0}".format(database))
        logger.info("Created database {0}".format(database))
    except:
        logger.critical("Could not create database {0}".format(database))
        raise

    # Create DB User
    try:
        root_engine.execute(
            "GRANT ALL ON `{0}`.* TO \'{1}\'@\'%%\' IDENTIFIED BY \'{2}\' {3}".format(
                database, user, password, mysql_x509))
        logger.info("Created user {0} for {1}".format(user, database))
    except:
        logger.critical("Could not create user {0} for {1}".format(user, database))
        raise

    # Test connection
    try:
        connection = user_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1}/{2} as {3}".format(
            host, port, database, user))
    except:
        logger.critical('Could not connect to database as user')
        raise

    logger.info('Finished DB Management')
  ks-service.sh: |
    #!/bin/bash

    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    set -ex

    # Service boilerplate description
    OS_SERVICE_DESC="${OS_REGION_NAME}: ${OS_SERVICE_NAME} (${OS_SERVICE_TYPE}) service"

    # Get Service ID if it exists
    unset OS_SERVICE_ID

    # FIXME - There seems to be an issue once in a while where the
    # openstack service list fails and encounters an error message such as:
    #   Unable to establish connection to
    #   https://keystone-api.openstack.svc.cluster.local:5000/v3/auth/tokens:
    #   ('Connection aborted.', OSError("(104, 'ECONNRESET')",))
    # During an upgrade scenario, this would cause the OS_SERVICE_ID to be blank
    # and it would attempt to create a new service when it was not needed.
    # This duplciate service would sometimes be used by other services such as
    # Horizon and would give an 'Invalid Service Catalog' error.
    # This loop allows for a 'retry' of the openstack service list in an
    # attempt to get the service list as expected if it does ecounter an error.
    # This loop and recheck can be reverted once the underlying issue is addressed.

    # If OS_SERVICE_ID is blank then wait a few seconds to give it
    # additional time and try again
    for i in $(seq 3)
    do
      OS_SERVICE_ID=$( openstack service list -f csv --quote none | \
                       grep ",${OS_SERVICE_NAME},${OS_SERVICE_TYPE}$" | \
                       sed -e "s/,${OS_SERVICE_NAME},${OS_SERVICE_TYPE}//g" )

      # If the service was found, go ahead and exit successfully.
      if [[ -n "${OS_SERVICE_ID}" ]]; then
        exit 0
      fi

      sleep 2
    done

    # If we've reached this point and a Service ID was not found,
    # then create the service
    OS_SERVICE_ID=$(openstack service create -f value -c id \
                    --name="${OS_SERVICE_NAME}" \
                    --description "${OS_SERVICE_DESC}" \
                    --enable \
                    "${OS_SERVICE_TYPE}")
  ks-endpoints.sh: |
    #!/bin/bash

    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    set -ex

    # Get Service ID
    OS_SERVICE_ID=$( openstack service list -f csv --quote none | \
                      grep ",${OS_SERVICE_NAME},${OS_SERVICE_TYPE}$" | \
                        sed -e "s/,${OS_SERVICE_NAME},${OS_SERVICE_TYPE}//g" )

    # Get Endpoint ID if it exists
    OS_ENDPOINT_ID=$( openstack endpoint list  -f csv --quote none | \
                      grep "^[a-z0-9]*,${OS_REGION_NAME},${OS_SERVICE_NAME},${OS_SERVICE_TYPE},True,${OS_SVC_ENDPOINT}," | \
                      awk -F ',' '{ print $1 }' )

    # Making sure only a single endpoint exists for a service within a region
    if [ "$(echo $OS_ENDPOINT_ID | wc -w)" -gt "1" ]; then
      echo "More than one endpoint found, cleaning up"
      for ENDPOINT_ID in $OS_ENDPOINT_ID; do
        openstack endpoint delete ${ENDPOINT_ID}
      done
      unset OS_ENDPOINT_ID
    fi

    # Determine if Endpoint needs updated
    if [[ ${OS_ENDPOINT_ID} ]]; then
      OS_ENDPOINT_URL_CURRENT=$(openstack endpoint show ${OS_ENDPOINT_ID} -f value -c url)
      if [ "${OS_ENDPOINT_URL_CURRENT}" == "${OS_SERVICE_ENDPOINT}" ]; then
        echo "Endpoints Match: no action required"
        OS_ENDPOINT_UPDATE="False"
      else
        echo "Endpoints Dont Match: removing existing entries"
        openstack endpoint delete ${OS_ENDPOINT_ID}
        OS_ENDPOINT_UPDATE="True"
      fi
    else
      OS_ENDPOINT_UPDATE="True"
    fi

    # Update Endpoint if required
    if [[ "${OS_ENDPOINT_UPDATE}" == "True" ]]; then
      OS_ENDPOINT_ID=$( openstack endpoint create -f value -c id \
        --region="${OS_REGION_NAME}" \
        "${OS_SERVICE_ID}" \
        ${OS_SVC_ENDPOINT} \
        "${OS_SERVICE_ENDPOINT}" )
    fi

    # Display the Endpoint
    openstack endpoint show ${OS_ENDPOINT_ID}
  ks-user.sh: |
    #!/bin/bash

    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    set -ex

    shopt -s nocasematch

    if [[ "${SERVICE_OS_PROJECT_DOMAIN_NAME}" == "Default" ]]
    then
      PROJECT_DOMAIN_ID="default"
    else
      # Manage project domain
      PROJECT_DOMAIN_ID=$(openstack domain create --or-show --enable -f value -c id \
        --description="Domain for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_PROJECT_DOMAIN_NAME}" \
        "${SERVICE_OS_PROJECT_DOMAIN_NAME}")
    fi

    if [[ "${SERVICE_OS_USER_DOMAIN_NAME}" == "Default" ]]
    then
      USER_DOMAIN_ID="default"
    else
      # Manage user domain
      USER_DOMAIN_ID=$(openstack domain create --or-show --enable -f value -c id \
        --description="Domain for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_USER_DOMAIN_NAME}" \
        "${SERVICE_OS_USER_DOMAIN_NAME}")
    fi

    shopt -u nocasematch

    # Manage user project
    USER_PROJECT_DESC="Service Project for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_PROJECT_DOMAIN_NAME}"
    USER_PROJECT_ID=$(openstack project create --or-show --enable -f value -c id \
        --domain="${PROJECT_DOMAIN_ID}" \
        --description="${USER_PROJECT_DESC}" \
        "${SERVICE_OS_PROJECT_NAME}");

    # Manage user
    USER_DESC="Service User for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_USER_DOMAIN_NAME}/${SERVICE_OS_SERVICE_NAME}"
    USER_ID=$(openstack user create --or-show --enable -f value -c id \
        --domain="${USER_DOMAIN_ID}" \
        --project-domain="${PROJECT_DOMAIN_ID}" \
        --project="${USER_PROJECT_ID}" \
        --description="${USER_DESC}" \
        "${SERVICE_OS_USERNAME}");

    # Manage user password (we do this in a seperate step to ensure the password is updated if required)
    set +x
    echo "Setting user password via: openstack user set --password=xxxxxxx ${USER_ID}"
    openstack user set --password="${SERVICE_OS_PASSWORD}" "${USER_ID}"
    set -x

    function ks_assign_user_role () {
      if [[ "$SERVICE_OS_ROLE" == "admin" ]]
      then
        USER_ROLE_ID="$SERVICE_OS_ROLE"
      else
        USER_ROLE_ID=$(openstack role create --or-show -f value -c id "${SERVICE_OS_ROLE}");
      fi

      # Manage user role assignment
      openstack role add \
          --user="${USER_ID}" \
          --user-domain="${USER_DOMAIN_ID}" \
          --project-domain="${PROJECT_DOMAIN_ID}" \
          --project="${USER_PROJECT_ID}" \
          "${USER_ROLE_ID}"
    }

    # Manage user service role
    IFS=','
    for SERVICE_OS_ROLE in ${SERVICE_OS_ROLES}; do
      ks_assign_user_role
    done

    # Manage user member role
    : ${MEMBER_OS_ROLE:="member"}
    export USER_ROLE_ID=$(openstack role create --or-show -f value -c id \
        "${MEMBER_OS_ROLE}");
    ks_assign_user_role
  manage-db.sh: |
    #!/bin/bash



    set -ex

    function create_or_update_db () {
      revisionResults=$(rally db revision)
      if [ $revisionResults = "None"  ]
      then
        rally db create
      else
        rally db upgrade
      fi
    }

    create_or_update_db
  run-task.sh: |
    #!/bin/bash



    set -ex


    : ${RALLY_ENV_NAME:="openstack-helm"}

    function run_rally () {
      CURRENT_TEST=$1
      rally deployment use ${RALLY_ENV_NAME}
      rally deployment check
      rally task validate /tasks/rally/${CURRENT_TEST}.yaml
      rally task start /tasks/rally/${CURRENT_TEST}.yaml
      rally task list
      rally task report --out /var/lib/rally/data/${CURRENT_TEST}.html
      rally task sla-check

    }

    function create_deployment () {
      listResults=$(rally deployment list)

      if [ $(echo $listResults | awk '{print $1;}') = "There"  ]
      then
        rally deployment create --fromenv --name ${RALLY_ENV_NAME}
      fi
    }

    create_deployment

    IFS=','; for TEST in $ENABLED_TESTS; do
      run_rally $TEST
    done

    exit 0
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rally-tasks
data:
  authenticate.yaml: |
    Authenticate.keystone:
    - context:
        users:
          tenants: 3
          users_per_tenant: 50
      runner:
        concurrency: 5
        times: 100
        type: constant
    Authenticate.validate_cinder:
    - args:
        repetitions: 2
      context:
        users:
          tenants: 3
          users_per_tenant: 5
      runner:
        concurrency: 5
        times: 10
        type: constant
    Authenticate.validate_glance:
    - args:
        repetitions: 2
      context:
        users:
          tenants: 3
          users_per_tenant: 5
      runner:
        concurrency: 5
        times: 10
        type: constant
    Authenticate.validate_heat:
    - args:
        repetitions: 2
      context:
        users:
          tenants: 3
          users_per_tenant: 5
      runner:
        concurrency: 5
        times: 10
        type: constant
    Authenticate.validate_neutron:
    - args:
        repetitions: 2
      context:
        users:
          tenants: 3
          users_per_tenant: 5
      runner:
        concurrency: 5
        times: 10
        type: constant
    Authenticate.validate_nova:
    - args:
        repetitions: 2
      context:
        users:
          tenants: 3
          users_per_tenant: 5
      runner:
        concurrency: 5
        times: 10
        type: constant
  ceilometer.yaml: |
    CeilometerAlarms.create_alarm:
    - args:
        alarm_actions:
        - http://localhost:8776/alarm
        insufficient_data_actions:
        - http://localhost:8776/notok
        meter_name: ram_util
        ok_actions:
        - http://localhost:8776/ok
        statistic: avg
        threshold: 10
        type: threshold
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerAlarms.create_alarm_and_get_history:
    - args:
        alarm_actions:
        - http://localhost:8776/alarm
        insufficient_data_actions:
        - http://localhost:8776/notok
        meter_name: ram_util
        ok_actions:
        - http://localhost:8776/ok
        state: ok
        statistic: avg
        threshold: 10
        type: threshold
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 5
        times: 10
        type: constant
    CeilometerAlarms.create_and_delete_alarm:
    - args:
        alarm_actions:
        - http://localhost:8776/alarm
        insufficient_data_actions:
        - http://localhost:8776/notok
        meter_name: ram_util
        ok_actions:
        - http://localhost:8776/ok
        statistic: avg
        threshold: 10
        type: threshold
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerAlarms.create_and_get_alarm:
    - args:
        alarm_actions:
        - http://localhost:8776/alarm
        insufficient_data_actions:
        - http://localhost:8776/notok
        meter_name: ram_util
        ok_actions:
        - http://localhost:8776/ok
        statistic: avg
        threshold: 10
        type: threshold
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    CeilometerAlarms.create_and_list_alarm:
    - args:
        alarm_actions:
        - http://localhost:8776/alarm
        insufficient_data_actions:
        - http://localhost:8776/notok
        meter_name: ram_util
        ok_actions:
        - http://localhost:8776/ok
        statistic: avg
        threshold: 10
        type: threshold
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerAlarms.create_and_update_alarm:
    - args:
        alarm_actions:
        - http://localhost:8776/alarm
        insufficient_data_actions:
        - http://localhost:8776/notok
        meter_name: ram_util
        ok_actions:
        - http://localhost:8776/ok
        statistic: avg
        threshold: 10
        type: threshold
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerAlarms.list_alarms:
    - context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerEvents.create_user_and_get_event:
    - context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 10
        type: constant
    CeilometerEvents.create_user_and_list_event_types:
    - context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 10
        type: constant
    CeilometerEvents.create_user_and_list_events:
    - context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 10
        type: constant
    CeilometerMeters.list_matched_meters:
    - args:
        filter_by_project_id: true
        filter_by_resource_id: true
        filter_by_user_id: true
        limit: 50
        metadata_query:
          status: terminated
      context:
        ceilometer:
          counter_name: benchmark_meter
          counter_type: gauge
          counter_unit: '%'
          counter_volume: 100
          metadata_list:
          - deleted: "false"
            name: rally benchmark on
            status: active
          - deleted: "true"
            name: rally benchmark off
            status: terminated
          resources_per_tenant: 100
          samples_per_resource: 100
          timestamp_interval: 10
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerMeters.list_meters:
    - args:
        limit: 50
        metadata_query:
          status: terminated
      context:
        ceilometer:
          counter_name: benchmark_meter
          counter_type: gauge
          counter_unit: '%'
          counter_volume: 100
          metadata_list:
          - deleted: "false"
            name: rally benchmark on
            status: active
          - deleted: "true"
            name: rally benchmark off
            status: terminated
          resources_per_tenant: 100
          samples_per_resource: 100
          timestamp_interval: 10
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerQueries.create_and_query_alarm_history:
    - args:
        alarm_actions:
        - http://localhost:8776/alarm
        insufficient_data_actions:
        - http://localhost:8776/notok
        limit: null
        meter_name: ram_util
        ok_actions:
        - http://localhost:8776/ok
        orderby: null
        statistic: avg
        threshold: 10
        type: threshold
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 100
        type: constant
    CeilometerQueries.create_and_query_alarms:
    - args:
        alarm_actions:
        - http://localhost:8776/alarm
        filter:
          and:
          - '!=':
              state: dummy_state
          - =:
              type: threshold
        insufficient_data_actions:
        - http://localhost:8776/notok
        limit: 10
        meter_name: ram_util
        ok_actions:
        - http://localhost:8776/ok
        orderby: null
        statistic: avg
        threshold: 10
        type: threshold
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 100
        type: constant
    CeilometerQueries.create_and_query_samples:
    - args:
        counter_name: cpu_util
        counter_type: gauge
        counter_unit: instance
        counter_volume: 1
        filter:
          =:
            counter_unit: instance
        limit: 10
        orderby: null
        resource_id: resource_id
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 100
        type: constant
    CeilometerResource.get_tenant_resources:
    - context:
        ceilometer:
          counter_name: cpu_util
          counter_type: gauge
          counter_unit: instance
          counter_volume: 1
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 5
        times: 10
        type: constant
    CeilometerResource.list_matched_resources:
    - args:
        filter_by_project_id: true
        filter_by_user_id: true
        limit: 50
        metadata_query:
          status: terminated
      context:
        ceilometer:
          counter_name: benchmark_meter
          counter_type: gauge
          counter_unit: '%'
          counter_volume: 100
          metadata_list:
          - deleted: "false"
            name: rally benchmark on
            status: active
          - deleted: "true"
            name: rally benchmark off
            status: terminated
          resources_per_tenant: 100
          samples_per_resource: 100
          timestamp_interval: 10
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerResource.list_resources:
    - args:
        limit: 50
        metadata_query:
          status: terminated
      context:
        ceilometer:
          counter_name: benchmark_meter
          counter_type: gauge
          counter_unit: '%'
          counter_volume: 100
          metadata_list:
          - deleted: "false"
            name: rally benchmark on
            status: active
          - deleted: "true"
            name: rally benchmark off
            status: terminated
          resources_per_tenant: 100
          samples_per_resource: 100
          timestamp_interval: 10
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerSamples.list_matched_samples:
    - args:
        filter_by_project_id: true
        filter_by_resource_id: true
        filter_by_user_id: true
        limit: 50
        metadata_query:
          status: not_active
      context:
        ceilometer:
          counter_name: cpu_util
          counter_type: gauge
          counter_unit: instance
          counter_volume: 1
          metadata_list:
          - created_at: 2015-09-04T12:34:19.000000
            deleted: "False"
            name: fake_resource
            status: active
          - created_at: 2015-09-10T06:55:12.000000
            deleted: "False"
            name: fake_resource_1
            status: not_active
          resources_per_tenant: 100
          samples_per_resource: 100
          timestamp_interval: 60
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    CeilometerSamples.list_samples:
    - args:
        limit: 50
        metadata_query:
          status: not_active
      context:
        ceilometer:
          batch_size: 5
          counter_name: cpu_util
          counter_type: gauge
          counter_unit: instance
          counter_volume: 1
          metadata_list:
          - created_at: 2015-09-04T12:34:19.000000
            deleted: "False"
            name: fake_resource
            status: active
          - created_at: 2015-09-10T06:55:12.000000
            deleted: "False"
            name: fake_resource_1
            status: not_active
          resources_per_tenant: 100
          samples_per_resource: 100
          timestamp_interval: 60
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    CeilometerStats.create_meter_and_get_stats:
    - args:
        counter_type: cumulative
        counter_unit: ""
        counter_volume: 1
        resource_id: resource-id
        user_id: user-id
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 5
        times: 200
        type: constant
    CeilometerStats.get_stats:
    - args:
        filter_by_project_id: true
        filter_by_resource_id: true
        filter_by_user_id: true
        groupby: resource_id
        metadata_query:
          status: terminated
        meter_name: benchmark_meter
        period: 300
      context:
        ceilometer:
          counter_name: benchmark_meter
          counter_type: gauge
          counter_unit: '%'
          counter_volume: 100
          metadata_list:
          - deleted: "false"
            name: rally benchmark on
            status: active
          - deleted: "true"
            name: rally benchmark off
            status: terminated
          resources_per_tenant: 100
          samples_per_resource: 100
          timestamp_interval: 10
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
    CeilometerTraits.create_user_and_list_trait_descriptions:
    - context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 10
        type: constant
    CeilometerTraits.create_user_and_list_traits:
    - context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 10
        type: constant
  cinder.yaml: |
    CinderVolumeBackups.create_incremental_volume_backup:
    - args:
        create_backup_kwargs: {}
        create_volume_kwargs: {}
        size: 1
      context:
        roles:
        - admin
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumeTypes.create_and_delete_volume_type:
    - args: {}
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumeTypes.create_and_list_encryption_type:
    - args:
        specs:
          cipher: aes-xts-plain64
          control_location: front-end
          key_size: 512
          provider: LuksEncryptor
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 4
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumeTypes.create_volume_type_and_encryption_type:
    - args:
        specs:
          cipher: aes-xts-plain64
          control_location: front-end
          key_size: 512
          provider: LuksEncryptor
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumes.create_and_accept_transfer:
    - args:
        size: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 3
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumes.create_and_attach_volume:
    - args:
        create_volume_params:
          availability_zone: nova
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
        size: 10
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 5
        type: constant
    - args:
        create_volume_params:
          availability_zone: nova
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
        size:
          max: 5
          min: 1
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 5
        type: constant
    CinderVolumes.create_and_delete_snapshot:
    - args:
        force: false
      context:
        users:
          tenants: 2
          users_per_tenant: 2
        volumes:
          size: 1
      runner:
        concurrency: 2
        times: 3
        type: constant
    CinderVolumes.create_and_delete_volume:
    - args:
        image:
          name: cirros-0.3.5-x86_64-disk.img
        size: 1
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 2
        type: constant
    CinderVolumes.create_and_extend_volume:
    - args:
        new_size: 2
        size: 1
      context:
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 2
        type: constant
    - args:
        new_size:
          max: 10
          min: 6
        size:
          max: 5
          min: 1
      context:
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 2
        type: constant
    CinderVolumes.create_and_get_volume:
    - args:
        size: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
      sla:
        failure_rate:
          max: 0
    - args:
        size:
          max: 5
          min: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumes.create_and_list_snapshots:
    - args:
        detailed: true
        force: false
      context:
        users:
          tenants: 1
          users_per_tenant: 1
        volumes:
          size: 1
      runner:
        concurrency: 2
        times: 2
        type: constant
    CinderVolumes.create_and_list_volume:
    - args:
        detailed: true
        size: 1
      context:
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 3
        type: constant
    - args:
        detailed: true
        size:
          max: 5
          min: 1
      context:
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 3
        type: constant
    CinderVolumes.create_and_list_volume_backups:
    - args:
        create_backup_kwargs: {}
        create_volume_kwargs: {}
        detailed: true
        do_delete: true
        size: 1
      context:
        roles:
        - member
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 2
        type: constant
    CinderVolumes.create_and_restore_volume_backup:
    - args:
        create_backup_kwargs: {}
        create_volume_kwargs: {}
        do_delete: true
        size: 1
      context:
        roles:
        - member
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 2
        type: constant
    CinderVolumes.create_and_update_volume:
    - args:
        create_volume_kwargs: {}
        size: 1
        update_volume_kwargs:
          display_description: desc_updated
          display_name: name_updated
      context:
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 3
        type: constant
    CinderVolumes.create_and_upload_volume_to_image:
    - args:
        container_format: bare
        disk_format: raw
        do_delete: true
        force: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
        size: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 3
        type: constant
    - args:
        container_format: bare
        disk_format: raw
        do_delete: true
        force: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
        size:
          max: 5
          min: 1
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 3
        type: constant
    CinderVolumes.create_from_volume_and_delete_volume:
    - args:
        size: 1
      context:
        users:
          tenants: 1
          users_per_tenant: 1
        volumes:
          size: 1
      runner:
        concurrency: 2
        times: 2
        type: constant
    - args:
        size:
          max: 5
          min: 1
      context:
        users:
          tenants: 1
          users_per_tenant: 1
        volumes:
          size: 1
      runner:
        concurrency: 2
        times: 2
        type: constant
    CinderVolumes.create_nested_snapshots_and_attach_volume:
    - args:
        nested_level: 5
        size:
          max: 5
          min: 1
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        servers:
          flavor:
            name: m1.tiny
          image:
            name: cirros-0.3.5-x86_64-disk.img
          servers_per_tenant: 2
        users:
          tenants: 2
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    CinderVolumes.create_snapshot_and_attach_volume:
    - args:
        size:
          max: 5
          min: 1
        volume_type: false
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        servers:
          flavor:
            name: m1.tiny
          image:
            name: cirros-0.3.5-x86_64-disk.img
          servers_per_tenant: 2
        users:
          tenants: 2
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 4
        type: constant
    - args:
        size:
          max: 5
          min: 1
        volume_type: true
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        servers:
          flavor:
            name: m1.tiny
          image:
            name: cirros-0.3.5-x86_64-disk.img
          servers_per_tenant: 2
        users:
          tenants: 2
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 4
        type: constant
    CinderVolumes.create_volume_and_clone:
    - args:
        size: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 3
        type: constant
    - args:
        nested_level: 3
        size:
          max: 5
          min: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 3
        type: constant
    CinderVolumes.create_volume_and_update_readonly_flag:
    - args:
        read_only: true
        size: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 3
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumes.create_volume_backup:
    - args:
        create_backup_kwargs: {}
        create_volume_kwargs: {}
        do_delete: true
        size: 1
      context:
        roles:
        - member
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 2
        type: constant
    CinderVolumes.create_volume_from_snapshot:
    - args:
        do_delete: true
      context:
        users:
          tenants: 2
          users_per_tenant: 2
        volumes:
          size: 1
      runner:
        concurrency: 2
        times: 3
        type: constant
    CinderVolumes.list_transfers:
    - args:
        detailed: true
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 3
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumes.list_types:
    - args:
        is_public: true
      context:
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    CinderVolumes.list_volumes:
    - args:
        detailed: true
      context:
        users:
          tenants: 1
          users_per_tenant: 1
        volumes:
          size: 1
          volumes_per_tenant: 4
      runner:
        concurrency: 1
        times: 100
        type: constant
    CinderVolumes.modify_volume_metadata:
    - args: {}
      context:
        users:
          tenants: 2
          users_per_tenant: 2
        volumes:
          size: 1
      runner:
        concurrency: 2
        times: 10
        type: constant
  glance.yaml: |
    GlanceImages.create_and_delete_image:
    - args:
        container_format: bare
        disk_format: qcow2
        image_location: http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img
      context:
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 2
        times: 10
        type: constant
    GlanceImages.create_and_list_image:
    - args:
        container_format: bare
        disk_format: qcow2
        image_location: http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img
      context:
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 10
        type: constant
    GlanceImages.create_image_and_boot_instances:
    - args:
        container_format: bare
        disk_format: qcow2
        flavor:
          name: m1.tiny
        image_location: http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img
        number_instances: 2
      context:
        users:
          tenants: 3
          users_per_tenant: 5
      runner:
        concurrency: 2
        times: 10
        type: constant
    GlanceImages.list_images:
    - context:
        images:
          image_container: bare
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img
          images_per_tenant: 4
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 10
        type: constant
  heat.yaml: |
    HeatStacks.create_and_delete_stack:
    - args:
        template_path: /tmp/tasks/test-templates/server-with-ports.yaml
      context:
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 2
        times: 10
        type: constant
    HeatStacks.create_and_list_stack:
    - args:
        template_path: /tmp/tasks/test-templates/default.yaml
      context:
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 10
        type: constant
    HeatStacks.create_check_delete_stack:
    - args:
        template_path: /tmp/tasks/test-templates/random-strings.yaml
      context:
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 2
        times: 10
        type: constant
    HeatStacks.create_snapshot_restore_delete_stack:
    - args:
        template_path: /tmp/tasks/test-templates/random-strings.yaml
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    HeatStacks.create_stack_and_list_output:
    - args:
        template_path: /tmp/tasks/test-templates/resource-group-with-outputs.yaml
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
    HeatStacks.create_stack_and_list_output_via_API:
    - args:
        template_path: /tmp/tasks/test-templates/resource-group-with-outputs.yaml
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
    HeatStacks.create_stack_and_scale:
    - args:
        delta: 1
        output_key: scaling_url
        template_path: /tmp/tasks/test-templates/autoscaling-group.yaml
      context:
        users:
          tenants: 2
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 3
        type: constant
    HeatStacks.create_stack_and_show_output:
    - args:
        output_key: val1
        template_path: /tmp/tasks/test-templates/resource-group-with-outputs.yaml
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
    HeatStacks.create_stack_and_show_output_via_API:
    - args:
        output_key: val1
        template_path: /tmp/tasks/test-templates/resource-group-with-outputs.yaml
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 5
        type: constant
    HeatStacks.create_suspend_resume_delete_stack:
    - args:
        template_path: /tmp/tasks/test-templates/random-strings.yaml
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    HeatStacks.create_update_delete_stack:
    - args:
        template_path: /tmp/tasks/test-templates/resource-group.yaml
        updated_template_path: /tmp/tasks/test-templates/updated-resource-group-reduce.yaml
      context:
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 2
        times: 10
        type: constant
    HeatStacks.list_stacks_and_events:
    - context:
        stacks:
          resources_per_stack: 10
          stacks_per_tenant: 2
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 10
        type: constant
    HeatStacks.list_stacks_and_resources:
    - context:
        stacks:
          resources_per_stack: 10
          stacks_per_tenant: 2
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 10
        type: constant
  keystone.yaml: |
    KeystoneBasic.add_and_remove_user_role:
    - context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.authenticate_user_and_validate_token:
    - args: {}
      runner:
        concurrency: 5
        times: 20
        type: constant
      sla:
        failure_rate:
          max: 0
    KeystoneBasic.create_add_and_list_user_roles:
    - context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_and_delete_ec2credential:
    - context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 5
        times: 10
        type: constant
    KeystoneBasic.create_and_delete_role:
    - runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_and_delete_service:
    - args:
        description: test_description
        service_type: Rally_test_type
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_and_get_role:
    - args: {}
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    KeystoneBasic.create_and_list_ec2credentials:
    - context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 5
        times: 10
        type: constant
    KeystoneBasic.create_and_list_services:
    - args:
        description: test_description
        service_type: Rally_test_type
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_and_list_tenants:
    - args: {}
      runner:
        concurrency: 1
        times: 10
        type: constant
    KeystoneBasic.create_and_list_users:
    - args: {}
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_delete_user:
    - args: {}
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_tenant:
    - args: {}
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_tenant_with_users:
    - args:
        users_per_tenant: 10
      runner:
        concurrency: 10
        times: 10
        type: constant
    KeystoneBasic.create_update_and_delete_tenant:
    - args: {}
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_user:
    - args: {}
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_user_set_enabled_and_delete:
    - args:
        enabled: true
      runner:
        concurrency: 10
        times: 100
        type: constant
    - args:
        enabled: false
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.create_user_update_password:
    - args: {}
      runner:
        concurrency: 10
        times: 100
        type: constant
    KeystoneBasic.get_entities:
    - runner:
        concurrency: 10
        times: 100
        type: constant
  magnum.yaml: |
    MagnumClusterTemplates.list_cluster_templates:
    - context:
        cluster_templates:
          coe: kubernetes
          dns_nameserver: 8.8.8.8
          docker_volume_size: 5
          external_network_id: public
          flavor_id: m1.small
          image_id: fedora-atomic-latest
          network_driver: flannel
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    - context:
        cluster_templates:
          coe: swarm
          dns_nameserver: 8.8.8.8
          docker_volume_size: 5
          external_network_id: public
          flavor_id: m1.small
          image_id: fedora-atomic-latest
          network_driver: docker
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    - context:
        cluster_templates:
          coe: mesos
          dns_nameserver: 8.8.8.8
          external_network_id: public
          flavor_id: m1.small
          image_id: ubuntu-mesos
          network_driver: docker
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    MagnumClusters.create_and_list_clusters:
    - args:
        node_count: 1
      context:
        cluster_templates:
          coe: kubernetes
          dns_nameserver: 8.8.8.8
          docker_volume_size: 5
          external_network_id: public
          flavor_id: m1.small
          image_id: fedora-atomic-latest
          network_driver: flannel
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    - args:
        node_count: 1
      context:
        cluster_templates:
          coe: swarm
          dns_nameserver: 8.8.8.8
          docker_volume_size: 5
          external_network_id: public
          flavor_id: m1.small
          image_id: fedora-atomic-latest
          network_driver: docker
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    - args:
        node_count: 1
      context:
        cluster_templates:
          coe: mesos
          dns_nameserver: 8.8.8.8
          external_network_id: public
          flavor_id: m1.small
          image_id: ubuntu-mesos
          network_driver: docker
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    MagnumClusters.list_clusters:
    - context:
        cluster_templates:
          coe: kubernetes
          dns_nameserver: 8.8.8.8
          docker_volume_size: 5
          external_network_id: public
          flavor_id: m1.small
          image_id: fedora-atomic-latest
          network_driver: flannel
        clusters:
          node_count: 2
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    - context:
        cluster_templates:
          coe: swarm
          dns_nameserver: 8.8.8.8
          docker_volume_size: 5
          external_network_id: public
          flavor_id: m1.small
          image_id: fedora-atomic-latest
          network_driver: docker
        clusters:
          node_count: 2
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    - context:
        cluster_templates:
          coe: mesos
          dns_nameserver: 8.8.8.8
          external_network_id: public
          flavor_id: m1.small
          image_id: ubuntu-mesos
          network_driver: docker
        clusters:
          node_count: 2
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
  neutron.yaml: |
    NeutronNetworks.create_and_delete_floating_ips:
    - args:
        floating_ip_args: {}
        floating_network: public
      context:
        quotas:
          neutron:
            floatingip: -1
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 5
        times: 10
        type: constant
    NeutronNetworks.create_and_delete_networks:
    - args:
        network_create_args: {}
      context:
        quotas:
          neutron:
            network: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
    NeutronNetworks.create_and_delete_ports:
    - args:
        network_create_args: {}
        port_create_args: {}
        ports_per_network: 10
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            port: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
    NeutronNetworks.create_and_delete_routers:
    - args:
        network_create_args: {}
        router_create_args: {}
        subnet_cidr_start: 1.1.0.0/30
        subnet_create_args: {}
        subnets_per_network: 2
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            router: -1
            subnet: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 30
        type: constant
    NeutronNetworks.create_and_delete_subnets:
    - args:
        network_create_args: {}
        subnet_cidr_start: 1.1.0.0/30
        subnet_create_args: {}
        subnets_per_network: 2
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            subnet: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
    NeutronNetworks.create_and_list_floating_ips:
    - args:
        floating_ip_args: {}
        floating_network: public
      context:
        quotas:
          neutron:
            floatingip: -1
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 5
        times: 10
        type: constant
    NeutronNetworks.create_and_list_networks:
    - args:
        network_create_args: {}
      context:
        quotas:
          neutron:
            network: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
      sla:
        failure_rate:
          max: 0
    - args:
        network_create_args:
          provider:network_type: vxlan
      context:
        quotas:
          neutron:
            network: -1
        roles:
        - admin
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
      sla:
        failure_rate:
          max: 0
    NeutronNetworks.create_and_list_ports:
    - args:
        network_create_args: {}
        port_create_args: {}
        ports_per_network: 10
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            port: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
    NeutronNetworks.create_and_list_routers:
    - args:
        network_create_args: {}
        router_create_args: {}
        subnet_cidr_start: 1.1.0.0/30
        subnet_create_args: {}
        subnets_per_network: 2
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            router: -1
            subnet: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
    NeutronNetworks.create_and_list_subnets:
    - args:
        network_create_args: {}
        subnet_cidr_start: 1.1.0.0/30
        subnet_create_args: {}
        subnets_per_network: 2
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            subnet: -1
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 5
        times: 10
        type: constant
    NeutronNetworks.create_and_show_network:
    - args:
        network_create_args: {}
      context:
        quotas:
          neutron:
            network: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NeutronNetworks.create_and_update_networks:
    - args:
        network_create_args: {}
        network_update_args:
          admin_state_up: false
          name: _updated
      context:
        quotas:
          neutron:
            network: -1
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 5
        times: 10
        type: constant
    NeutronNetworks.create_and_update_ports:
    - args:
        network_create_args: {}
        port_create_args: {}
        port_update_args:
          admin_state_up: false
          device_id: dummy_id
          device_owner: dummy_owner
          name: _port_updated
        ports_per_network: 5
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            port: -1
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 5
        times: 10
        type: constant
    NeutronNetworks.create_and_update_routers:
    - args:
        network_create_args: {}
        router_create_args: {}
        router_update_args:
          admin_state_up: false
          name: _router_updated
        subnet_cidr_start: 1.1.0.0/30
        subnet_create_args: {}
        subnets_per_network: 2
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            router: -1
            subnet: -1
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 5
        times: 10
        type: constant
    NeutronNetworks.create_and_update_subnets:
    - args:
        network_create_args: {}
        subnet_cidr_start: 1.4.0.0/16
        subnet_create_args: {}
        subnet_update_args:
          enable_dhcp: false
          name: _subnet_updated
        subnets_per_network: 2
      context:
        network: {}
        quotas:
          neutron:
            network: -1
            subnet: -1
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 5
        times: 10
        type: constant
    NeutronNetworks.list_agents:
    - args:
        agent_args: {}
      context:
        users:
          tenants: 2
          users_per_tenant: 3
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NeutronSecurityGroup.create_and_delete_security_groups:
    - args:
        security_group_create_args: {}
      context:
        quotas:
          neutron:
            security_group: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
    NeutronSecurityGroup.create_and_list_security_groups:
    - args:
        security_group_create_args: {}
      context:
        quotas:
          neutron:
            security_group: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
    NeutronSecurityGroup.create_and_update_security_groups:
    - args:
        security_group_create_args: {}
        security_group_update_args: {}
      context:
        quotas:
          neutron:
            security_group: -1
        users:
          tenants: 3
          users_per_tenant: 3
      runner:
        concurrency: 10
        times: 100
        type: constant
  nova.yaml: |
    NovaAgents.list_agents:
    - runner:
        concurrency: 2
        times: 10
        type: constant
    NovaAggregates.create_aggregate_add_and_remove_host:
    - args:
        availability_zone: nova
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaAggregates.create_aggregate_add_host_and_boot_server:
    - args:
        availability_zone: nova
        boot_server_kwargs: {}
        disk: 1
        image:
          name: cirros-0.3.5-x86_64-disk.img
        metadata:
          test_metadata: "true"
        ram: 512
        vcpus: 1
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaAggregates.create_and_delete_aggregate:
    - args:
        availability_zone: nova
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaAggregates.create_and_get_aggregate_details:
    - args:
        availability_zone: nova
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaAggregates.create_and_list_aggregates:
    - args:
        availability_zone: nova
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaAggregates.create_and_update_aggregate:
    - args:
        availability_zone: nova
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaAggregates.list_aggregates:
    - runner:
        concurrency: 2
        times: 10
        type: constant
    NovaAvailabilityZones.list_availability_zones:
    - args:
        detailed: true
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaFlavors.create_and_delete_flavor:
    - args:
        disk: 1
        ram: 500
        vcpus: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaFlavors.create_and_get_flavor:
    - args:
        disk: 1
        ram: 500
        vcpus: 1
      context:
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaFlavors.create_and_list_flavor_access:
    - args:
        disk: 1
        ram: 500
        vcpus: 1
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaFlavors.create_flavor:
    - args:
        disk: 1
        ram: 500
        vcpus: 1
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaFlavors.create_flavor_and_add_tenant_access:
    - args:
        disk: 1
        ram: 500
        vcpus: 1
      context:
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaFlavors.create_flavor_and_set_keys:
    - args:
        disk: 1
        extra_specs:
          quota:disk_read_bytes_sec: 10240
        ram: 500
        vcpus: 1
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaFlavors.list_flavors:
    - args:
        detailed: true
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaHypervisors.list_and_get_hypervisors:
    - args:
        detailed: true
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 2
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaHypervisors.list_and_get_uptime_hypervisors:
    - args:
        detailed: true
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 2
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaHypervisors.list_and_search_hypervisors:
    - args:
        detailed: true
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 2
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaHypervisors.list_hypervisors:
    - args:
        detailed: true
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaHypervisors.statistics_hypervisors:
    - args: {}
      context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 2
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaKeypair.boot_and_delete_server_with_keypair:
    - args:
        boot_server_kwargs: {}
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        network:
          start_cidr: 100.1.0.0/26
        users:
          tenants: 2
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 5
        type: constant
    NovaKeypair.create_and_delete_keypair:
    - context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaKeypair.create_and_list_keypairs:
    - context:
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_and_associate_floating_ip:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        network: {}
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    NovaServers.boot_and_bounce_server:
    - args:
        actions:
        - hard_reboot: 1
        - soft_reboot: 1
        - stop_start: 1
        - rescue_unrescue: 1
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_and_delete_multiple_servers:
    - args:
        count: 5
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    NovaServers.boot_and_delete_server:
    - args:
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    - args:
        auto_assign_nic: true
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        network:
          networks_per_tenant: 2
          start_cidr: 10.2.0.0/24
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_and_get_console_output:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    NovaServers.boot_and_list_server:
    - args:
        detailed: true
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    NovaServers.boot_and_live_migrate_server:
    - args:
        block_migration: false
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_and_migrate_server:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_and_rebuild_server:
    - args:
        flavor:
          name: m1.tiny
        from_image:
          name: cirros-0.3.5-x86_64-disk.img
        to_image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 5
        type: constant
    NovaServers.boot_and_show_server:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    NovaServers.boot_and_update_server:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_lock_unlock_and_delete:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_server:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_server_associate_and_dissociate_floating_ip:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        network: {}
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 5
        type: constant
      sla:
        failure_rate:
          max: 0
    NovaServers.boot_server_attach_created_volume_and_live_migrate:
    - args:
        block_migration: false
        boot_server_kwargs: {}
        create_volume_kwargs: {}
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
        size: 10
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 2
          users_per_tenant: 2
      runner:
        concurrency: 1
        times: 5
        type: constant
    NovaServers.boot_server_attach_created_volume_and_resize:
    - args:
        boot_server_kwargs: {}
        confirm: true
        create_volume_kwargs: {}
        do_delete: true
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
        to_flavor:
          name: m1.small
        volume_size: 1
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_server_from_volume:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
        volume_size: 10
        volume_type: ""
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_server_from_volume_and_delete:
    - args:
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
        volume_size: 10
        volume_type: ""
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_server_from_volume_and_live_migrate:
    - args:
        block_migration: false
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
        volume_size: 10
        volume_type: ""
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_server_from_volume_and_resize:
    - args:
        boot_server_kwargs: {}
        confirm: true
        create_volume_kwargs: {}
        do_delete: true
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
        to_flavor:
          name: m1.small
        volume_size: 1
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.boot_server_from_volume_snapshot:
    - args:
        flavor:
          name: m1.tiny
        image:
          name: cirros-0.3.5-x86_64-disk.img
        volume_size: 10
        volume_type: ""
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.list_servers:
    - args:
        detailed: true
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        servers:
          flavor:
            name: m1.tiny
          image:
            name: cirros-0.3.5-x86_64-disk.img
          servers_per_tenant: 2
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 1
        type: constant
    NovaServers.pause_and_unpause_server:
    - args:
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.resize_server:
    - args:
        confirm: true
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
        to_flavor:
          name: m1.small
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 5
        times: 10
        type: constant
    NovaServers.shelve_and_unshelve_server:
    - args:
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.snapshot_server:
    - args:
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServers.suspend_and_resume_server:
    - args:
        flavor:
          name: m1.tiny
        force_delete: false
        image:
          name: cirros-0.3.5-x86_64-disk.img
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        users:
          tenants: 3
          users_per_tenant: 2
      runner:
        concurrency: 2
        times: 10
        type: constant
    NovaServices.list_services:
    - runner:
        concurrency: 2
        times: 10
        type: constant
  senlin.yaml: |
    SenlinClusters.create_and_delete_cluster:
    - args:
        desired_capacity: 3
        max_size: 5
        min_size: 0
      context:
        images:
          image_container: bare
          image_name: cirros-0.3.5-x86_64-disk.img
          image_type: qcow2
          image_url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
          images_per_tenant: 1
        profiles:
          properties:
            flavor: 1
            image: cirros-0.3.4-x86_64-uec
            name: cirros_server
            networks:
            - network: private
          type: os.nova.server
          version: "1.0"
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 1
        times: 3
        type: constant
  swift.yaml: |
    SwiftObjects.create_container_and_object_then_delete_all:
    - args:
        object_size: 102400
        objects_per_container: 5
      context:
        roles:
        - admin
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 4
        type: constant
    SwiftObjects.create_container_and_object_then_download_object:
    - args:
        object_size: 1024
        objects_per_container: 5
      context:
        roles:
        - admin
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 3
        times: 6
        type: constant
    SwiftObjects.create_container_and_object_then_list_objects:
    - args:
        object_size: 5120
        objects_per_container: 2
      context:
        roles:
        - admin
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 2
        type: constant
    SwiftObjects.list_and_download_objects_in_containers:
    - context:
        roles:
        - admin
        swift_objects:
          containers_per_tenant: 2
          object_size: 10240
          objects_per_container: 5
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 2
        times: 2
        type: constant
    SwiftObjects.list_objects_in_containers:
    - context:
        roles:
        - admin
        swift_objects:
          containers_per_tenant: 1
          object_size: 1024
          objects_per_container: 10
        users:
          tenants: 1
          users_per_tenant: 1
      runner:
        concurrency: 3
        times: 6
        type: constant
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: heat-tasks-test-templates
data:
  autoscaling-group.yaml: "heat_template_version: \"2013-05-23\"\noutputs:\n  scaling_url:\n    value:\n      get_attr:\n      - scaling_policy\n      - alarm_url\nparameters:\n  flavor:\n    constraints:\n    - custom_constraint: nova.flavor\n    default: m1.tiny\n    type: string\n  image:\n    constraints:\n    - custom_constraint: glance.image\n    default: cirros-0.3.4-x86_64-uec\n    type: string\n  max_size:\n    constraints:\n    - range:\n        min: 1\n    default: 5\n    type: number\n  scaling_adjustment:\n    default: 1\n    type: number\nresources:\n  asg:\n    properties:\n      desired_capacity: 3\n      max_size:\n        get_param: max_size\n      min_size: 1\n      resource:\n        properties:\n          flavor:\n            get_param: flavor\n          image:\n            get_param: image\n        type: OS::Nova::Server\n    type: OS::Heat::AutoScalingGroup\n  scaling_policy:\n    properties:\n      adjustment_type: change_in_capacity\n      auto_scaling_group_id:\n        get_resource: asg\n      scaling_adjustment:\n        get_param: scaling_adjustment\n    type: OS::Heat::ScalingPolicy  \n"
  autoscaling-policy.yaml: "heat_template_version: \"2013-05-23\"\nresources:\n  test_group:\n    properties:\n      desired_capacity: 0\n      max_size: 0\n      min_size: 0\n      resource:\n        type: OS::Heat::RandomString\n    type: OS::Heat::AutoScalingGroup\n  test_policy:\n    properties:\n      adjustment_type: change_in_capacity\n      auto_scaling_group_id:\n        get_resource: test_group\n      scaling_adjustment: 1\n    type: OS::Heat::ScalingPolicy  \n"
  default.yaml: "heat_template_version: \"2014-10-16\"  \n"
  random-strings.yaml: "description: Test template for rally create-update-delete scenario\nheat_template_version: \"2014-10-16\"\nresources:\n  test_string_one:\n    properties:\n      length: 20\n    type: OS::Heat::RandomString\n  test_string_two:\n    properties:\n      length: 20\n    type: OS::Heat::RandomString  \n"
  resource-group.yaml: "description: Test template for rally create-update-delete scenario\nheat_template_version: \"2014-10-16\"\nresources:\n  test_group:\n    properties:\n      count: 2\n      resource_def:\n        properties:\n          length: 20\n        type: OS::Heat::RandomString\n    type: OS::Heat::ResourceGroup  \n"
  resource-group-server-with-volume.yaml: "description: |\n  Test template that creates a resource group with servers and volumes.\n  The template allows to create a lot of nested stacks with standard configuration:\n  nova instance, cinder volume attached to that instance\nheat_template_version: \"2014-10-16\"\nparameters:\n  instance_availability_zone:\n    default: nova\n    description: The Availability Zone to launch the instance.\n    type: string\n  instance_flavor:\n    default: m1.tiny\n    description: Type of the instance to be created.\n    type: string\n  instance_image:\n    default: cirros-0.3.4-x86_64-uec\n    type: string\n  instance_volume_size:\n    constraints:\n    - range:\n        max: 1024\n        min: 1\n    default: 1\n    description: Size of volume to attach to instance\n    type: number\n  num_instances:\n    constraints:\n    - range:\n        min: 1\n    description: number of instances that should be created in resource group\n    type: number\nresources:\n  group_of_volumes:\n    properties:\n      count:\n        get_param: num_instances\n      resource_def:\n        properties:\n          availability_zone:\n            get_param: instance_availability_zone\n          flavor:\n            get_param: instance_flavor\n          image:\n            get_param: instance_image\n          volume_size:\n            get_param: instance_volume_size\n        type: templates/server-with-volume.yaml.template\n    type: OS::Heat::ResourceGroup  \n"
  resource-group-with-constraint.yaml: "description: Template for testing caching.\nheat_template_version: \"2013-05-23\"\nparameters:\n  count:\n    default: 40\n    type: number\n  delay:\n    default: 0.1\n    type: number\nresources:\n  rg:\n    properties:\n      count:\n        get_param: count\n      resource_def:\n        properties:\n          constraint_prop_secs:\n            get_param: delay\n        type: OS::Heat::TestResource\n    type: OS::Heat::ResourceGroup  \n"
  resource-group-with-outputs.yaml: "heat_template_version: \"2013-05-23\"\noutputs:\n  val1:\n    value:\n      get_attr:\n      - rg\n      - resource.0.output\n  val2:\n    value:\n      get_attr:\n      - rg\n      - resource.1.output\n  val3:\n    value:\n      get_attr:\n      - rg\n      - resource.2.output\n  val4:\n    value:\n      get_attr:\n      - rg\n      - resource.3.output\n  val5:\n    value:\n      get_attr:\n      - rg\n      - resource.4.output\n  val6:\n    value:\n      get_attr:\n      - rg\n      - resource.5.output\n  val7:\n    value:\n      get_attr:\n      - rg\n      - resource.6.output\n  val8:\n    value:\n      get_attr:\n      - rg\n      - resource.7.output\n  val9:\n    value:\n      get_attr:\n      - rg\n      - resource.8.output\n  val10:\n    value:\n      get_attr:\n      - rg\n      - resource.9.output\nparameters:\n  attr_wait_secs:\n    default: 0.5\n    type: number\nresources:\n  rg:\n    properties:\n      count: 10\n      resource_def:\n        properties:\n          attr_wait_secs:\n            get_param: attr_wait_secs\n        type: OS::Heat::TestResource\n    type: OS::Heat::ResourceGroup  \n"
  server-with-ports.yaml: "heat_template_version: \"2013-05-23\"\nparameters:\n  cidr:\n    default: 11.11.11.0/24\n    type: string\n  flavor:\n    default: m1.tiny\n    type: string\n  image:\n    default: cirros-0.3.4-x86_64-uec\n    type: string\n  public_net:\n    default: public\n    type: string\nresources:\n  port_security_group:\n    properties:\n      description: |\n        Default security group assigned to port. The neutron default group\n        is not used because neutron creates several groups with the same name=default\n        and nova cannot chooses which one should it use.\n      name: default_port_security_group\n    type: OS::Neutron::SecurityGroup\n  private_net:\n    type: OS::Neutron::Net\n  private_subnet:\n    properties:\n      cidr:\n        get_param: cidr\n      network:\n        get_resource: private_net\n    type: OS::Neutron::Subnet\n  router:\n    properties:\n      external_gateway_info:\n        network:\n          get_param: public_net\n    type: OS::Neutron::Router\n  router_interface:\n    properties:\n      router_id:\n        get_resource: router\n      subnet_id:\n        get_resource: private_subnet\n    type: OS::Neutron::RouterInterface\n  server:\n    properties:\n      flavor:\n        get_param: flavor\n      image:\n        get_param: image\n      networks:\n      - port:\n          get_resource: server_port\n    type: OS::Nova::Server\n  server_port:\n    properties:\n      fixed_ips:\n      - subnet:\n          get_resource: private_subnet\n      network:\n        get_resource: private_net\n      security_groups:\n      - get_resource: port_security_group\n    type: OS::Neutron::Port  \n"
  server-with-volume.yaml: "heat_template_version: \"2013-05-23\"\nparameters:\n  availability_zone:\n    default: nova\n    description: The Availability Zone to launch the instance.\n    type: string\n  flavor:\n    default: m1.tiny\n    type: string\n  image:\n    default: cirros-0.3.4-x86_64-uec\n    type: string\n  volume_size:\n    constraints:\n    - description: must be between 1 and 1024 Gb.\n      range:\n        max: 1024\n        min: 1\n    default: 1\n    description: Size of the volume to be created.\n    type: number\nresources:\n  cinder_volume:\n    properties:\n      availability_zone:\n        get_param: availability_zone\n      size:\n        get_param: volume_size\n    type: OS::Cinder::Volume\n  server:\n    properties:\n      flavor:\n        get_param: flavor\n      image:\n        get_param: image\n    type: OS::Nova::Server\n  volume_attachment:\n    properties:\n      instance_uuid:\n        get_resource: server\n      mountpoint: /dev/vdc\n      volume_id:\n        get_resource: cinder_volume\n    type: OS::Cinder::VolumeAttachment  \n"
  updated-random-strings-add.yaml: "description: |\n  Test template for create-update-delete-stack scenario in rally. The\n  template updates the stack defined by random-strings.yaml.template with additional\n  resource.\nheat_template_version: \"2014-10-16\"\nresources:\n  test_string_one:\n    properties:\n      length: 20\n    type: OS::Heat::RandomString\n  test_string_three:\n    properties:\n      length: 20\n    type: OS::Heat::RandomString\n  test_string_two:\n    properties:\n      length: 20\n    type: OS::Heat::RandomString  \n"
  updated-random-strings-delete.yaml: "description: |\n  Test template for create-update-delete-stack scenario in rally. The\n  template deletes one resource from the stack defined by random-strings.yaml.template.\nheat_template_version: \"2014-10-16\"\nresources:\n  test_string_one:\n    properties:\n      length: 20\n    type: OS::Heat::RandomString  \n"
  updated-random-strings-replace.yaml: "description: |\n  Test template for create-update-delete-stack scenario in rally. The\n  template deletes one resource from the stack defined by random-strings.yaml.template\n  and re-creates it with the updated parameters (so-called update-replace). That happens\n  because some parameters cannot be changed without resource re-creation. The template\n  allows to measure performance of update-replace operation.\nheat_template_version: \"2014-10-16\"\nresources:\n  test_string_one:\n    properties:\n      length: 20\n    type: OS::Heat::RandomString\n  test_string_two:\n    properties:\n      length: 40\n    type: OS::Heat::RandomString  \n"
  updated-resource-group-increase.yaml: "description: |\n  Test template for create-update-delete-stack scenario in rally. The\n  template updates one resource from the stack defined by resource-group.yaml.template\n  and adds children resources to that resource.\nheat_template_version: \"2014-10-16\"\nresources:\n  test_group:\n    properties:\n      count: 3\n      resource_def:\n        properties:\n          length: 20\n        type: OS::Heat::RandomString\n    type: OS::Heat::ResourceGroup  \n"
  updated-resource-group-reduce.yaml: |
    description: |
      Test template for create-update-delete-stack scenario in rally.
      The template updates one resource from the stack defined by resource-group.yaml.template
      and deletes children resources from that resource.
    heat_template_version: "2014-10-16"
    resources:
      test_group:
        properties:
          count: 1
          resource_def:
            properties:
              length: 20
            type: OS::Heat::RandomString
        type: OS::Heat::ResourceGroup
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pvc-rally
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
  storageClassName: general
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-rally-db-init
  namespace: zw2oFEKLFrAP
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-rally-ks-endpoints
  namespace: zw2oFEKLFrAP
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
      - jobs
      - pods
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-rally-ks-service
  namespace: zw2oFEKLFrAP
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-rally-ks-user
  namespace: zw2oFEKLFrAP
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-rally-manage-db
  namespace: zw2oFEKLFrAP
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
      - jobs
      - pods
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-rally-run-task
  namespace: zw2oFEKLFrAP
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
      - jobs
      - pods
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-rally-db-init
  namespace: zw2oFEKLFrAP
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-rally-db-init
subjects:
  - kind: ServiceAccount
    name: rally-db-init
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-rally-ks-endpoints
  namespace: zw2oFEKLFrAP
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-rally-ks-endpoints
subjects:
  - kind: ServiceAccount
    name: rally-ks-endpoints
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-rally-ks-service
  namespace: zw2oFEKLFrAP
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-rally-ks-service
subjects:
  - kind: ServiceAccount
    name: rally-ks-service
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-rally-ks-user
  namespace: zw2oFEKLFrAP
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-rally-ks-user
subjects:
  - kind: ServiceAccount
    name: rally-ks-user
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-rally-manage-db
  namespace: zw2oFEKLFrAP
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-rally-manage-db
subjects:
  - kind: ServiceAccount
    name: rally-manage-db
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-rally-run-task
  namespace: zw2oFEKLFrAP
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-rally-run-task
subjects:
  - kind: ServiceAccount
    name: rally-run-task
    namespace: default
---
apiVersion: batch/v1
kind: Job
metadata:
  name: rally-db-init
  annotations:
    helm.sh/hook-delete-policy: before-hook-creation
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: rally
        component: db-init
      annotations:
        openstackhelm.openstack.org/release_uuid: ""
    spec:
      serviceAccountName: rally-db-init
      restartPolicy: OnFailure
      nodeSelector:
        openstack-control-plane: enabled
      initContainers:
        - name: init
          image: quay.io/airshipit/kubernetes-entrypoint:v1.0.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: default:mariadb
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts: []
      containers:
        - name: rally-db-init-0
          image: docker.io/xrally/xrally-openstack:2.0.0
          imagePullPolicy: IfNotPresent
          env:
            - name: ROOT_DB_CONNECTION
              valueFrom:
                secretKeyRef:
                  name: rally-db-admin
                  key: DB_CONNECTION
            - name: OPENSTACK_CONFIG_FILE
              value: /etc/rally/rally.conf
            - name: OPENSTACK_CONFIG_DB_SECTION
              value: database
            - name: OPENSTACK_CONFIG_DB_KEY
              value: connection
          command:
            - /tmp/db-init.py
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: db-init-sh
              mountPath: /tmp/db-init.py
              subPath: db-init.py
              readOnly: true
            - name: etc-service
              mountPath: /etc/rally
            - name: db-init-conf
              mountPath: /etc/rally/rally.conf
              subPath: rally.conf
              readOnly: true
            - name: db-init-conf
              mountPath: /etc/rally/logging.conf
              subPath: logging.conf
              readOnly: true
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: db-init-sh
          configMap:
            name: rally-bin
            defaultMode: 365
        - name: etc-service
          emptyDir: {}
        - name: db-init-conf
          secret:
            secretName: rally-etc
            defaultMode: 292
---
apiVersion: batch/v1
kind: Job
metadata:
  name: rally-ks-endpoints
  annotations:
    openstackhelm.openstack.org/release_uuid: ""
spec:
  template:
    metadata:
      labels:
        release_group: release-name
        application: rally
        component: ks-endpoints
    spec:
      serviceAccountName: rally-ks-endpoints
      restartPolicy: OnFailure
      nodeSelector:
        openstack-control-plane: enabled
      initContainers:
        - name: init
          image: quay.io/airshipit/kubernetes-entrypoint:v1.0.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: default:keystone-api
            - name: DEPENDENCY_JOBS
              value: rally-ks-service
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts: []
      containers:
        - name: benchmark-ks-endpoints-admin
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          command:
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
          env:
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_SVC_ENDPOINT
              value: admin
            - name: OS_SERVICE_NAME
              value: rally
            - name: OS_SERVICE_TYPE
              value: benchmark
            - name: OS_SERVICE_ENDPOINT
              value: http://rally-api.default.svc.cluster.local:9312/v1
        - name: benchmark-ks-endpoints-internal
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          command:
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
          env:
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_SVC_ENDPOINT
              value: internal
            - name: OS_SERVICE_NAME
              value: rally
            - name: OS_SERVICE_TYPE
              value: benchmark
            - name: OS_SERVICE_ENDPOINT
              value: http://rally-api.default.svc.cluster.local:9312/v1
        - name: benchmark-ks-endpoints-public
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          command:
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
          env:
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_SVC_ENDPOINT
              value: public
            - name: OS_SERVICE_NAME
              value: rally
            - name: OS_SERVICE_TYPE
              value: benchmark
            - name: OS_SERVICE_ENDPOINT
              value: http://rally.default.svc.cluster.local/v1
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-endpoints-sh
          configMap:
            name: rally-bin
            defaultMode: 365
---
apiVersion: batch/v1
kind: Job
metadata:
  name: rally-ks-service
  annotations:
    openstackhelm.openstack.org/release_uuid: ""
spec:
  template:
    metadata:
      labels:
        release_group: release-name
        application: rally
        component: ks-service
    spec:
      serviceAccountName: rally-ks-service
      restartPolicy: OnFailure
      nodeSelector:
        openstack-control-plane: enabled
      initContainers:
        - name: init
          image: quay.io/airshipit/kubernetes-entrypoint:v1.0.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: default:keystone-api
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts: []
      containers:
        - name: benchmark-ks-service-registration
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          command:
            - /tmp/ks-service.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-service-sh
              mountPath: /tmp/ks-service.sh
              subPath: ks-service.sh
              readOnly: true
          env:
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_SERVICE_NAME
              value: rally
            - name: OS_SERVICE_TYPE
              value: benchmark
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-service-sh
          configMap:
            name: rally-bin
            defaultMode: 365
---
apiVersion: batch/v1
kind: Job
metadata:
  name: rally-ks-user
  annotations:
    helm.sh/hook-delete-policy: before-hook-creation
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: rally
        component: ks-user
      annotations:
        openstackhelm.openstack.org/release_uuid: ""
    spec:
      serviceAccountName: rally-ks-user
      restartPolicy: OnFailure
      nodeSelector:
        openstack-control-plane: enabled
      initContainers:
        - name: init
          image: quay.io/airshipit/kubernetes-entrypoint:v1.0.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: default:keystone-api
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts: []
      containers:
        - name: ks-user
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          command:
            - /bin/bash
            - -c
            - /tmp/ks-user.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-user-sh
              mountPath: /tmp/ks-user.sh
              subPath: ks-user.sh
              readOnly: true
          env:
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: SERVICE_OS_SERVICE_NAME
              value: rally
            - name: SERVICE_OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-user
                  key: OS_REGION_NAME
            - name: SERVICE_OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-user
                  key: OS_PROJECT_DOMAIN_NAME
            - name: SERVICE_OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-user
                  key: OS_PROJECT_NAME
            - name: SERVICE_OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-user
                  key: OS_USER_DOMAIN_NAME
            - name: SERVICE_OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-user
                  key: OS_USERNAME
            - name: SERVICE_OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-user
                  key: OS_PASSWORD
            - name: SERVICE_OS_ROLES
              value: admin
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-user-sh
          configMap:
            name: rally-bin
            defaultMode: 365
---
apiVersion: batch/v1
kind: Job
metadata:
  name: rally-manage-db
  annotations:
    openstackhelm.openstack.org/release_uuid: ""
spec:
  template:
    metadata:
      labels:
        release_group: release-name
        application: rally
        component: manage-db
    spec:
      serviceAccountName: rally-manage-db
      restartPolicy: OnFailure
      nodeSelector:
        openstack-control-plane: enabled
      initContainers:
        - name: init
          image: quay.io/airshipit/kubernetes-entrypoint:v1.0.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: default:mariadb,default:keystone-api
            - name: DEPENDENCY_JOBS
              value: rally-ks-user,rally-ks-endpoints,rally-db-init
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts: []
      containers:
        - name: rally-manage-db
          image: docker.io/xrally/xrally-openstack:2.0.0
          imagePullPolicy: IfNotPresent
          command:
            - /tmp/manage-db.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: rally-bin
              mountPath: /tmp/manage-db.sh
              subPath: manage-db.sh
              readOnly: true
            - name: etcrally
              mountPath: /etc/rally
            - name: rally-etc
              mountPath: /etc/rally/rally.conf
              subPath: rally.conf
              readOnly: true
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: etcrally
          emptyDir: {}
        - name: rally-etc
          secret:
            secretName: rally-etc
            defaultMode: 292
        - name: rally-bin
          configMap:
            name: rally-bin
            defaultMode: 365
---
apiVersion: batch/v1
kind: Job
metadata:
  name: rally-run-task
  annotations:
    openstackhelm.openstack.org/release_uuid: ""
spec:
  template:
    metadata:
      labels:
        release_group: release-name
        application: rally
        component: run-task
    spec:
      serviceAccountName: rally-run-task
      restartPolicy: OnFailure
      nodeSelector:
        openstack-control-plane: enabled
      initContainers:
        - name: init
          image: quay.io/airshipit/kubernetes-entrypoint:v1.0.0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: default:mariadb,default:keystone-api
            - name: DEPENDENCY_JOBS
              value: rally-manage-db
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts: []
        - name: rally-run-task-init
          image: docker.io/xrally/xrally-openstack:2.0.0
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 0
          command:
            - chown
            - -R
            - 'rally:'
            - /var/lib/rally/data
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: rally-reports
              mountPath: /var/lib/rally/data
      containers:
        - name: rally-run-task
          image: docker.io/xrally/xrally-openstack:2.0.0
          imagePullPolicy: IfNotPresent
          command:
            - /tmp/run-task.sh
          env:
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: rally-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: ENABLED_TESTS
              value: cinder,glance,heat,keystone,magnum,nova,senlin
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: rally-bin
              mountPath: /tmp/run-task.sh
              subPath: run-task.sh
              readOnly: true
            - name: etcrally
              mountPath: /etc/rally
            - name: rally-etc
              mountPath: /etc/rally/rally.conf
              subPath: rally.conf
              readOnly: true
            - name: rally-tasks
              mountPath: /tasks/rally
              readOnly: true
            - name: heat-tasks-test-templates
              mountPath: /tmp/tasks/test-templates
              readOnly: true
            - name: rally-reports
              mountPath: /var/lib/rally/data
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: etcrally
          emptyDir: {}
        - name: rally-etc
          secret:
            secretName: rally-etc
            defaultMode: 292
        - name: rally-tasks
          configMap:
            name: rally-tasks
            defaultMode: 292
        - name: rally-bin
          configMap:
            name: rally-bin
            defaultMode: 365
        - name: heat-tasks-test-templates
          configMap:
            name: heat-tasks-test-templates
        - name: rally-reports
          persistentVolumeClaim:
            claimName: pvc-rally
